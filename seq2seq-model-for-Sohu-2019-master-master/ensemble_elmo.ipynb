{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dutir923/irguest/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from elmoformanylangs import Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderState_ensemble(object):\n",
    "    \"\"\"\n",
    "    State of Decoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, states):\n",
    "        \"\"\"\n",
    "        hidden: Tensor(num_layers, batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        self.states=states\n",
    "        self.mask=states[0].mask\n",
    "        \n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return self.__dict__.get(name)\n",
    "\n",
    "    def set_mask(self,):\n",
    "        for state in self.states:\n",
    "            state.mask=self.mask\n",
    "    \n",
    "    def get_batch_size(self):\n",
    "        \"\"\"\n",
    "        get_batch_size\n",
    "        \"\"\"\n",
    "        return self.states[0].get_batch_size()\n",
    "\n",
    "    def size(self):\n",
    "        \"\"\"\n",
    "        size\n",
    "        \"\"\"\n",
    "        return self.states[0].size()\n",
    "\n",
    "    def slice_select(self, stop):\n",
    "        \"\"\"\n",
    "        slice_select\n",
    "        \"\"\"\n",
    "        states=[]\n",
    "        for state in self.states:\n",
    "            states.append(state.slice_select(stop))\n",
    "        return DecoderState_ensemble(states)\n",
    "\n",
    "    def index_select(self, indices):\n",
    "        \"\"\"\n",
    "        index_select\n",
    "        \"\"\"\n",
    "        states=[]\n",
    "        for state in self.states:\n",
    "            states.append(state.index_select(indices))\n",
    "        return DecoderState_ensemble(states)\n",
    "\n",
    "    def mask_select(self, mask):\n",
    "        \"\"\"\n",
    "        mask_select\n",
    "        \"\"\"\n",
    "        states=[]\n",
    "        for state in self.states:\n",
    "            states.append(state.mask_select(mask))\n",
    "        return DecoderState_ensemble(states)\n",
    "\n",
    "    def inflate(self, times):\n",
    "        \"\"\"\n",
    "        inflate\n",
    "        \"\"\"\n",
    "        states=[]\n",
    "        for state in self.states:\n",
    "            states.append(state.inflate(times))\n",
    "            \n",
    "        return DecoderState_ensemble(states)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from source.utils.misc import Pack\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ensemble(nn.Module):\n",
    "    def __init__(self, models):\n",
    "        super(ensemble, self).__init__()\n",
    "        self.num=len(models)\n",
    "        self.models=nn.ModuleList(models)\n",
    "    def encode(self,inputs, enc_hidden):\n",
    "        enc_outputs=Pack()\n",
    "        states=[]\n",
    "        elmo_embed=self.models[0].encoder.elmo_embedder.sents2elmo(inputs.raw_src)\n",
    "        elmo_length = [x.shape[0] for x in elmo_embed]\n",
    "        batch_size_1=len(elmo_length)\n",
    "        max_l = max(elmo_length)\n",
    "        size = (batch_size_1, max_l, 1024)\n",
    "        tensor_1 = torch.zeros(size, dtype=torch.float)\n",
    "        for i in range(batch_size_1):\n",
    "            tensor_1[i][:elmo_length[i]] = torch.tensor(elmo_embed[i])\n",
    "        elmo_embed=tensor_1.cuda()\n",
    "        for i in range(self.num):\n",
    "            _, state = self.models[i].encode_infe(inputs, elmo_embed, enc_hidden)\n",
    "            states.append(state)\n",
    "#         print(len(states))\n",
    "        return enc_outputs, DecoderState_ensemble(states)\n",
    "    \n",
    "    def decode(self,input_var, dec_state):\n",
    "#         print('-----')\n",
    "        dec_state.set_mask()\n",
    "        p=Pack()\n",
    "        output_temp=[]\n",
    "        attn_temp=[]\n",
    "        dec_state_temp=[]\n",
    "#         print(len(dec_state.states))\n",
    "        for i in range(self.num):\n",
    "#             state_=dec_state.states[i]\n",
    "#             model_=self.models[i]\n",
    "#             print(type(state_))\n",
    "#             print(type(model_))\n",
    "#             output, dec_state_0, attn = model_.decode(input_var, state_)\n",
    "            output, dec_state_0, attn = self.models[i].decode(input_var, dec_state.states[i])\n",
    "            output_temp.append(output)\n",
    "            attn_temp.append(attn.attn)\n",
    "            dec_state_temp.append(dec_state_0)\n",
    "        \n",
    "        output_temp=torch.stack(output_temp).mean(0)\n",
    "        attn_temp=torch.stack(attn_temp).mean(0)\n",
    "        p.add(attn=attn_temp)\n",
    "        dec_state_temp=DecoderState_ensemble(dec_state_temp)\n",
    "        return output_temp, dec_state_temp, p\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='./models/layer_2_64_embed_elmo/params.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_file=open(file,'r',encoding='utf-8')\n",
    "pp=json.loads(p_file.read())\n",
    "config=Pack(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.entity_file='./data/demo_neww_entity.txt'\n",
    "# config.data_dir='./data/data500_pf/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.inputters.corpus import KnowledgeCorpus, Entity_Corpus, Entity_Corpus_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.gpu=1\n",
    "device = config.gpu\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载实体成功，size= 547394\n",
      "Loading prepared vocab from ./data/data550_pos/model_50000.vocab.pt ...\n",
      "Finish loading vocab , size: 50005\n",
      "Finish loading pos vocab , size: 31\n",
      "Loading prepared data from ./data/data550_pos/model_50000.data.pt ...\n",
      "Number of examples: TRAIN-37226 VALID-2000\n"
     ]
    }
   ],
   "source": [
    "corpus = Entity_Corpus_pos(data_dir=config.data_dir, data_prefix=config.data_prefix, entity_file=config.entity_file,\n",
    "                             min_freq=config.min_freq, max_vocab_size=config.max_vocab_size)\n",
    "corpus.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_iter = corpus.create_batches(\n",
    "    15, \"valid\", shuffle=False, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dutir923/irguest/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from source.models.Entity_seq2seq import Entity_Seq2Seq\n",
    "from source.models.Entity_seq2seq_pos import Entity_Seq2Seq_pos\n",
    "from source.models.Entity_seq2seq_pos_gru import Entity_Seq2Seq_pos_gru\n",
    "from source.models.Entity_seq2seq_elmo import Entity_Seq2Seq_elmo\n",
    "from source.models.Entity_seq2seq_elmo_gru import Entity_Seq2Seq_elmo_gru\n",
    "from source.utils.generator import TopKGenerator\n",
    "from source.utils.engine import evaluate, evaluate_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]2019-05-04 17:07:00,808 INFO: char embedding size: 6169\n",
      "2019-05-04 17:07:01,318 INFO: word embedding size: 71222\n",
      "2019-05-04 17:07:08,062 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(71222, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(6169, 50, padding_idx=6166)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      " 20%|██        | 1/5 [00:10<00:40, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model state from './models/layer_2_64_embed_elmo/best.model'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-04 17:07:09,712 INFO: char embedding size: 6169\n",
      "2019-05-04 17:07:10,215 INFO: word embedding size: 71222\n",
      "2019-05-04 17:07:14,325 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(71222, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(6169, 50, padding_idx=6166)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      " 40%|████      | 2/5 [00:15<00:26,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model state from './models/layer_2_64_embed_elmo_1/best.model'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-04 17:07:15,496 INFO: char embedding size: 6169\n",
      "2019-05-04 17:07:15,893 INFO: word embedding size: 71222\n",
      "2019-05-04 17:07:20,260 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(71222, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(6169, 50, padding_idx=6166)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      " 60%|██████    | 3/5 [00:23<00:16,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model state from './models/layer_2_64_embed_elmo_2/best.model'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-04 17:07:23,059 INFO: char embedding size: 6169\n",
      "2019-05-04 17:07:23,527 INFO: word embedding size: 71222\n",
      "2019-05-04 17:07:28,385 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(71222, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(6169, 50, padding_idx=6166)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      " 80%|████████  | 4/5 [00:29<00:07,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model state from './models/layer_2_64_embed_elmo_3/best.model'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-04 17:07:29,398 INFO: char embedding size: 6169\n",
      "2019-05-04 17:07:29,814 INFO: word embedding size: 71222\n",
      "2019-05-04 17:07:34,316 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(71222, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(6169, 50, padding_idx=6166)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "100%|██████████| 5/5 [00:35<00:00,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model state from './models/layer_2_64_embed_elmo_4/best.model'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file1='./models/layer_2_64_embed_elmo/params.json'\n",
    "file2='./models/layer_2_64_embed_elmo_1/params.json'\n",
    "file3='./models/layer_2_64_embed_elmo_2/params.json'\n",
    "file4='./models/layer_2_64_embed_elmo_3/params.json'\n",
    "file5='./models/layer_2_64_embed_elmo_4/params.json'\n",
    "\n",
    "files=[file1,file2,file3,file4,file5]\n",
    "\n",
    "def get_model(files):\n",
    "    models=[]\n",
    "    for f in tqdm(files):\n",
    "        p_file=open(f,'r',encoding='utf-8')\n",
    "        pp=json.loads(p_file.read())\n",
    "        config=Pack(pp)\n",
    "        config.batch_size=15\n",
    "        if config.rnn_type=='GRU':\n",
    "            \n",
    "            model = model = Entity_Seq2Seq_elmo_gru(src_vocab_size=corpus.SRC.vocab_size,\n",
    "                                   embed_size=config.embed_size, hidden_size=config.hidden_size,\n",
    "                                   padding_idx=corpus.padding_idx,\n",
    "                                   num_layers=config.num_layers, bidirectional=config.bidirectional,\n",
    "                                   attn_mode=config.attn, with_bridge=config.with_bridge,\n",
    "                                   dropout=config.dropout,\n",
    "                                   use_gpu=config.use_gpu,\n",
    "                                   pretrain_epoch=config.pretrain_epoch,\n",
    "                                   batch_size=config.batch_size)\n",
    "        else:\n",
    "            model = model = Entity_Seq2Seq_elmo(src_vocab_size=corpus.SRC.vocab_size,\n",
    "                                   embed_size=config.embed_size, hidden_size=config.hidden_size,\n",
    "                                   padding_idx=corpus.padding_idx,\n",
    "                                   num_layers=config.num_layers, bidirectional=config.bidirectional,\n",
    "                                   attn_mode=config.attn, with_bridge=config.with_bridge,\n",
    "                                   dropout=config.dropout,\n",
    "                                   use_gpu=config.use_gpu,\n",
    "                                   pretrain_epoch=config.pretrain_epoch,\n",
    "                                   batch_size=config.batch_size)\n",
    "        config.ckpt=config.save_dir+'/best.model'\n",
    "        model.load(config.ckpt)\n",
    "        models.append(model)\n",
    "    return ensemble(models)\n",
    "\n",
    "models=get_model(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.max_dec_len=5\n",
    "config.beam_size=5\n",
    "generator = TopKGenerator(model=models,\n",
    "                              src_field=corpus.SRC,\n",
    "                              max_length=config.max_dec_len, ignore_unk=config.ignore_unk,\n",
    "\t\t\t      length_average=config.length_average, use_gpu=config.use_gpu, beam_size=config.beam_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-01 22:33:43,300 INFO: 1 batches, avg len: 458.7\n",
      "2019-05-01 22:33:46,635 INFO: 1 batches, avg len: 462.4\n",
      "2019-05-01 22:33:49,192 INFO: 1 batches, avg len: 514.4\n",
      "2019-05-01 22:33:52,422 INFO: 1 batches, avg len: 500.8\n",
      "2019-05-01 22:33:55,455 INFO: 1 batches, avg len: 447.0\n",
      "2019-05-01 22:33:58,367 INFO: 1 batches, avg len: 455.5\n",
      "2019-05-01 22:34:00,764 INFO: 1 batches, avg len: 462.4\n",
      "2019-05-01 22:34:03,158 INFO: 1 batches, avg len: 475.3\n",
      "2019-05-01 22:34:05,538 INFO: 1 batches, avg len: 488.3\n",
      "2019-05-01 22:34:07,923 INFO: 1 batches, avg len: 438.8\n",
      "2019-05-01 22:34:10,333 INFO: 1 batches, avg len: 470.0\n",
      "2019-05-01 22:34:12,691 INFO: 1 batches, avg len: 390.1\n",
      "2019-05-01 22:34:14,989 INFO: 1 batches, avg len: 386.7\n",
      "2019-05-01 22:34:17,258 INFO: 1 batches, avg len: 357.7\n",
      "2019-05-01 22:34:19,607 INFO: 1 batches, avg len: 482.3\n",
      "2019-05-01 22:34:21,931 INFO: 1 batches, avg len: 432.2\n",
      "2019-05-01 22:34:24,364 INFO: 1 batches, avg len: 516.5\n",
      "2019-05-01 22:34:27,089 INFO: 1 batches, avg len: 473.9\n",
      "2019-05-01 22:34:30,093 INFO: 1 batches, avg len: 497.9\n",
      "2019-05-01 22:34:33,107 INFO: 1 batches, avg len: 486.5\n",
      "2019-05-01 22:34:36,117 INFO: 1 batches, avg len: 422.4\n",
      "2019-05-01 22:34:39,220 INFO: 1 batches, avg len: 475.8\n",
      "2019-05-01 22:34:42,268 INFO: 1 batches, avg len: 446.1\n",
      "2019-05-01 22:34:45,217 INFO: 1 batches, avg len: 403.9\n",
      "2019-05-01 22:34:47,775 INFO: 1 batches, avg len: 503.1\n",
      "2019-05-01 22:34:50,185 INFO: 1 batches, avg len: 424.3\n",
      "2019-05-01 22:34:52,615 INFO: 1 batches, avg len: 531.6\n",
      "2019-05-01 22:34:55,148 INFO: 1 batches, avg len: 482.4\n",
      "2019-05-01 22:34:57,634 INFO: 1 batches, avg len: 477.4\n",
      "2019-05-01 22:35:00,117 INFO: 1 batches, avg len: 453.7\n",
      "2019-05-01 22:35:02,549 INFO: 1 batches, avg len: 463.7\n",
      "2019-05-01 22:35:04,955 INFO: 1 batches, avg len: 419.7\n",
      "2019-05-01 22:35:07,533 INFO: 1 batches, avg len: 440.7\n",
      "2019-05-01 22:35:10,581 INFO: 1 batches, avg len: 351.4\n",
      "2019-05-01 22:35:13,608 INFO: 1 batches, avg len: 412.7\n",
      "2019-05-01 22:35:16,665 INFO: 1 batches, avg len: 424.2\n",
      "2019-05-01 22:35:19,717 INFO: 1 batches, avg len: 439.9\n",
      "2019-05-01 22:35:22,828 INFO: 1 batches, avg len: 450.2\n",
      "2019-05-01 22:35:25,896 INFO: 1 batches, avg len: 400.4\n",
      "2019-05-01 22:35:28,970 INFO: 1 batches, avg len: 466.3\n",
      "2019-05-01 22:35:32,086 INFO: 1 batches, avg len: 452.4\n",
      "2019-05-01 22:35:35,117 INFO: 1 batches, avg len: 380.9\n",
      "2019-05-01 22:35:38,093 INFO: 1 batches, avg len: 363.9\n",
      "2019-05-01 22:35:41,115 INFO: 1 batches, avg len: 427.3\n",
      "2019-05-01 22:35:44,178 INFO: 1 batches, avg len: 448.8\n",
      "2019-05-01 22:35:47,285 INFO: 1 batches, avg len: 431.1\n",
      "2019-05-01 22:35:50,449 INFO: 1 batches, avg len: 515.9\n",
      "2019-05-01 22:35:53,516 INFO: 1 batches, avg len: 499.9\n",
      "2019-05-01 22:35:56,592 INFO: 1 batches, avg len: 436.1\n",
      "2019-05-01 22:35:59,643 INFO: 1 batches, avg len: 497.3\n",
      "2019-05-01 22:36:02,717 INFO: 1 batches, avg len: 475.3\n",
      "2019-05-01 22:36:05,712 INFO: 1 batches, avg len: 420.4\n",
      "2019-05-01 22:36:08,906 INFO: 1 batches, avg len: 507.4\n",
      "2019-05-01 22:36:11,927 INFO: 1 batches, avg len: 387.4\n",
      "2019-05-01 22:36:14,906 INFO: 1 batches, avg len: 436.9\n",
      "2019-05-01 22:36:17,977 INFO: 1 batches, avg len: 465.7\n",
      "2019-05-01 22:36:20,937 INFO: 1 batches, avg len: 438.1\n",
      "2019-05-01 22:36:23,980 INFO: 1 batches, avg len: 520.1\n",
      "2019-05-01 22:36:27,012 INFO: 1 batches, avg len: 449.5\n",
      "2019-05-01 22:36:30,139 INFO: 1 batches, avg len: 497.1\n",
      "2019-05-01 22:36:33,266 INFO: 1 batches, avg len: 492.4\n",
      "2019-05-01 22:36:36,276 INFO: 1 batches, avg len: 457.1\n",
      "2019-05-01 22:36:38,731 INFO: 1 batches, avg len: 448.5\n",
      "2019-05-01 22:36:41,287 INFO: 1 batches, avg len: 488.9\n",
      "2019-05-01 22:36:44,492 INFO: 1 batches, avg len: 470.5\n",
      "2019-05-01 22:36:47,544 INFO: 1 batches, avg len: 462.9\n",
      "2019-05-01 22:36:50,545 INFO: 1 batches, avg len: 457.7\n",
      "2019-05-01 22:36:53,627 INFO: 1 batches, avg len: 497.7\n",
      "2019-05-01 22:36:56,633 INFO: 1 batches, avg len: 462.5\n",
      "2019-05-01 22:36:59,710 INFO: 1 batches, avg len: 443.3\n",
      "2019-05-01 22:37:02,813 INFO: 1 batches, avg len: 491.6\n",
      "2019-05-01 22:37:05,795 INFO: 1 batches, avg len: 435.7\n",
      "2019-05-01 22:37:08,817 INFO: 1 batches, avg len: 453.3\n",
      "2019-05-01 22:37:11,731 INFO: 1 batches, avg len: 374.9\n",
      "2019-05-01 22:37:14,699 INFO: 1 batches, avg len: 429.3\n",
      "2019-05-01 22:37:17,722 INFO: 1 batches, avg len: 486.0\n",
      "2019-05-01 22:37:20,699 INFO: 1 batches, avg len: 431.6\n",
      "2019-05-01 22:37:23,703 INFO: 1 batches, avg len: 446.3\n",
      "2019-05-01 22:37:26,772 INFO: 1 batches, avg len: 445.8\n",
      "2019-05-01 22:37:29,867 INFO: 1 batches, avg len: 454.7\n",
      "2019-05-01 22:37:33,030 INFO: 1 batches, avg len: 490.7\n",
      "2019-05-01 22:37:35,967 INFO: 1 batches, avg len: 388.5\n",
      "2019-05-01 22:37:38,920 INFO: 1 batches, avg len: 420.7\n",
      "2019-05-01 22:37:41,913 INFO: 1 batches, avg len: 447.3\n",
      "2019-05-01 22:37:44,893 INFO: 1 batches, avg len: 432.7\n",
      "2019-05-01 22:37:47,794 INFO: 1 batches, avg len: 398.1\n",
      "2019-05-01 22:37:50,754 INFO: 1 batches, avg len: 420.3\n",
      "2019-05-01 22:37:53,812 INFO: 1 batches, avg len: 474.3\n",
      "2019-05-01 22:37:56,866 INFO: 1 batches, avg len: 481.3\n",
      "2019-05-01 22:37:59,858 INFO: 1 batches, avg len: 446.3\n",
      "2019-05-01 22:38:02,389 INFO: 1 batches, avg len: 454.9\n",
      "2019-05-01 22:38:04,793 INFO: 1 batches, avg len: 451.9\n",
      "2019-05-01 22:38:07,175 INFO: 1 batches, avg len: 451.1\n",
      "2019-05-01 22:38:09,726 INFO: 1 batches, avg len: 475.3\n",
      "2019-05-01 22:38:12,818 INFO: 1 batches, avg len: 495.1\n",
      "2019-05-01 22:38:15,855 INFO: 1 batches, avg len: 429.3\n",
      "2019-05-01 22:38:18,837 INFO: 1 batches, avg len: 453.6\n",
      "2019-05-01 22:38:21,818 INFO: 1 batches, avg len: 425.7\n",
      "2019-05-01 22:38:24,883 INFO: 1 batches, avg len: 493.1\n",
      "2019-05-01 22:38:27,962 INFO: 1 batches, avg len: 469.4\n",
      "2019-05-01 22:38:30,968 INFO: 1 batches, avg len: 429.1\n",
      "2019-05-01 22:38:33,911 INFO: 1 batches, avg len: 410.1\n",
      "2019-05-01 22:38:36,919 INFO: 1 batches, avg len: 459.1\n",
      "2019-05-01 22:38:39,990 INFO: 1 batches, avg len: 487.0\n",
      "2019-05-01 22:38:42,909 INFO: 1 batches, avg len: 493.9\n",
      "2019-05-01 22:38:45,311 INFO: 1 batches, avg len: 433.6\n",
      "2019-05-01 22:38:47,712 INFO: 1 batches, avg len: 446.3\n",
      "2019-05-01 22:38:50,164 INFO: 1 batches, avg len: 449.5\n",
      "2019-05-01 22:38:52,803 INFO: 1 batches, avg len: 431.5\n",
      "2019-05-01 22:38:55,762 INFO: 1 batches, avg len: 388.4\n",
      "2019-05-01 22:38:58,713 INFO: 1 batches, avg len: 427.5\n",
      "2019-05-01 22:39:01,819 INFO: 1 batches, avg len: 465.7\n",
      "2019-05-01 22:39:04,904 INFO: 1 batches, avg len: 457.8\n",
      "2019-05-01 22:39:07,996 INFO: 1 batches, avg len: 436.5\n",
      "2019-05-01 22:39:11,024 INFO: 1 batches, avg len: 378.9\n",
      "2019-05-01 22:39:14,089 INFO: 1 batches, avg len: 455.1\n",
      "2019-05-01 22:39:17,082 INFO: 1 batches, avg len: 473.5\n",
      "2019-05-01 22:39:20,075 INFO: 1 batches, avg len: 452.1\n",
      "2019-05-01 22:39:23,083 INFO: 1 batches, avg len: 431.5\n",
      "2019-05-01 22:39:26,086 INFO: 1 batches, avg len: 460.3\n",
      "2019-05-01 22:39:29,053 INFO: 1 batches, avg len: 424.3\n",
      "2019-05-01 22:39:32,039 INFO: 1 batches, avg len: 406.9\n",
      "2019-05-01 22:39:34,997 INFO: 1 batches, avg len: 423.1\n",
      "2019-05-01 22:39:38,017 INFO: 1 batches, avg len: 431.8\n",
      "2019-05-01 22:39:41,088 INFO: 1 batches, avg len: 449.1\n",
      "2019-05-01 22:39:44,192 INFO: 1 batches, avg len: 502.7\n",
      "2019-05-01 22:39:47,420 INFO: 1 batches, avg len: 459.3\n",
      "2019-05-01 22:39:50,449 INFO: 1 batches, avg len: 411.3\n",
      "2019-05-01 22:39:53,480 INFO: 1 batches, avg len: 461.4\n",
      "2019-05-01 22:39:56,495 INFO: 1 batches, avg len: 394.4\n",
      "2019-05-01 22:39:59,617 INFO: 1 batches, avg len: 496.4\n",
      "2019-05-01 22:40:02,666 INFO: 1 batches, avg len: 432.5\n",
      "2019-05-01 22:40:05,796 INFO: 1 batches, avg len: 441.1\n",
      "2019-05-01 22:40:08,605 INFO: 1 batches, avg len: 372.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generation results to './test.result'\n",
      "Avg_Len-2.055   F1-0.664   precision-0.709   recal-0.693   emo_precision-0.654\n",
      "Target:   AVG_LEN-2.093   \n"
     ]
    }
   ],
   "source": [
    "evaluate_generation(generator, valid_iter, save_file=config.gen_file, verbos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 211/3000 [00:00<00:01, 2109.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished data read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:01<00:00, 2954.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: TRAIN-37226 VALID-2000 TEST-3000\n"
     ]
    }
   ],
   "source": [
    "corpus.reload(data_type='test')\n",
    "test_iter = corpus.create_batches(\n",
    "            15, \"test\", shuffle=False, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.inputters.dataset import Dataset, Entity_Dataset, Entity_Dataset_pos,Entity_Dataset_pos_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 364/40000 [00:00<00:10, 3630.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished data read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [00:14<00:00, 2744.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: TRAIN-37226 VALID-2000 TEST-40000\n"
     ]
    }
   ],
   "source": [
    "corpus.reload(data_type='test')\n",
    "data=Entity_Dataset_pos(corpus.data[\"test\"].data[:3000])\n",
    "test_iter=data.create_batches(\n",
    "            15,  shuffle=False, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-04 17:10:34,732 INFO: 1 batches, avg len: 483.7\n",
      "2019-05-04 17:10:37,697 INFO: 1 batches, avg len: 378.3\n",
      "2019-05-04 17:10:40,677 INFO: 1 batches, avg len: 488.4\n",
      "2019-05-04 17:10:43,530 INFO: 1 batches, avg len: 427.1\n",
      "2019-05-04 17:10:46,449 INFO: 1 batches, avg len: 395.5\n",
      "2019-05-04 17:10:48,902 INFO: 1 batches, avg len: 447.9\n",
      "2019-05-04 17:10:51,378 INFO: 1 batches, avg len: 491.6\n",
      "2019-05-04 17:10:53,936 INFO: 1 batches, avg len: 477.7\n",
      "2019-05-04 17:10:56,736 INFO: 1 batches, avg len: 477.9\n",
      "2019-05-04 17:10:59,961 INFO: 1 batches, avg len: 466.7\n",
      "2019-05-04 17:11:03,120 INFO: 1 batches, avg len: 479.6\n",
      "2019-05-04 17:11:05,945 INFO: 1 batches, avg len: 338.3\n",
      "2019-05-04 17:11:08,716 INFO: 1 batches, avg len: 460.7\n",
      "2019-05-04 17:11:11,731 INFO: 1 batches, avg len: 472.1\n",
      "2019-05-04 17:11:14,934 INFO: 1 batches, avg len: 468.6\n",
      "2019-05-04 17:11:17,454 INFO: 1 batches, avg len: 336.4\n",
      "2019-05-04 17:11:20,497 INFO: 1 batches, avg len: 464.2\n",
      "2019-05-04 17:11:23,343 INFO: 1 batches, avg len: 444.2\n",
      "2019-05-04 17:11:26,627 INFO: 1 batches, avg len: 445.7\n",
      "2019-05-04 17:11:29,382 INFO: 1 batches, avg len: 488.4\n",
      "2019-05-04 17:11:32,162 INFO: 1 batches, avg len: 446.4\n",
      "2019-05-04 17:11:35,399 INFO: 1 batches, avg len: 446.1\n",
      "2019-05-04 17:11:38,511 INFO: 1 batches, avg len: 418.2\n",
      "2019-05-04 17:11:41,642 INFO: 1 batches, avg len: 431.7\n",
      "2019-05-04 17:11:44,767 INFO: 1 batches, avg len: 419.9\n",
      "2019-05-04 17:11:47,879 INFO: 1 batches, avg len: 427.9\n",
      "2019-05-04 17:11:50,814 INFO: 1 batches, avg len: 448.4\n",
      "2019-05-04 17:11:53,447 INFO: 1 batches, avg len: 421.2\n",
      "2019-05-04 17:11:56,043 INFO: 1 batches, avg len: 434.8\n",
      "2019-05-04 17:11:58,757 INFO: 1 batches, avg len: 415.7\n",
      "2019-05-04 17:12:01,451 INFO: 1 batches, avg len: 379.9\n",
      "2019-05-04 17:12:04,026 INFO: 1 batches, avg len: 342.5\n",
      "2019-05-04 17:12:06,724 INFO: 1 batches, avg len: 396.3\n",
      "2019-05-04 17:12:09,372 INFO: 1 batches, avg len: 359.2\n",
      "2019-05-04 17:12:12,130 INFO: 1 batches, avg len: 405.3\n",
      "2019-05-04 17:12:15,103 INFO: 1 batches, avg len: 378.6\n",
      "2019-05-04 17:12:17,867 INFO: 1 batches, avg len: 462.5\n",
      "2019-05-04 17:12:20,518 INFO: 1 batches, avg len: 323.4\n",
      "2019-05-04 17:12:23,549 INFO: 1 batches, avg len: 418.5\n",
      "2019-05-04 17:12:26,308 INFO: 1 batches, avg len: 476.2\n",
      "2019-05-04 17:12:28,857 INFO: 1 batches, avg len: 403.1\n",
      "2019-05-04 17:12:31,362 INFO: 1 batches, avg len: 489.6\n",
      "2019-05-04 17:12:33,885 INFO: 1 batches, avg len: 339.9\n",
      "2019-05-04 17:12:36,382 INFO: 1 batches, avg len: 421.4\n",
      "2019-05-04 17:12:38,990 INFO: 1 batches, avg len: 439.5\n",
      "2019-05-04 17:12:41,652 INFO: 1 batches, avg len: 425.7\n",
      "2019-05-04 17:12:44,460 INFO: 1 batches, avg len: 411.4\n",
      "2019-05-04 17:12:47,217 INFO: 1 batches, avg len: 417.9\n",
      "2019-05-04 17:12:50,197 INFO: 1 batches, avg len: 451.6\n",
      "2019-05-04 17:12:52,999 INFO: 1 batches, avg len: 402.5\n",
      "2019-05-04 17:12:55,758 INFO: 1 batches, avg len: 444.1\n",
      "2019-05-04 17:12:58,610 INFO: 1 batches, avg len: 467.7\n",
      "2019-05-04 17:13:01,575 INFO: 1 batches, avg len: 406.9\n",
      "2019-05-04 17:13:04,335 INFO: 1 batches, avg len: 386.2\n",
      "2019-05-04 17:13:06,943 INFO: 1 batches, avg len: 419.9\n",
      "2019-05-04 17:13:09,893 INFO: 1 batches, avg len: 441.9\n",
      "2019-05-04 17:13:12,789 INFO: 1 batches, avg len: 469.7\n",
      "2019-05-04 17:13:15,977 INFO: 1 batches, avg len: 429.4\n",
      "2019-05-04 17:13:19,154 INFO: 1 batches, avg len: 446.9\n",
      "2019-05-04 17:13:22,293 INFO: 1 batches, avg len: 368.8\n",
      "2019-05-04 17:13:25,324 INFO: 1 batches, avg len: 449.7\n",
      "2019-05-04 17:13:28,656 INFO: 1 batches, avg len: 458.3\n",
      "2019-05-04 17:13:32,066 INFO: 1 batches, avg len: 444.8\n",
      "2019-05-04 17:13:34,948 INFO: 1 batches, avg len: 475.7\n",
      "2019-05-04 17:13:37,644 INFO: 1 batches, avg len: 400.8\n",
      "2019-05-04 17:13:40,687 INFO: 1 batches, avg len: 404.8\n",
      "2019-05-04 17:13:43,785 INFO: 1 batches, avg len: 397.8\n",
      "2019-05-04 17:13:46,694 INFO: 1 batches, avg len: 499.0\n",
      "2019-05-04 17:13:49,599 INFO: 1 batches, avg len: 447.5\n",
      "2019-05-04 17:13:52,265 INFO: 1 batches, avg len: 411.3\n",
      "2019-05-04 17:13:55,145 INFO: 1 batches, avg len: 429.3\n",
      "2019-05-04 17:13:57,845 INFO: 1 batches, avg len: 442.1\n",
      "2019-05-04 17:14:00,850 INFO: 1 batches, avg len: 455.9\n",
      "2019-05-04 17:14:03,702 INFO: 1 batches, avg len: 423.6\n",
      "2019-05-04 17:14:06,320 INFO: 1 batches, avg len: 363.1\n",
      "2019-05-04 17:14:09,231 INFO: 1 batches, avg len: 431.9\n",
      "2019-05-04 17:14:11,997 INFO: 1 batches, avg len: 464.1\n",
      "2019-05-04 17:14:14,941 INFO: 1 batches, avg len: 435.4\n",
      "2019-05-04 17:14:18,007 INFO: 1 batches, avg len: 441.3\n",
      "2019-05-04 17:14:20,484 INFO: 1 batches, avg len: 362.6\n",
      "2019-05-04 17:14:23,157 INFO: 1 batches, avg len: 475.3\n",
      "2019-05-04 17:14:25,769 INFO: 1 batches, avg len: 470.0\n",
      "2019-05-04 17:14:28,587 INFO: 1 batches, avg len: 487.7\n",
      "2019-05-04 17:14:31,299 INFO: 1 batches, avg len: 483.7\n",
      "2019-05-04 17:14:34,100 INFO: 1 batches, avg len: 468.8\n",
      "2019-05-04 17:14:36,915 INFO: 1 batches, avg len: 459.5\n",
      "2019-05-04 17:14:39,457 INFO: 1 batches, avg len: 388.1\n",
      "2019-05-04 17:14:42,007 INFO: 1 batches, avg len: 410.9\n",
      "2019-05-04 17:14:44,672 INFO: 1 batches, avg len: 442.8\n",
      "2019-05-04 17:14:47,642 INFO: 1 batches, avg len: 435.6\n",
      "2019-05-04 17:14:50,391 INFO: 1 batches, avg len: 452.8\n",
      "2019-05-04 17:14:53,470 INFO: 1 batches, avg len: 470.5\n",
      "2019-05-04 17:14:56,390 INFO: 1 batches, avg len: 402.9\n",
      "2019-05-04 17:14:59,204 INFO: 1 batches, avg len: 426.1\n",
      "2019-05-04 17:15:02,146 INFO: 1 batches, avg len: 419.5\n",
      "2019-05-04 17:15:04,991 INFO: 1 batches, avg len: 450.9\n",
      "2019-05-04 17:15:08,044 INFO: 1 batches, avg len: 460.3\n",
      "2019-05-04 17:15:11,112 INFO: 1 batches, avg len: 398.7\n",
      "2019-05-04 17:15:14,037 INFO: 1 batches, avg len: 451.7\n",
      "2019-05-04 17:15:17,262 INFO: 1 batches, avg len: 493.1\n",
      "2019-05-04 17:15:20,099 INFO: 1 batches, avg len: 396.3\n",
      "2019-05-04 17:15:23,099 INFO: 1 batches, avg len: 459.7\n",
      "2019-05-04 17:15:25,644 INFO: 1 batches, avg len: 401.3\n",
      "2019-05-04 17:15:28,353 INFO: 1 batches, avg len: 447.7\n",
      "2019-05-04 17:15:31,345 INFO: 1 batches, avg len: 421.2\n",
      "2019-05-04 17:15:33,915 INFO: 1 batches, avg len: 404.4\n",
      "2019-05-04 17:15:36,707 INFO: 1 batches, avg len: 398.5\n",
      "2019-05-04 17:15:39,371 INFO: 1 batches, avg len: 462.9\n",
      "2019-05-04 17:15:41,878 INFO: 1 batches, avg len: 428.3\n",
      "2019-05-04 17:15:44,665 INFO: 1 batches, avg len: 490.9\n",
      "2019-05-04 17:15:47,258 INFO: 1 batches, avg len: 453.0\n",
      "2019-05-04 17:15:49,740 INFO: 1 batches, avg len: 464.8\n",
      "2019-05-04 17:15:52,795 INFO: 1 batches, avg len: 442.6\n",
      "2019-05-04 17:15:55,575 INFO: 1 batches, avg len: 490.4\n",
      "2019-05-04 17:15:58,193 INFO: 1 batches, avg len: 424.9\n",
      "2019-05-04 17:16:00,750 INFO: 1 batches, avg len: 463.8\n",
      "2019-05-04 17:16:03,349 INFO: 1 batches, avg len: 409.0\n",
      "2019-05-04 17:16:05,864 INFO: 1 batches, avg len: 407.5\n",
      "2019-05-04 17:16:08,420 INFO: 1 batches, avg len: 416.6\n",
      "2019-05-04 17:16:10,959 INFO: 1 batches, avg len: 532.7\n",
      "2019-05-04 17:16:13,658 INFO: 1 batches, avg len: 461.7\n",
      "2019-05-04 17:16:16,422 INFO: 1 batches, avg len: 465.5\n",
      "2019-05-04 17:16:19,112 INFO: 1 batches, avg len: 473.3\n",
      "2019-05-04 17:16:21,702 INFO: 1 batches, avg len: 414.3\n",
      "2019-05-04 17:16:24,601 INFO: 1 batches, avg len: 467.3\n",
      "2019-05-04 17:16:27,598 INFO: 1 batches, avg len: 482.0\n",
      "2019-05-04 17:16:30,470 INFO: 1 batches, avg len: 479.1\n",
      "2019-05-04 17:16:33,532 INFO: 1 batches, avg len: 422.8\n",
      "2019-05-04 17:16:36,274 INFO: 1 batches, avg len: 402.1\n",
      "2019-05-04 17:16:39,259 INFO: 1 batches, avg len: 460.0\n",
      "2019-05-04 17:16:41,848 INFO: 1 batches, avg len: 458.7\n",
      "2019-05-04 17:16:44,380 INFO: 1 batches, avg len: 428.7\n",
      "2019-05-04 17:16:47,079 INFO: 1 batches, avg len: 448.5\n",
      "2019-05-04 17:16:50,074 INFO: 1 batches, avg len: 432.0\n",
      "2019-05-04 17:16:52,518 INFO: 1 batches, avg len: 400.2\n",
      "2019-05-04 17:16:54,897 INFO: 1 batches, avg len: 358.5\n",
      "2019-05-04 17:16:57,370 INFO: 1 batches, avg len: 472.3\n",
      "2019-05-04 17:17:00,015 INFO: 1 batches, avg len: 445.7\n",
      "2019-05-04 17:17:02,801 INFO: 1 batches, avg len: 457.2\n",
      "2019-05-04 17:17:05,390 INFO: 1 batches, avg len: 444.3\n",
      "2019-05-04 17:17:08,279 INFO: 1 batches, avg len: 491.1\n",
      "2019-05-04 17:17:10,876 INFO: 1 batches, avg len: 404.1\n",
      "2019-05-04 17:17:13,532 INFO: 1 batches, avg len: 443.7\n",
      "2019-05-04 17:17:16,102 INFO: 1 batches, avg len: 418.3\n",
      "2019-05-04 17:17:18,962 INFO: 1 batches, avg len: 490.9\n",
      "2019-05-04 17:17:21,542 INFO: 1 batches, avg len: 399.7\n",
      "2019-05-04 17:17:24,448 INFO: 1 batches, avg len: 495.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-04 17:17:26,958 INFO: 1 batches, avg len: 432.3\n",
      "2019-05-04 17:17:29,467 INFO: 1 batches, avg len: 348.9\n",
      "2019-05-04 17:17:32,110 INFO: 1 batches, avg len: 468.3\n",
      "2019-05-04 17:17:34,867 INFO: 1 batches, avg len: 473.3\n",
      "2019-05-04 17:17:37,691 INFO: 1 batches, avg len: 478.3\n",
      "2019-05-04 17:17:40,352 INFO: 1 batches, avg len: 485.0\n",
      "2019-05-04 17:17:43,252 INFO: 1 batches, avg len: 395.9\n",
      "2019-05-04 17:17:45,669 INFO: 1 batches, avg len: 367.8\n",
      "2019-05-04 17:17:48,318 INFO: 1 batches, avg len: 465.3\n",
      "2019-05-04 17:17:51,224 INFO: 1 batches, avg len: 436.2\n",
      "2019-05-04 17:17:54,046 INFO: 1 batches, avg len: 474.5\n",
      "2019-05-04 17:17:56,871 INFO: 1 batches, avg len: 439.0\n",
      "2019-05-04 17:17:59,948 INFO: 1 batches, avg len: 498.0\n",
      "2019-05-04 17:18:02,665 INFO: 1 batches, avg len: 447.9\n",
      "2019-05-04 17:18:05,357 INFO: 1 batches, avg len: 491.3\n",
      "2019-05-04 17:18:08,085 INFO: 1 batches, avg len: 430.4\n",
      "2019-05-04 17:18:10,646 INFO: 1 batches, avg len: 425.2\n",
      "2019-05-04 17:18:13,602 INFO: 1 batches, avg len: 488.8\n",
      "2019-05-04 17:18:16,250 INFO: 1 batches, avg len: 440.7\n",
      "2019-05-04 17:18:18,777 INFO: 1 batches, avg len: 449.7\n",
      "2019-05-04 17:18:21,413 INFO: 1 batches, avg len: 401.0\n",
      "2019-05-04 17:18:24,012 INFO: 1 batches, avg len: 493.3\n",
      "2019-05-04 17:18:26,682 INFO: 1 batches, avg len: 457.7\n",
      "2019-05-04 17:18:29,258 INFO: 1 batches, avg len: 432.3\n",
      "2019-05-04 17:18:31,766 INFO: 1 batches, avg len: 481.0\n",
      "2019-05-04 17:18:34,306 INFO: 1 batches, avg len: 464.7\n",
      "2019-05-04 17:18:36,965 INFO: 1 batches, avg len: 507.6\n",
      "2019-05-04 17:18:39,735 INFO: 1 batches, avg len: 411.7\n",
      "2019-05-04 17:18:42,700 INFO: 1 batches, avg len: 439.6\n",
      "2019-05-04 17:18:45,327 INFO: 1 batches, avg len: 504.3\n",
      "2019-05-04 17:18:47,821 INFO: 1 batches, avg len: 443.9\n",
      "2019-05-04 17:18:50,331 INFO: 1 batches, avg len: 302.8\n",
      "2019-05-04 17:18:52,959 INFO: 1 batches, avg len: 295.5\n",
      "2019-05-04 17:18:55,438 INFO: 1 batches, avg len: 245.5\n",
      "2019-05-04 17:18:57,832 INFO: 1 batches, avg len: 287.0\n",
      "2019-05-04 17:19:00,271 INFO: 1 batches, avg len: 371.7\n",
      "2019-05-04 17:19:03,503 INFO: 1 batches, avg len: 431.4\n",
      "2019-05-04 17:19:06,470 INFO: 1 batches, avg len: 448.0\n",
      "2019-05-04 17:19:09,453 INFO: 1 batches, avg len: 386.1\n",
      "2019-05-04 17:19:12,312 INFO: 1 batches, avg len: 419.1\n",
      "2019-05-04 17:19:15,428 INFO: 1 batches, avg len: 463.1\n",
      "2019-05-04 17:19:17,874 INFO: 1 batches, avg len: 432.0\n",
      "2019-05-04 17:19:20,644 INFO: 1 batches, avg len: 433.5\n",
      "2019-05-04 17:19:23,673 INFO: 1 batches, avg len: 474.6\n",
      "2019-05-04 17:19:26,321 INFO: 1 batches, avg len: 389.7\n",
      "2019-05-04 17:19:29,043 INFO: 1 batches, avg len: 460.7\n",
      "2019-05-04 17:19:31,638 INFO: 1 batches, avg len: 433.5\n",
      "2019-05-04 17:19:34,292 INFO: 1 batches, avg len: 415.5\n",
      "2019-05-04 17:19:36,864 INFO: 1 batches, avg len: 424.3\n",
      "2019-05-04 17:19:39,272 INFO: 1 batches, avg len: 378.1\n",
      "2019-05-04 17:19:41,953 INFO: 1 batches, avg len: 489.5\n",
      "2019-05-04 17:19:44,624 INFO: 1 batches, avg len: 435.9\n",
      "2019-05-04 17:19:47,400 INFO: 1 batches, avg len: 365.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg_Len-2.452   F1-0.000   precision-0.000   recal-0.000   emo_precision-0.000\n",
      "Target:   AVG_LEN-1.000   \n"
     ]
    }
   ],
   "source": [
    "config.gen_file='./result.txt545'\n",
    "evaluate_generation(generator, test_iter, save_file=config.gen_file, verbos=True, for_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg_Len-2.152   F1-0.646   precision-0.682   recal-0.688   emo_precision-0.649\n",
    "Target:   AVG_LEN-2.093  \n",
    "Avg_Len-2.168   F1-0.649   precision-0.680   recal-0.692   emo_precision-0.653\n",
    "Target:   AVG_LEN-2.093   \n",
    "Avg_Len-2.168   F1-0.649   precision-0.680   recal-0.692   emo_precision-0.653\n",
    "Target:   AVG_LEN-2.093   \n",
    "Avg_Len-2.055   F1-0.664   precision-0.709   recal-0.693   emo_precision-0.654\n",
    "Target:   AVG_LEN-2.093   \n",
    "Avg_Len-2.425   F1-0.640   precision-0.615   recal-0.729   emo_precision-0.693\n",
    "Target:   AVG_LEN-2.093   \n",
    "Avg_Len-1.730   F1-0.658   precision-0.744   recal-0.645   emo_precision-0.602\n",
    "Target:   AVG_LEN-2.093\n",
    "\n",
    "Avg_Len-2.006   F1-0.667   precision-0.711   recal-0.690   emo_precision-0.645\n",
    "Target:   AVG_LEN-2.091  \n",
    "\n",
    "\n",
    "Saved generation results to './test.result'\n",
    "Avg_Len-2.055   F1-0.664   precision-0.709   recal-0.693   emo_precision-0.654\n",
    "Target:   AVG_LEN-2.093  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
