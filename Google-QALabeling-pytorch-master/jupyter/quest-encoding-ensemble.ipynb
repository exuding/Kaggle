{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ../input/sacremoses/sacremoses-master/ > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"../input/kerasswa/keras-swa-0.1.2\"  > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "import random\n",
    "from tqdm import tqdm_notebook\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.preprocessing import OneHotEncoder, minmax_scale, MultiLabelBinarizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import MultiTaskElasticNet\n",
    "from scipy.stats import spearmanr, rankdata\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1' # -1 = CPU only\n",
    "\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim import utils\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, \"../input/transformers/transformers-master/\")\n",
    "import transformers\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras import Model\n",
    "from swa.keras import SWA\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "\n",
    "import pickle    \n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "                \n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.path.append(\"../input/nltk-data/nltk_data\")\n",
    "# thse are in nltk_data dataset \n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#INPUT_PATH=\"/kaggle/input/\"\n",
    "INPUT_PATH=\"../input/\"\n",
    "train = pd.read_csv(INPUT_PATH+'google-quest-challenge/train.csv')\n",
    "test = pd.read_csv(INPUT_PATH+'google-quest-challenge/test.csv')\n",
    "submission = pd.read_csv(INPUT_PATH+'google-quest-challenge/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\n",
    "        'question_asker_intent_understanding',\n",
    "        'question_body_critical',\n",
    "        'question_conversational',\n",
    "        'question_expect_short_answer',\n",
    "        'question_fact_seeking',\n",
    "        'question_has_commonly_accepted_answer',\n",
    "        'question_interestingness_others',\n",
    "        'question_interestingness_self',\n",
    "        'question_multi_intent',\n",
    "        'question_not_really_a_question',\n",
    "        'question_opinion_seeking',\n",
    "        'question_type_choice',\n",
    "        'question_type_compare',\n",
    "        'question_type_consequence',\n",
    "        'question_type_definition',\n",
    "        'question_type_entity',\n",
    "        'question_type_instructions',\n",
    "        'question_type_procedure',\n",
    "        'question_type_reason_explanation',\n",
    "        'question_type_spelling',\n",
    "        'question_well_written',\n",
    "        'answer_helpful',\n",
    "        'answer_level_of_information',\n",
    "        'answer_plausible',\n",
    "        'answer_relevance',\n",
    "        'answer_satisfaction',\n",
    "        'answer_type_instructions',\n",
    "        'answer_type_procedure',\n",
    "        'answer_type_reason_explanation',\n",
    "        'answer_well_written'    \n",
    "    ]\n",
    "\n",
    "input_columns = ['question_title','question_body','answer']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean data\n",
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '\\xa0', '\\t',\n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '\\u3000', '\\u202f',\n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '«',\n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "mispell_dict = {\"aren't\" : \"are not\",\n",
    "\"can't\" : \"cannot\",\n",
    "\"couldn't\" : \"could not\",\n",
    "\"couldnt\" : \"could not\",\n",
    "\"didn't\" : \"did not\",\n",
    "\"doesn't\" : \"does not\",\n",
    "\"doesnt\" : \"does not\",\n",
    "\"don't\" : \"do not\",\n",
    "\"hadn't\" : \"had not\",\n",
    "\"hasn't\" : \"has not\",\n",
    "\"haven't\" : \"have not\",\n",
    "\"havent\" : \"have not\",\n",
    "\"he'd\" : \"he would\",\n",
    "\"he'll\" : \"he will\",\n",
    "\"he's\" : \"he is\",\n",
    "\"i'd\" : \"I would\",\n",
    "\"i'd\" : \"I had\",\n",
    "\"i'll\" : \"I will\",\n",
    "\"i'm\" : \"I am\",\n",
    "\"isn't\" : \"is not\",\n",
    "\"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\",\n",
    "\"i've\" : \"I have\",\n",
    "\"let's\" : \"let us\",\n",
    "\"mightn't\" : \"might not\",\n",
    "\"mustn't\" : \"must not\",\n",
    "\"shan't\" : \"shall not\",\n",
    "\"she'd\" : \"she would\",\n",
    "\"she'll\" : \"she will\",\n",
    "\"she's\" : \"she is\",\n",
    "\"shouldn't\" : \"should not\",\n",
    "\"shouldnt\" : \"should not\",\n",
    "\"that's\" : \"that is\",\n",
    "\"thats\" : \"that is\",\n",
    "\"there's\" : \"there is\",\n",
    "\"theres\" : \"there is\",\n",
    "\"they'd\" : \"they would\",\n",
    "\"they'll\" : \"they will\",\n",
    "\"they're\" : \"they are\",\n",
    "\"theyre\":  \"they are\",\n",
    "\"they've\" : \"they have\",\n",
    "\"we'd\" : \"we would\",\n",
    "\"we're\" : \"we are\",\n",
    "\"weren't\" : \"were not\",\n",
    "\"we've\" : \"we have\",\n",
    "\"what'll\" : \"what will\",\n",
    "\"what're\" : \"what are\",\n",
    "\"what's\" : \"what is\",\n",
    "\"what've\" : \"what have\",\n",
    "\"where's\" : \"where is\",\n",
    "\"who'd\" : \"who would\",\n",
    "\"who'll\" : \"who will\",\n",
    "\"who're\" : \"who are\",\n",
    "\"who's\" : \"who is\",\n",
    "\"who've\" : \"who have\",\n",
    "\"won't\" : \"will not\",\n",
    "\"wouldn't\" : \"would not\",\n",
    "\"you'd\" : \"you would\",\n",
    "\"you'll\" : \"you will\",\n",
    "\"you're\" : \"you are\",\n",
    "\"you've\" : \"you have\",\n",
    "\"'re\": \" are\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'll\":\" will\",\n",
    "\"didn't\": \"did not\",\n",
    "\"tryin'\":\"trying\"}\n",
    "\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x).replace(\"\\n\",\"\")\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_numbers(x):\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "\n",
    "    return mispellings_re.sub(replace, text)\n",
    "\n",
    "\n",
    "def clean_data(df, columns: list):\n",
    "    for col in columns:\n",
    "#         df[col] = df[col].apply(lambda x: clean_numbers(x))\n",
    "        df[col] = df[col].apply(lambda x: clean_text(x.lower()))\n",
    "        df[col] = df[col].apply(lambda x: replace_typical_misspell(x))\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = clean_data(train, input_columns)\n",
    "test = clean_data(test, input_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'after playing around with macro photography on - the - cheap  ( read :  reversed lens ,  rev .  lens mounted on a straight lens ,  passive extension tubes )  ,  i would like to get further with this .  the problems with the techniques i used is that focus is manual and aperture control is problematic at best .  this limited my setup to still subjects  ( read :  dead insects )  now ,  as spring is approaching ,  i want to be able to shoot live insects .  i believe that for this ,  autofocus and settable aperture will be of great help . so ,  one obvious but expensive option is a macro lens  ( say ,  ef 100mm macro )  however ,  i am not really interested in yet another prime lens .  an alternative is the electrical extension tubes . except for maximum focusing distance ,  what am i losing when using tubes  ( coupled with a fine lens ,  say ef70 - 200 / 2 . 8 )  instead of a macro lens ? '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['question_body'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructLabeledSentences(data):\n",
    "    sentences=[]\n",
    "    for index, row in data.iteritems():\n",
    "        sentences.append(TaggedDocument(utils.to_unicode(row).split(), ['Text' + '_%s' % str(index)]))\n",
    "    return sentences\n",
    "\n",
    "def textClean(text):\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = text.lower().split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops]    \n",
    "    text = \" \".join(text)\n",
    "    return(text)\n",
    "    \n",
    "def cleanup(text):\n",
    "    text = textClean(text)\n",
    "    text= text.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "    return text\n",
    "\n",
    "train_question_body_sentences = constructLabeledSentences(train['question_body'])\n",
    "train_question_title_sentences = constructLabeledSentences(train['question_title'])\n",
    "train_answer_sentences = constructLabeledSentences(train['answer'])\n",
    "\n",
    "test_question_body_sentences = constructLabeledSentences(test['question_body'])\n",
    "test_question_title_sentences = constructLabeledSentences(test['question_title'])\n",
    "test_answer_sentences = constructLabeledSentences(test['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "\n",
    "all_sentences = train_question_body_sentences + \\\n",
    "                train_answer_sentences + \\\n",
    "                test_question_body_sentences + \\\n",
    "                test_answer_sentences\n",
    "\n",
    "Text_INPUT_DIM=128\n",
    "text_model = Doc2Vec(min_count=1, window=5, vector_size=Text_INPUT_DIM, sample=1e-4, negative=5, workers=4, epochs=5,seed=1)\n",
    "text_model.build_vocab(all_sentences)\n",
    "text_model.train(all_sentences, total_examples=text_model.corpus_count, epochs=text_model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "def normalize_sentence(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in pos_tag(tokens):\n",
    "        if tag.startswith('NN') or tag.startswith('PRP'):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            continue\n",
    "            pos = 'a'\n",
    "        lemmatized_sentence.append(lemmatizer.lemmatize(word, pos).lower())\n",
    "    return lemmatized_sentence\n",
    "\n",
    "#print(set(normalize_sentence(word_tokenize(train['question_body'][0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_title\n",
      "question_body\n",
      "answer\n",
      "question_title\n",
      "question_body\n",
      "answer\n"
     ]
    }
   ],
   "source": [
    "def normalize_vectorize(df, columns: list):\n",
    "    for col in columns:\n",
    "        print(col)\n",
    "        df[col+'_norm'] = df[col].apply(lambda x: ' '.join(set(normalize_sentence(word_tokenize(x)))))\n",
    "        df[col+'_vec'] = df[col].apply(lambda x: text_model.infer_vector([x]))\n",
    "\n",
    "    return df\n",
    "\n",
    "train = normalize_vectorize(train, input_columns)\n",
    "test = normalize_vectorize(test, input_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load failed, build embedding\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6154ff1ca84a50849068a584829561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ce04d21ba847a9a09cdae75898d71f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c375c8e6f75f4c9a87d01a91f996c8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122b703ebac24dfb900bed603005d957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54794e5145b343ee8f2c8cffac1c2352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e70762a9d8954d6cbffdab1750ea410e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#bert embedings\n",
    "try:\n",
    "    pbe = load_obj(\"../input/questembeddings/precomputed_bert_embeddings\")\n",
    "    train_question_body_dense = pbe['train_question_body_dense']\n",
    "    train_answer_dense = pbe['train_answer_dense']\n",
    "    train_question_title_dense = pbe['train_question_title_dense']\n",
    "    test_question_body_dense = pbe['test_question_body_dense']\n",
    "    test_answer_dense = pbe['test_answer_dense']\n",
    "    test_question_title_dense = pbe['test_question_title_dense']\n",
    "except:\n",
    "    print(\"Load failed, build embedding\")\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "\n",
    "    def chunks(l, n):\n",
    "        \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "        for i in range(0, len(l), n):\n",
    "            yield l[i:i + n]\n",
    "\n",
    "    def fetch_vectors(string_list, batch_size=64):\n",
    "        # inspired by https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\n",
    "        DEVICE = torch.device(\"cuda\")\n",
    "        tokenizer = transformers.DistilBertTokenizer.from_pretrained(\"../input/distilbertbaseuncased/\")\n",
    "        model = transformers.DistilBertModel.from_pretrained(\"../input/distilbertbaseuncased/\")\n",
    "        model.to(DEVICE)\n",
    "\n",
    "        fin_features = []\n",
    "        for data in tqdm_notebook(chunks(string_list, batch_size)):\n",
    "            tokenized = []\n",
    "            for x in data:\n",
    "                x = \" \".join(x.strip().split()[:300])\n",
    "                tok = tokenizer.encode(x, add_special_tokens=True)\n",
    "                tokenized.append(tok[:512])\n",
    "\n",
    "            max_len = 512\n",
    "            padded = np.array([i + [0] * (max_len - len(i)) for i in tokenized], dtype='int64')\n",
    "            attention_mask = np.where(padded != 0, 1, 0)\n",
    "            input_ids = torch.tensor(padded).to(DEVICE)\n",
    "            attention_mask = torch.tensor(attention_mask).to(DEVICE)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            features = last_hidden_states[0][:, 0, :].cpu().numpy()\n",
    "            fin_features.append(features)\n",
    "\n",
    "        fin_features = np.vstack(fin_features)\n",
    "        return fin_features\n",
    "\n",
    "    train_question_body_dense = fetch_vectors(train.question_body.values)\n",
    "    train_answer_dense = fetch_vectors(train.answer.values)\n",
    "    train_question_title_dense = fetch_vectors(train.question_title.values)\n",
    "\n",
    "\n",
    "    test_question_body_dense = fetch_vectors(test.question_body.values)\n",
    "    test_answer_dense = fetch_vectors(test.answer.values)\n",
    "    test_question_title_dense = fetch_vectors(test.question_title.values)\n",
    "\n",
    "    precomputed_bert_embeddings = {\n",
    "        'train_question_body_dense': train_question_body_dense,\n",
    "        'train_answer_dense': train_answer_dense,\n",
    "        'train_question_title_dense': train_question_title_dense,\n",
    "        'test_question_body_dense': test_question_body_dense,\n",
    "        'test_answer_dense': test_answer_dense,\n",
    "        'test_question_title_dense': test_question_title_dense,\n",
    "\n",
    "    }\n",
    "\n",
    "    #save_obj(precomputed_bert_embeddings,\"../input/questembeddings/precomputed_bert_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1, 3))\n",
    "tsvd = TruncatedSVD(n_components = 128, n_iter=5)\n",
    "tfquestion_title = tfidf.fit_transform(train[\"question_title\"].values)\n",
    "tfquestion_title_test = tfidf.transform(test[\"question_title\"].values)\n",
    "tfquestion_title = tsvd.fit_transform(tfquestion_title)\n",
    "tfquestion_title_test = tsvd.transform(tfquestion_title_test)\n",
    "\n",
    "tfquestion_body = tfidf.fit_transform(train[\"question_body\"].values)\n",
    "tfquestion_body_test = tfidf.transform(test[\"question_body\"].values)\n",
    "tfquestion_body = tsvd.fit_transform(tfquestion_body)\n",
    "tfquestion_body_test = tsvd.transform(tfquestion_body_test)\n",
    "\n",
    "tfanswer = tfidf.fit_transform(train[\"answer\"].values)\n",
    "tfanswer_test = tfidf.transform(test[\"answer\"].values)\n",
    "tfanswer = tsvd.fit_transform(tfanswer)\n",
    "tfanswer_test = tsvd.transform(tfanswer_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() # release all gpu memory from pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load failed, build embedding\n",
      "question_title\n",
      "question_body\n",
      "answer\n"
     ]
    }
   ],
   "source": [
    "# universal sentence encoder\n",
    "\n",
    "try:\n",
    "    embeddings_train = load_obj(\"../input/questembeddings/use_embeddings_train\")\n",
    "    embeddings_test = load_obj(\"../input/questembeddings/use_embeddings_test\")\n",
    "except:\n",
    "    print(\"Load failed, build embedding\")\n",
    "    try:\n",
    "        module_url = INPUT_PATH+'universalsentenceencoderlarge4/'\n",
    "        embed = hub.load(module_url)\n",
    "        def UniversalEmbedding(x):\n",
    "            results = embed(tf.squeeze(tf.cast(x, tf.string)))[\"outputs\"]\n",
    "            return keras.backend.concatenate([results])\n",
    "    except:\n",
    "        module_url = INPUT_PATH+'universalsentenceencoderlarge3/'\n",
    "        embed = hub.Module(module_url)\n",
    "        def UniversalEmbedding(x):\n",
    "            results = embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n",
    "            return keras.backend.concatenate([results])\n",
    "\n",
    "    embeddings_train = {}\n",
    "    embeddings_test = {}\n",
    "    for text in input_columns:\n",
    "        print(text)\n",
    "        train_text = train[text].str.replace('?', '.').str.replace('!', '.').tolist()\n",
    "        test_text = test[text].str.replace('?', '.').str.replace('!', '.').tolist()\n",
    "\n",
    "        curr_train_emb = []\n",
    "        curr_test_emb = []\n",
    "        batch_size = 4\n",
    "        ind = 0\n",
    "        while ind*batch_size < len(train_text):\n",
    "            curr_train_emb.append(embed(train_text[ind*batch_size: (ind + 1)*batch_size])[\"outputs\"].numpy())\n",
    "            ind += 1\n",
    "\n",
    "        ind = 0\n",
    "        while ind*batch_size < len(test_text):\n",
    "            curr_test_emb.append(embed(test_text[ind*batch_size: (ind + 1)*batch_size])[\"outputs\"].numpy())\n",
    "            ind += 1    \n",
    "\n",
    "        embeddings_train[text + '_embedding'] = np.vstack(curr_train_emb)\n",
    "        embeddings_test[text + '_embedding'] = np.vstack(curr_test_emb)\n",
    "\n",
    "    del embed\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    #save_obj(embeddings_train,\"../input/questembeddings/use_embeddings_train\")\n",
    "    #save_obj(embeddings_test,\"../input/questembeddings/use_embeddings_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     40,
     51
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category 13\n",
      "netloc 16\n",
      "host 35\n",
      "category 13\n",
      "netloc 16\n",
      "question_user_name 30\n",
      "answer_user_name 30\n",
      "host 35\n"
     ]
    }
   ],
   "source": [
    "find = re.compile(r\"^[^.]*\")\n",
    "train['netloc'] = train['url'].apply(lambda x: re.findall(find, urlparse(x).netloc)[0])\n",
    "test['netloc'] = test['url'].apply(lambda x: re.findall(find, urlparse(x).netloc)[0])\n",
    "\n",
    "features_lrg = ['category', 'netloc', 'question_user_name','answer_user_name','host']\n",
    "features_sml = ['category', 'netloc', 'host']\n",
    "    \n",
    "features_train = []\n",
    "features_test = []\n",
    "for feature in features_sml:\n",
    "    merged = pd.concat([train[feature], test[feature]]).to_numpy().reshape(-1, 1).squeeze()\n",
    "    encoded_size = len(max(merged, key=len))\n",
    "    print(feature,encoded_size)\n",
    "    ctr = 0\n",
    "    column = []\n",
    "    for val in train[feature].values:\n",
    "        ctr +=1\n",
    "        output = np.zeros(encoded_size)\n",
    "        output[:len(val)] = [ord(i)/128. for i in val]\n",
    "        column.append(output)\n",
    "    features_train.append(column)\n",
    "        \n",
    "    column = []\n",
    "    for val in test[feature].values:\n",
    "        output = np.zeros(encoded_size)\n",
    "        output[:len(val)] = [ord(i)/128. for i in val]\n",
    "        column.append(output)\n",
    "    features_test.append(column)\n",
    "\n",
    "features_train_lrg = []\n",
    "features_test_lrg = []\n",
    "for feature in features_lrg:\n",
    "    merged = pd.concat([train[feature], test[feature]]).to_numpy().reshape(-1, 1).squeeze()\n",
    "    encoded_size = len(max(merged, key=len))\n",
    "    print(feature,encoded_size)\n",
    "    ctr = 0\n",
    "    column = []\n",
    "    for val in train[feature].values:\n",
    "        ctr +=1\n",
    "        output = np.zeros(encoded_size)\n",
    "        output[:len(val)] = [ord(i)/128. for i in val]\n",
    "        column.append(output)\n",
    "    features_train.append(column)\n",
    "        \n",
    "    column = []\n",
    "    for val in test[feature].values:\n",
    "        output = np.zeros(encoded_size)\n",
    "        output[:len(val)] = [ord(i)/128. for i in val]\n",
    "        column.append(output)\n",
    "    features_test.append(column)\n",
    "    \n",
    "    \n",
    "l2_dist = lambda x, y: np.power(x - y, 2).sum(axis=1)\n",
    "cos_dist = lambda x, y: (x*y).sum(axis=1)\n",
    "abs_dist = lambda x, y: np.abs(x-y).sum(axis=1)\n",
    "sum_dist = lambda x, y: (x+y).sum(axis=1)\n",
    "\n",
    "dist_features_train = np.array([\n",
    "    l2_dist(embeddings_train['question_title_embedding'], embeddings_train['answer_embedding']),\n",
    "    l2_dist(embeddings_train['question_body_embedding'], embeddings_train['answer_embedding']),\n",
    "    l2_dist(embeddings_train['question_body_embedding'], embeddings_train['question_title_embedding']),\n",
    "    l2_dist(np.array([x for x in train.question_body_vec.values]), np.array([x for x in train.answer_vec.values])),\n",
    "    l2_dist(np.array([x for x in train.question_title_vec.values]), np.array([x for x in train.answer_vec.values])),\n",
    "    l2_dist(np.array([x for x in train.question_body_vec.values]), np.array([x for x in train.question_title_vec.values])),\n",
    "    cos_dist(embeddings_train['question_title_embedding'], embeddings_train['answer_embedding']),\n",
    "    cos_dist(embeddings_train['question_body_embedding'], embeddings_train['answer_embedding']),\n",
    "    cos_dist(embeddings_train['question_body_embedding'], embeddings_train['question_title_embedding']),\n",
    "    cos_dist(np.array([x for x in train.question_body_vec.values]), np.array([x for x in train.answer_vec.values])),\n",
    "    cos_dist(np.array([x for x in train.question_title_vec.values]), np.array([x for x in train.answer_vec.values])),\n",
    "    cos_dist(np.array([x for x in train.question_body_vec.values]), np.array([x for x in train.question_title_vec.values])),\n",
    "    abs_dist(embeddings_train['question_title_embedding'], embeddings_train['answer_embedding']),\n",
    "    abs_dist(embeddings_train['question_body_embedding'], embeddings_train['answer_embedding']),\n",
    "    abs_dist(embeddings_train['question_body_embedding'], embeddings_train['question_title_embedding']),\n",
    "    abs_dist(np.array([x for x in train.question_body_vec.values]), np.array([x for x in train.answer_vec.values])),\n",
    "    abs_dist(np.array([x for x in train.question_title_vec.values]), np.array([x for x in train.answer_vec.values])),\n",
    "    abs_dist(np.array([x for x in train.question_body_vec.values]), np.array([x for x in train.question_title_vec.values])),\n",
    "    sum_dist(embeddings_train['question_title_embedding'], embeddings_train['answer_embedding']),\n",
    "    sum_dist(embeddings_train['question_body_embedding'], embeddings_train['answer_embedding']),\n",
    "    sum_dist(embeddings_train['question_body_embedding'], embeddings_train['question_title_embedding']),\n",
    "    sum_dist(np.array([x for x in train.question_body_vec.values]), np.array([x for x in train.answer_vec.values])),\n",
    "    sum_dist(np.array([x for x in train.question_title_vec.values]), np.array([x for x in train.answer_vec.values])),\n",
    "    sum_dist(np.array([x for x in train.question_body_vec.values]), np.array([x for x in train.question_title_vec.values])),\n",
    "    l2_dist(train_question_body_dense, train_answer_dense),\n",
    "    cos_dist(train_question_body_dense, train_answer_dense),\n",
    "    abs_dist(train_question_body_dense, train_answer_dense),\n",
    "    sum_dist(train_question_body_dense, train_answer_dense),\n",
    "    l2_dist(train_question_body_dense, train_question_title_dense),\n",
    "    cos_dist(train_question_body_dense, train_question_title_dense),\n",
    "    abs_dist(train_question_body_dense, train_question_title_dense),\n",
    "    sum_dist(train_question_body_dense, train_question_title_dense),\n",
    "    l2_dist(train_answer_dense, train_question_title_dense),\n",
    "    cos_dist(train_answer_dense, train_question_title_dense),\n",
    "    abs_dist(train_answer_dense, train_question_title_dense),\n",
    "    sum_dist(train_answer_dense, train_question_title_dense),\n",
    "]).T\n",
    "\n",
    "\n",
    "dist_features_test = np.array([\n",
    "    l2_dist(embeddings_test['question_title_embedding'], embeddings_test['answer_embedding']),\n",
    "    l2_dist(embeddings_test['question_body_embedding'], embeddings_test['answer_embedding']),\n",
    "    l2_dist(embeddings_test['question_body_embedding'], embeddings_test['question_title_embedding']),\n",
    "    l2_dist(np.array([x for x in test.question_body_vec.values]), np.array([x for x in test.answer_vec.values])),\n",
    "    l2_dist(np.array([x for x in test.question_title_vec.values]), np.array([x for x in test.answer_vec.values])),\n",
    "    l2_dist(np.array([x for x in test.question_body_vec.values]), np.array([x for x in test.question_title_vec.values])),\n",
    "    cos_dist(embeddings_test['question_title_embedding'], embeddings_test['answer_embedding']),\n",
    "    cos_dist(embeddings_test['question_body_embedding'], embeddings_test['answer_embedding']),\n",
    "    cos_dist(embeddings_test['question_body_embedding'], embeddings_test['question_title_embedding']),\n",
    "    cos_dist(np.array([x for x in test.question_body_vec.values]), np.array([x for x in test.answer_vec.values])),\n",
    "    cos_dist(np.array([x for x in test.question_title_vec.values]), np.array([x for x in test.answer_vec.values])),\n",
    "    cos_dist(np.array([x for x in test.question_body_vec.values]), np.array([x for x in test.question_title_vec.values])),\n",
    "    abs_dist(embeddings_test['question_title_embedding'], embeddings_test['answer_embedding']),\n",
    "    abs_dist(embeddings_test['question_body_embedding'], embeddings_test['answer_embedding']),\n",
    "    abs_dist(embeddings_test['question_body_embedding'], embeddings_test['question_title_embedding']),\n",
    "    abs_dist(np.array([x for x in test.question_body_vec.values]), np.array([x for x in test.answer_vec.values])),\n",
    "    abs_dist(np.array([x for x in test.question_title_vec.values]), np.array([x for x in test.answer_vec.values])),\n",
    "    abs_dist(np.array([x for x in test.question_body_vec.values]), np.array([x for x in test.question_title_vec.values])),\n",
    "    sum_dist(embeddings_test['question_title_embedding'], embeddings_test['answer_embedding']),\n",
    "    sum_dist(embeddings_test['question_body_embedding'], embeddings_test['answer_embedding']),\n",
    "    sum_dist(embeddings_test['question_body_embedding'], embeddings_test['question_title_embedding']),\n",
    "    sum_dist(np.array([x for x in test.question_body_vec.values]), np.array([x for x in test.answer_vec.values])),\n",
    "    sum_dist(np.array([x for x in test.question_title_vec.values]), np.array([x for x in test.answer_vec.values])),\n",
    "    sum_dist(np.array([x for x in test.question_body_vec.values]), np.array([x for x in test.question_title_vec.values])),\n",
    "    l2_dist(test_question_body_dense, test_answer_dense),\n",
    "    cos_dist(test_question_body_dense, test_answer_dense),\n",
    "    abs_dist(test_question_body_dense, test_answer_dense),\n",
    "    sum_dist(test_question_body_dense, test_answer_dense),\n",
    "    l2_dist(test_question_body_dense, test_question_title_dense),\n",
    "    cos_dist(test_question_body_dense, test_question_title_dense),\n",
    "    abs_dist(test_question_body_dense, test_question_title_dense),\n",
    "    sum_dist(test_question_body_dense, test_question_title_dense),\n",
    "    l2_dist(test_answer_dense, test_question_title_dense),\n",
    "    cos_dist(test_answer_dense, test_question_title_dense),\n",
    "    abs_dist(test_answer_dense, test_question_title_dense),\n",
    "    sum_dist(test_answer_dense, test_question_title_dense),\n",
    "]).T\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_features_train = [\n",
    "    [item for k, item in embeddings_train.items()],\n",
    "    features_train,\n",
    "    features_train_lrg,\n",
    "    [ dist_features_train ],\n",
    "    [ [x for x in train.question_body_vec.values] ],\n",
    "    [ [x for x in train.question_title_vec.values] ],\n",
    "    [ [x for x in train.answer_vec.values] ],\n",
    "    [ train_question_body_dense ],\n",
    "    [ train_answer_dense ],\n",
    "    [ tfquestion_title ],\n",
    "    [ tfquestion_body ],\n",
    "    [ tfanswer ]\n",
    "    \n",
    "]\n",
    "possible_features_test = [\n",
    "    [item for k, item in embeddings_test.items()],\n",
    "    features_test,\n",
    "    features_test_lrg,\n",
    "    [ dist_features_test ],\n",
    "    [ [x for x in test.question_body_vec.values] ],\n",
    "    [ [x for x in test.question_title_vec.values] ],\n",
    "    [ [x for x in test.answer_vec.values] ],\n",
    "    [ test_question_body_dense ],\n",
    "    [ test_answer_dense ],\n",
    "    [ tfquestion_title_test ],\n",
    "    [ tfquestion_body_test ],\n",
    "    [ tfanswer_test ]\n",
    "]\n",
    "\n",
    "def get_train_test(split=0.8):\n",
    "    total_len = len(possible_features_train)\n",
    "    r_idx = random.sample(range(total_len), int(total_len * split))\n",
    "    \n",
    "    train = [ train_question_title_dense ]\n",
    "\n",
    "    test =  [ test_question_title_dense ]\n",
    "\n",
    "    for i in r_idx:\n",
    "        train += possible_features_train[i]\n",
    "        test += possible_features_test[i]\n",
    "        \n",
    "    return np.hstack(train),np.hstack(test)\n",
    "\n",
    "X_train,X_test = get_train_test()\n",
    "y_train = train[targets].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import *\n",
    "def bce(t,p):\n",
    "    return binary_crossentropy(t,p)\n",
    "\n",
    "def custom_loss(true,pred):\n",
    "    bce = binary_crossentropy(true,pred)\n",
    "    return bce + logcosh(true,pred)\n",
    "\n",
    "def swish(x):\n",
    "    return K.sigmoid(x) * x\n",
    "\n",
    "def relu1(x):\n",
    "    return keras.activations.relu(x, alpha=0.0, max_value=1., threshold=0.0)\n",
    "\n",
    "def create_model1(X_train):\n",
    "    input1 = Input(shape=(X_train.shape[1],))\n",
    "    x = Dense(64, activation='elu',kernel_initializer='lecun_normal')(input1)\n",
    "    x = Dense(128, activation='elu',kernel_initializer='lecun_normal')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    output = Dense(len(targets),activation='sigmoid',name='output')(x)\n",
    "    model = Model(inputs=input1, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model2(X_train):\n",
    "    input1 = Input(shape=(X_train.shape[1],))\n",
    "    x = Dense(512, activation='elu',kernel_initializer='lecun_normal')(input1)\n",
    "    x = Dense(256, activation='elu',\n",
    "              kernel_initializer='lecun_normal', \n",
    "              #kernel_regularizer=keras.regularizers.l2(0.01)\n",
    "             )(x)\n",
    "    output = Dense(len(targets),activation='sigmoid',name='output')(x)\n",
    "    model = Model(inputs=input1, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model3(X_train):\n",
    "    input1 = Input(shape=(X_train.shape[1],))\n",
    "    x = Dense(200, activation='selu',kernel_initializer='lecun_normal')(input1)\n",
    "    x = Dense(512, activation='selu',\n",
    "              kernel_initializer='lecun_normal', \n",
    "              )(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    output = Dense(len(targets),activation='sigmoid',name='output')(x)\n",
    "    model = Model(inputs=input1, outputs=output)\n",
    "    return model\n",
    "\n",
    "def create_model4(X_train):\n",
    "    input1 = Input(shape=(X_train.shape[1],))\n",
    "    x = Dense(512, activation='elu',\n",
    "              kernel_initializer='lecun_normal', \n",
    "              )(input1)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(len(targets),activation='sigmoid',name='output')(x)\n",
    "    model = Model(inputs=input1, outputs=output)\n",
    "    return model\n",
    "\n",
    "def create_model5(X_train):\n",
    "    input1 = Input(shape=(X_train.shape[1],))\n",
    "    x = Dense(4096, activation='selu',kernel_initializer='lecun_normal')(input1)\n",
    "    x = Dense(512, activation='selu',\n",
    "              kernel_initializer='lecun_normal', \n",
    "              kernel_regularizer=keras.regularizers.l2(0.01)\n",
    "             )(x)\n",
    "    output = Dense(len(targets),activation='sigmoid',name='output')(x)\n",
    "    model = Model(inputs=input1, outputs=output)\n",
    "    return model\n",
    "\n",
    "def create_model(X_train):\n",
    "    model = random.choice([create_model1, create_model2, create_model3, create_model4, create_model5])(X_train)\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "print(gc.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_metric(y_true, y_pred):\n",
    "    y_true = K.clip(y_true, K.epsilon(), 1)\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
    "    # reshape stage\n",
    "#     y_true = K.reshape(y_true, shape=(-1, 224 * 224 * 3))\n",
    "#     y_pred = K.reshape(y_pred, shape=(-1, 224 * 224 * 3))\n",
    "    # normalizing stage - setting a 0 mean.\n",
    "    y_true -= K.mean(y_true)\n",
    "    y_pred -= K.mean(y_pred)\n",
    "    # normalizing stage - setting a 1 variance\n",
    "    y_true = K.l2_normalize(y_true, axis=-1)\n",
    "    y_pred = K.l2_normalize(y_pred, axis=-1)\n",
    "    # final result\n",
    "    pearson_correlation = K.sum(y_true * y_pred, axis=-1)\n",
    "    return 1-pearson_correlation\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Compatible with tensorflow backend\n",
    "error_pred_y = None\n",
    "error_y = None\n",
    "class SpearmanRhoCallback(Callback):\n",
    "    def __init__(self, training_data, validation_data, patience, model_name, reload=False):\n",
    "        global noise\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "        \n",
    "        self.patience = patience\n",
    "        self.value = -1\n",
    "        self.bad_epochs = 0\n",
    "        self.model_name = model_name\n",
    "        self.reload = reload\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        noise = np.random.normal(0, 1e-7, y_pred_val.shape[0])\n",
    "        rho_val = np.mean([spearmanr(self.y_val[:, ind] + noise, y_pred_val[:, ind] + noise).correlation for ind in range(y_pred_val.shape[1])])\n",
    "        print('\\r  val_spearman-rho: %s' % (str(round(rho_val, 4))), end=100*' '+'\\n')\n",
    "\n",
    "        if rho_val >= self.value:\n",
    "            self.model.save_weights(self.model_name)\n",
    "            self.value = rho_val\n",
    "        else:\n",
    "            self.model.load_weights(self.model_name)\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        global error_pred_y, error_y        \n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        noise = np.random.normal(0, 1e-7, y_pred_val.shape[0])\n",
    "        rho_val = np.mean([spearmanr(self.y_val[:, ind] + noise, y_pred_val[:, ind] + noise).correlation for ind in range(y_pred_val.shape[1])])\n",
    "        if np.isnan(rho_val):\n",
    "            print(\"Error\")\n",
    "            error_pred_y = y_pred_val\n",
    "            error_y = self.y_val\n",
    "            print(y_pred_val)\n",
    "            print(self.x_val)\n",
    "            print(self.y_val)\n",
    "            raise \"bogus error\"\n",
    "#         y_pred = self.model.predict(self.x)\n",
    "#         rho = np.mean([spearmanr(self.y[:, ind], y_pred[:, ind] + np.random.normal(0, 1e-7, y_pred.shape[0])).correlation for ind in range(y_pred.shape[1])])\n",
    "        if rho_val >= self.value:\n",
    "            self.model.save_weights(self.model_name)\n",
    "            self.value = rho_val\n",
    "        else:\n",
    "            self.bad_epochs += 1\n",
    "#         if self.bad_epochs >= self.patience:\n",
    "#             print(\"Epoch %05d: early stopping Threshold\" % epoch)\n",
    "#             self.model.stop_training = True\n",
    "        print('\\r  val_spearman-rho: %s' % (str(round(rho_val, 4))), end=100*' '+'\\n')\n",
    "#         print('\\rtrain_spearman-rho: %s' % (str(round(rho, 4))), end=100*' '+'\\n')\n",
    "        if self.reload:\n",
    "            print('  reload best: %s' % (str(round(self.value, 4))))\n",
    "            self.model.load_weights(self.model_name)\n",
    "        return rho_val\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "model_idx =0 \n",
    "def run_model():\n",
    "    global y_train,all_predictions, model_idx\n",
    "    X_train,X_test = get_train_test()\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                                  patience=7, min_lr=1e-6, verbose=1)\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss',\n",
    "                                  min_delta=0,\n",
    "                                  patience=15,\n",
    "                                  mode='auto')\n",
    "\n",
    "    kf = KFold(n_splits=5, random_state=random.randint(0,1000), shuffle=True)\n",
    "\n",
    "    for ind, (tr, val) in enumerate(kf.split(X_train)):\n",
    "        X_tr = X_train[tr]\n",
    "        y_tr = y_train[tr]\n",
    "        X_vl = X_train[val]\n",
    "        y_vl = y_train[val]\n",
    "        model_idx+=1\n",
    "        model = create_model(X_train)\n",
    "        optimizer = Adam(lr=5e-4,clipnorm=1.4)\n",
    "        model.compile(optimizer=optimizer, loss=custom_loss, metrics=[bce,logcosh])\n",
    "        model.fit(\n",
    "            X_tr, y_tr, \n",
    "            epochs=100, batch_size=64, \n",
    "            validation_data=(X_vl, y_vl), \n",
    "            verbose=True, \n",
    "            callbacks=[SpearmanRhoCallback(training_data=(X_tr, y_tr), \n",
    "                                           validation_data=(X_vl, y_vl),\n",
    "                                           patience=10, \n",
    "                                           model_name=f'best_model_batch{model_idx}.h5',\n",
    "                                           reload=True),\n",
    "                       reduce_lr,\n",
    "                       early_stop\n",
    "                      ]\n",
    "        )\n",
    "        optimizer = SGD(lr=0.01,clipnorm=1.1)\n",
    "        model.compile(optimizer=optimizer, loss=custom_loss, metrics=[bce,logcosh])\n",
    "        history = model.fit(\n",
    "            X_tr, y_tr, \n",
    "            epochs=50, batch_size=64, \n",
    "            validation_data=(X_vl, y_vl), \n",
    "            verbose=True, \n",
    "            callbacks=[SpearmanRhoCallback(training_data=(X_tr, y_tr), \n",
    "                                           validation_data=(X_vl, y_vl),\n",
    "                                           patience=10, \n",
    "                                           model_name=f'best_model_batch_sgd{model_idx}.h5'),\n",
    "                       reduce_lr,\n",
    "                       early_stop   \n",
    "                      ]\n",
    "        )\n",
    "        if min(history.history['val_bce']) < 0.375:\n",
    "            all_predictions.append(model.predict(X_test))\n",
    "\n",
    "    optimizer = Adam(lr=2e-4,clipnorm=1.9)\n",
    "    model.compile(optimizer=optimizer, loss=bce)\n",
    "    model.fit(\n",
    "        X_train, y_train, \n",
    "        epochs=30, batch_size=128, \n",
    "        validation_data=(X_train, y_train), \n",
    "        verbose=True, \n",
    "        callbacks=[SpearmanRhoCallback(training_data=(X_train, y_train), \n",
    "                                       validation_data=(X_train, y_train),\n",
    "                                       patience=10, \n",
    "                                       model_name=f'best_model_batchoverfit{model_idx}.h5',\n",
    "                                       reload=False),\n",
    "                   reduce_lr,\n",
    "                   early_stop\n",
    "                  ]\n",
    "    )\n",
    "    all_predictions.append(model.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3936)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               787400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               102912    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 905,702\n",
      "Trainable params: 905,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/100\n",
      "4863/4863 [==============================] - 1s 199us/step - loss: 0.6016 - bce: 0.5604 - logcosh: 0.0412 - val_loss: 0.4336 - val_bce: 0.4083 - val_logcosh: 0.0253\n",
      "  val_spearman-rho: 0.2393                                                                                                    \n",
      "  reload best: 0.2393\n",
      "Epoch 2/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.4553 - bce: 0.4270 - logcosh: 0.0283 - val_loss: 0.4224 - val_bce: 0.3987 - val_logcosh: 0.0237\n",
      "  val_spearman-rho: 0.2694                                                                                                    \n",
      "  reload best: 0.2694\n",
      "Epoch 3/100\n",
      "4863/4863 [==============================] - 1s 109us/step - loss: 0.4358 - bce: 0.4101 - logcosh: 0.0257 - val_loss: 0.4179 - val_bce: 0.3949 - val_logcosh: 0.0229\n",
      "  val_spearman-rho: 0.2855                                                                                                    \n",
      "  reload best: 0.2855\n",
      "Epoch 4/100\n",
      "4863/4863 [==============================] - 1s 107us/step - loss: 0.4239 - bce: 0.3999 - logcosh: 0.0240 - val_loss: 0.4112 - val_bce: 0.3891 - val_logcosh: 0.0222\n",
      "  val_spearman-rho: 0.2955                                                                                                    \n",
      "  reload best: 0.2955\n",
      "Epoch 5/100\n",
      "4863/4863 [==============================] - 0s 102us/step - loss: 0.4148 - bce: 0.3919 - logcosh: 0.0229 - val_loss: 0.4145 - val_bce: 0.3918 - val_logcosh: 0.0226\n",
      "  val_spearman-rho: 0.2995                                                                                                    \n",
      "  reload best: 0.2995\n",
      "Epoch 6/100\n",
      "4863/4863 [==============================] - 0s 102us/step - loss: 0.4084 - bce: 0.3864 - logcosh: 0.0220 - val_loss: 0.4103 - val_bce: 0.3884 - val_logcosh: 0.0219\n",
      "  val_spearman-rho: 0.2989                                                                                                    \n",
      "  reload best: 0.2995\n",
      "Epoch 7/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.4088 - bce: 0.3868 - logcosh: 0.0221 - val_loss: 0.4130 - val_bce: 0.3907 - val_logcosh: 0.0223\n",
      "  val_spearman-rho: 0.305                                                                                                    \n",
      "  reload best: 0.305\n",
      "Epoch 8/100\n",
      "4863/4863 [==============================] - 1s 103us/step - loss: 0.4042 - bce: 0.3827 - logcosh: 0.0215 - val_loss: 0.4170 - val_bce: 0.3943 - val_logcosh: 0.0227\n",
      "  val_spearman-rho: 0.3104                                                                                                    \n",
      "  reload best: 0.3104\n",
      "Epoch 9/100\n",
      "4863/4863 [==============================] - 1s 106us/step - loss: 0.4028 - bce: 0.3815 - logcosh: 0.0213 - val_loss: 0.4080 - val_bce: 0.3865 - val_logcosh: 0.0215\n",
      "  val_spearman-rho: 0.3228                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 10/100\n",
      "4863/4863 [==============================] - 0s 100us/step - loss: 0.3965 - bce: 0.3761 - logcosh: 0.0204 - val_loss: 0.4080 - val_bce: 0.3862 - val_logcosh: 0.0218\n",
      "  val_spearman-rho: 0.31                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 11/100\n",
      "4863/4863 [==============================] - 1s 114us/step - loss: 0.3972 - bce: 0.3766 - logcosh: 0.0206 - val_loss: 0.4058 - val_bce: 0.3843 - val_logcosh: 0.0215\n",
      "  val_spearman-rho: 0.3115                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 12/100\n",
      "4863/4863 [==============================] - 1s 104us/step - loss: 0.3969 - bce: 0.3764 - logcosh: 0.0205 - val_loss: 0.4122 - val_bce: 0.3902 - val_logcosh: 0.0220\n",
      "  val_spearman-rho: 0.3101                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 13/100\n",
      "4863/4863 [==============================] - 1s 106us/step - loss: 0.3965 - bce: 0.3761 - logcosh: 0.0204 - val_loss: 0.4089 - val_bce: 0.3872 - val_logcosh: 0.0217\n",
      "  val_spearman-rho: 0.3184                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 14/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.3961 - bce: 0.3757 - logcosh: 0.0203 - val_loss: 0.4069 - val_bce: 0.3856 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.31                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 15/100\n",
      "4863/4863 [==============================] - 0s 102us/step - loss: 0.3982 - bce: 0.3775 - logcosh: 0.0206 - val_loss: 0.4144 - val_bce: 0.3921 - val_logcosh: 0.0223\n",
      "  val_spearman-rho: 0.3147                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 16/100\n",
      "4863/4863 [==============================] - 1s 105us/step - loss: 0.3982 - bce: 0.3776 - logcosh: 0.0206 - val_loss: 0.4077 - val_bce: 0.3861 - val_logcosh: 0.0216\n",
      "  val_spearman-rho: 0.3105                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 17/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3970 - bce: 0.3765 - logcosh: 0.0205 - val_loss: 0.4074 - val_bce: 0.3858 - val_logcosh: 0.0216\n",
      "  val_spearman-rho: 0.3118                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 18/100\n",
      "4863/4863 [==============================] - 1s 107us/step - loss: 0.3968 - bce: 0.3764 - logcosh: 0.0204 - val_loss: 0.4110 - val_bce: 0.3892 - val_logcosh: 0.0218\n",
      "  val_spearman-rho: 0.3135                                                                                                    \n",
      "  reload best: 0.3228\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 19/100\n",
      "4863/4863 [==============================] - 1s 106us/step - loss: 0.3855 - bce: 0.3665 - logcosh: 0.0189 - val_loss: 0.4002 - val_bce: 0.3796 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3113                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 20/100\n",
      "4863/4863 [==============================] - 0s 100us/step - loss: 0.3859 - bce: 0.3669 - logcosh: 0.0190 - val_loss: 0.4004 - val_bce: 0.3798 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3108                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 21/100\n",
      "4863/4863 [==============================] - 1s 106us/step - loss: 0.3861 - bce: 0.3671 - logcosh: 0.0190 - val_loss: 0.3999 - val_bce: 0.3793 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3182                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 22/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3852 - bce: 0.3663 - logcosh: 0.0189 - val_loss: 0.4015 - val_bce: 0.3807 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3113                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 23/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.3858 - bce: 0.3668 - logcosh: 0.0189 - val_loss: 0.4003 - val_bce: 0.3797 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3057                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 24/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.3857 - bce: 0.3667 - logcosh: 0.0190 - val_loss: 0.3995 - val_bce: 0.3790 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3149                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 25/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.3860 - bce: 0.3670 - logcosh: 0.0190 - val_loss: 0.4009 - val_bce: 0.3800 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3187                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 26/100\n",
      "4863/4863 [==============================] - 1s 105us/step - loss: 0.3859 - bce: 0.3669 - logcosh: 0.0190 - val_loss: 0.4023 - val_bce: 0.3814 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3184                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 27/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3855 - bce: 0.3665 - logcosh: 0.0189 - val_loss: 0.3998 - val_bce: 0.3792 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3039                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 28/100\n",
      "4863/4863 [==============================] - 1s 108us/step - loss: 0.3854 - bce: 0.3665 - logcosh: 0.0189 - val_loss: 0.3996 - val_bce: 0.3790 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3131                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 29/100\n",
      "4863/4863 [==============================] - 1s 107us/step - loss: 0.3857 - bce: 0.3667 - logcosh: 0.0190 - val_loss: 0.4005 - val_bce: 0.3797 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3122                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 30/100\n",
      "4863/4863 [==============================] - 1s 105us/step - loss: 0.3853 - bce: 0.3663 - logcosh: 0.0189 - val_loss: 0.3995 - val_bce: 0.3789 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3106                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 31/100\n",
      "4863/4863 [==============================] - 1s 108us/step - loss: 0.3857 - bce: 0.3668 - logcosh: 0.0189 - val_loss: 0.3998 - val_bce: 0.3792 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3208                                                                                                    \n",
      "  reload best: 0.3228\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 5.000000237487257e-06.\n",
      "Epoch 32/100\n",
      "4863/4863 [==============================] - 1s 107us/step - loss: 0.3869 - bce: 0.3678 - logcosh: 0.0191 - val_loss: 0.3995 - val_bce: 0.3790 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3142                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 33/100\n",
      "4863/4863 [==============================] - 1s 105us/step - loss: 0.3862 - bce: 0.3672 - logcosh: 0.0190 - val_loss: 0.3996 - val_bce: 0.3790 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3147                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 34/100\n",
      "4863/4863 [==============================] - 1s 111us/step - loss: 0.3866 - bce: 0.3676 - logcosh: 0.0191 - val_loss: 0.3995 - val_bce: 0.3790 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3119                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 35/100\n",
      "4863/4863 [==============================] - 1s 103us/step - loss: 0.3874 - bce: 0.3682 - logcosh: 0.0192 - val_loss: 0.3997 - val_bce: 0.3792 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3026                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 36/100\n",
      "4863/4863 [==============================] - 1s 112us/step - loss: 0.3865 - bce: 0.3675 - logcosh: 0.0190 - val_loss: 0.3997 - val_bce: 0.3792 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3083                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 37/100\n",
      "4863/4863 [==============================] - 1s 106us/step - loss: 0.3870 - bce: 0.3679 - logcosh: 0.0191 - val_loss: 0.3994 - val_bce: 0.3789 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3104                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 38/100\n",
      "4863/4863 [==============================] - 1s 108us/step - loss: 0.3869 - bce: 0.3678 - logcosh: 0.0191 - val_loss: 0.3995 - val_bce: 0.3790 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3094                                                                                                    \n",
      "  reload best: 0.3228\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 39/100\n",
      "4863/4863 [==============================] - 1s 103us/step - loss: 0.3897 - bce: 0.3703 - logcosh: 0.0194 - val_loss: 0.4011 - val_bce: 0.3804 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3046                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 40/100\n",
      "4863/4863 [==============================] - 1s 106us/step - loss: 0.3895 - bce: 0.3701 - logcosh: 0.0194 - val_loss: 0.4009 - val_bce: 0.3802 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3129                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 41/100\n",
      "4863/4863 [==============================] - 1s 112us/step - loss: 0.3900 - bce: 0.3706 - logcosh: 0.0195 - val_loss: 0.4009 - val_bce: 0.3803 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3028                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 42/100\n",
      "4863/4863 [==============================] - 1s 105us/step - loss: 0.3898 - bce: 0.3704 - logcosh: 0.0194 - val_loss: 0.4010 - val_bce: 0.3803 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3126                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 43/100\n",
      "4863/4863 [==============================] - 1s 111us/step - loss: 0.3900 - bce: 0.3705 - logcosh: 0.0195 - val_loss: 0.4010 - val_bce: 0.3803 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.315                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 44/100\n",
      "4863/4863 [==============================] - 1s 108us/step - loss: 0.3900 - bce: 0.3705 - logcosh: 0.0195 - val_loss: 0.4010 - val_bce: 0.3804 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3068                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 45/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.3897 - bce: 0.3703 - logcosh: 0.0194 - val_loss: 0.4010 - val_bce: 0.3804 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3136                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 46/100\n",
      "4863/4863 [==============================] - 1s 106us/step - loss: 0.3896 - bce: 0.3702 - logcosh: 0.0194 - val_loss: 0.4010 - val_bce: 0.3804 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.311                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 47/100\n",
      "4863/4863 [==============================] - 1s 105us/step - loss: 0.3897 - bce: 0.3702 - logcosh: 0.0194 - val_loss: 0.4011 - val_bce: 0.3804 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.312                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 48/100\n",
      "4863/4863 [==============================] - 0s 103us/step - loss: 0.3896 - bce: 0.3702 - logcosh: 0.0194 - val_loss: 0.4010 - val_bce: 0.3804 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3138                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 49/100\n",
      "4863/4863 [==============================] - 0s 102us/step - loss: 0.3899 - bce: 0.3704 - logcosh: 0.0195 - val_loss: 0.4011 - val_bce: 0.3804 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3058                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 50/100\n",
      "4863/4863 [==============================] - 1s 105us/step - loss: 0.3899 - bce: 0.3704 - logcosh: 0.0194 - val_loss: 0.4010 - val_bce: 0.3803 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3087                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 51/100\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.3900 - bce: 0.3705 - logcosh: 0.0195 - val_loss: 0.4011 - val_bce: 0.3804 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.301                                                                                                    \n",
      "  reload best: 0.3228\n",
      "Epoch 52/100\n",
      "4863/4863 [==============================] - 1s 106us/step - loss: 0.3898 - bce: 0.3704 - logcosh: 0.0195 - val_loss: 0.4011 - val_bce: 0.3804 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3118                                                                                                    \n",
      "  reload best: 0.3228\n",
      "  val_spearman-rho: 0.305                                                                                                    \n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/50\n",
      "4863/4863 [==============================] - 1s 173us/step - loss: 0.4250 - bce: 0.4006 - logcosh: 0.0244 - val_loss: 0.4308 - val_bce: 0.4062 - val_logcosh: 0.0246\n",
      "  val_spearman-rho: 0.3084                                                                                                    \n",
      "Epoch 2/50\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.4230 - bce: 0.3989 - logcosh: 0.0241 - val_loss: 0.4291 - val_bce: 0.4049 - val_logcosh: 0.0242\n",
      "  val_spearman-rho: 0.309                                                                                                    \n",
      "Epoch 3/50\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.4221 - bce: 0.3982 - logcosh: 0.0239 - val_loss: 0.4349 - val_bce: 0.4100 - val_logcosh: 0.0249\n",
      "  val_spearman-rho: 0.3141                                                                                                    \n",
      "Epoch 4/50\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.4207 - bce: 0.3969 - logcosh: 0.0238 - val_loss: 0.4281 - val_bce: 0.4042 - val_logcosh: 0.0239\n",
      "  val_spearman-rho: 0.3073                                                                                                    \n",
      "Epoch 5/50\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.4215 - bce: 0.3976 - logcosh: 0.0239 - val_loss: 0.4259 - val_bce: 0.4025 - val_logcosh: 0.0234\n",
      "  val_spearman-rho: 0.307                                                                                                    \n",
      "Epoch 6/50\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.4212 - bce: 0.3974 - logcosh: 0.0238 - val_loss: 0.4351 - val_bce: 0.4103 - val_logcosh: 0.0248\n",
      "  val_spearman-rho: 0.3066                                                                                                    \n",
      "Epoch 7/50\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.4203 - bce: 0.3965 - logcosh: 0.0238 - val_loss: 0.4259 - val_bce: 0.4020 - val_logcosh: 0.0239\n",
      "  val_spearman-rho: 0.3081                                                                                                    \n",
      "Epoch 8/50\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.4205 - bce: 0.3967 - logcosh: 0.0238 - val_loss: 0.4251 - val_bce: 0.4015 - val_logcosh: 0.0236\n",
      "  val_spearman-rho: 0.2999                                                                                                    \n",
      "Epoch 9/50\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.4199 - bce: 0.3962 - logcosh: 0.0237 - val_loss: 0.4246 - val_bce: 0.4011 - val_logcosh: 0.0235\n",
      "  val_spearman-rho: 0.3067                                                                                                    \n",
      "Epoch 10/50\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.4194 - bce: 0.3958 - logcosh: 0.0236 - val_loss: 0.4319 - val_bce: 0.4077 - val_logcosh: 0.0243\n",
      "  val_spearman-rho: 0.3163                                                                                                    \n",
      "Epoch 11/50\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.4191 - bce: 0.3956 - logcosh: 0.0236 - val_loss: 0.4235 - val_bce: 0.4002 - val_logcosh: 0.0233\n",
      "  val_spearman-rho: 0.3084                                                                                                    \n",
      "Epoch 12/50\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.4182 - bce: 0.3947 - logcosh: 0.0235 - val_loss: 0.4241 - val_bce: 0.4006 - val_logcosh: 0.0235\n",
      "  val_spearman-rho: 0.3145                                                                                                    \n",
      "Epoch 13/50\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.4180 - bce: 0.3946 - logcosh: 0.0234 - val_loss: 0.4297 - val_bce: 0.4052 - val_logcosh: 0.0245\n",
      "  val_spearman-rho: 0.3109                                                                                                    \n",
      "Epoch 14/50\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.4169 - bce: 0.3936 - logcosh: 0.0233 - val_loss: 0.4270 - val_bce: 0.4031 - val_logcosh: 0.0239\n",
      "  val_spearman-rho: 0.2999                                                                                                    \n",
      "Epoch 15/50\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.4170 - bce: 0.3937 - logcosh: 0.0233 - val_loss: 0.4266 - val_bce: 0.4026 - val_logcosh: 0.0240\n",
      "  val_spearman-rho: 0.3096                                                                                                    \n",
      "Epoch 16/50\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.4173 - bce: 0.3940 - logcosh: 0.0233 - val_loss: 0.4206 - val_bce: 0.3975 - val_logcosh: 0.0231\n",
      "  val_spearman-rho: 0.3046                                                                                                    \n",
      "Epoch 17/50\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.4173 - bce: 0.3939 - logcosh: 0.0234 - val_loss: 0.4295 - val_bce: 0.4051 - val_logcosh: 0.0244\n",
      "  val_spearman-rho: 0.3125                                                                                                    \n",
      "Epoch 18/50\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.4154 - bce: 0.3922 - logcosh: 0.0231 - val_loss: 0.4287 - val_bce: 0.4045 - val_logcosh: 0.0242\n",
      "  val_spearman-rho: 0.3061                                                                                                    \n",
      "Epoch 19/50\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.4162 - bce: 0.3930 - logcosh: 0.0232 - val_loss: 0.4318 - val_bce: 0.4070 - val_logcosh: 0.0248\n",
      "  val_spearman-rho: 0.3068                                                                                                    \n",
      "Epoch 20/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.4155 - bce: 0.3924 - logcosh: 0.0231 - val_loss: 0.4240 - val_bce: 0.4001 - val_logcosh: 0.0240\n",
      "  val_spearman-rho: 0.3111                                                                                                    \n",
      "Epoch 21/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.4148 - bce: 0.3917 - logcosh: 0.0231 - val_loss: 0.4259 - val_bce: 0.4019 - val_logcosh: 0.0240\n",
      "  val_spearman-rho: 0.3146                                                                                                    \n",
      "Epoch 22/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.4150 - bce: 0.3920 - logcosh: 0.0231 - val_loss: 0.4263 - val_bce: 0.4022 - val_logcosh: 0.0241\n",
      "  val_spearman-rho: 0.3145                                                                                                    \n",
      "Epoch 23/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.4144 - bce: 0.3915 - logcosh: 0.0229 - val_loss: 0.4291 - val_bce: 0.4048 - val_logcosh: 0.0243\n",
      "  val_spearman-rho: 0.311                                                                                                    \n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 24/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3858 - bce: 0.3668 - logcosh: 0.0190 - val_loss: 0.4012 - val_bce: 0.3805 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3154                                                                                                    \n",
      "Epoch 25/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3843 - bce: 0.3655 - logcosh: 0.0188 - val_loss: 0.4000 - val_bce: 0.3793 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3115                                                                                                    \n",
      "Epoch 26/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3844 - bce: 0.3656 - logcosh: 0.0188 - val_loss: 0.3997 - val_bce: 0.3790 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3087                                                                                                    \n",
      "Epoch 27/50\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3843 - bce: 0.3655 - logcosh: 0.0188 - val_loss: 0.4002 - val_bce: 0.3795 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.313                                                                                                    \n",
      "Epoch 28/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3843 - bce: 0.3655 - logcosh: 0.0188 - val_loss: 0.4003 - val_bce: 0.3796 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3149                                                                                                    \n",
      "Epoch 29/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3839 - bce: 0.3652 - logcosh: 0.0187 - val_loss: 0.3995 - val_bce: 0.3789 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3073                                                                                                    \n",
      "Epoch 30/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3843 - bce: 0.3655 - logcosh: 0.0188 - val_loss: 0.3995 - val_bce: 0.3789 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3126                                                                                                    \n",
      "Epoch 31/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3838 - bce: 0.3651 - logcosh: 0.0187 - val_loss: 0.3998 - val_bce: 0.3792 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3165                                                                                                    \n",
      "Epoch 32/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3840 - bce: 0.3652 - logcosh: 0.0187 - val_loss: 0.4001 - val_bce: 0.3795 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3127                                                                                                    \n",
      "Epoch 33/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3839 - bce: 0.3652 - logcosh: 0.0187 - val_loss: 0.3993 - val_bce: 0.3788 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3098                                                                                                    \n",
      "Epoch 34/50\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.3838 - bce: 0.3651 - logcosh: 0.0187 - val_loss: 0.4003 - val_bce: 0.3796 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3097                                                                                                    \n",
      "Epoch 35/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3838 - bce: 0.3651 - logcosh: 0.0187 - val_loss: 0.4001 - val_bce: 0.3795 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3107                                                                                                    \n",
      "Epoch 36/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3843 - bce: 0.3655 - logcosh: 0.0188 - val_loss: 0.3996 - val_bce: 0.3790 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3145                                                                                                    \n",
      "Epoch 37/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3838 - bce: 0.3651 - logcosh: 0.0187 - val_loss: 0.4000 - val_bce: 0.3793 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3109                                                                                                    \n",
      "Epoch 38/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3839 - bce: 0.3652 - logcosh: 0.0187 - val_loss: 0.3999 - val_bce: 0.3793 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3144                                                                                                    \n",
      "Epoch 39/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3834 - bce: 0.3647 - logcosh: 0.0187 - val_loss: 0.4006 - val_bce: 0.3799 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3089                                                                                                    \n",
      "Epoch 40/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3839 - bce: 0.3652 - logcosh: 0.0187 - val_loss: 0.3994 - val_bce: 0.3788 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3102                                                                                                    \n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 41/50\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.3831 - bce: 0.3645 - logcosh: 0.0186 - val_loss: 0.3992 - val_bce: 0.3787 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3164                                                                                                    \n",
      "Epoch 42/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3830 - bce: 0.3644 - logcosh: 0.0186 - val_loss: 0.3992 - val_bce: 0.3786 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3173                                                                                                    \n",
      "Epoch 43/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3834 - bce: 0.3647 - logcosh: 0.0187 - val_loss: 0.3993 - val_bce: 0.3788 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3187                                                                                                    \n",
      "Epoch 44/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3829 - bce: 0.3644 - logcosh: 0.0186 - val_loss: 0.3992 - val_bce: 0.3787 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3087                                                                                                    \n",
      "Epoch 45/50\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.3826 - bce: 0.3640 - logcosh: 0.0186 - val_loss: 0.3992 - val_bce: 0.3787 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3005                                                                                                    \n",
      "Epoch 46/50\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3830 - bce: 0.3644 - logcosh: 0.0186 - val_loss: 0.3992 - val_bce: 0.3786 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3089                                                                                                    \n",
      "Epoch 47/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3828 - bce: 0.3643 - logcosh: 0.0186 - val_loss: 0.3991 - val_bce: 0.3786 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3121                                                                                                    \n",
      "Epoch 48/50\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.3829 - bce: 0.3643 - logcosh: 0.0186 - val_loss: 0.3993 - val_bce: 0.3787 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3117                                                                                                    \n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 49/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3826 - bce: 0.3641 - logcosh: 0.0185 - val_loss: 0.3992 - val_bce: 0.3787 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.314                                                                                                    \n",
      "Epoch 50/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3830 - bce: 0.3644 - logcosh: 0.0186 - val_loss: 0.3992 - val_bce: 0.3787 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3106                                                                                                    \n",
      "  val_spearman-rho: 0.314                                                                                                    \n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 3936)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               2015744   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 2,031,134\n",
      "Trainable params: 2,031,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/100\n",
      "4863/4863 [==============================] - 1s 164us/step - loss: 0.5826 - bce: 0.5446 - logcosh: 0.0380 - val_loss: 0.4212 - val_bce: 0.3973 - val_logcosh: 0.0239\n",
      "  val_spearman-rho: 0.2494                                                                                                    \n",
      "  reload best: 0.2494\n",
      "Epoch 2/100\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.4355 - bce: 0.4097 - logcosh: 0.0258 - val_loss: 0.4105 - val_bce: 0.3880 - val_logcosh: 0.0225\n",
      "  val_spearman-rho: 0.2863                                                                                                    \n",
      "  reload best: 0.2863\n",
      "Epoch 3/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.4236 - bce: 0.3995 - logcosh: 0.0241 - val_loss: 0.4028 - val_bce: 0.3815 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.2984                                                                                                    \n",
      "  reload best: 0.2984\n",
      "Epoch 4/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.4144 - bce: 0.3916 - logcosh: 0.0228 - val_loss: 0.3995 - val_bce: 0.3786 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3066                                                                                                    \n",
      "  reload best: 0.3066\n",
      "Epoch 5/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.4074 - bce: 0.3855 - logcosh: 0.0219 - val_loss: 0.4001 - val_bce: 0.3792 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3133                                                                                                    \n",
      "  reload best: 0.3133\n",
      "Epoch 6/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.4039 - bce: 0.3826 - logcosh: 0.0213 - val_loss: 0.3967 - val_bce: 0.3763 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.318                                                                                                    \n",
      "  reload best: 0.318\n",
      "Epoch 7/100\n",
      "4863/4863 [==============================] - 0s 102us/step - loss: 0.3990 - bce: 0.3783 - logcosh: 0.0207 - val_loss: 0.3981 - val_bce: 0.3774 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3093                                                                                                    \n",
      "  reload best: 0.318\n",
      "Epoch 8/100\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.3984 - bce: 0.3778 - logcosh: 0.0206 - val_loss: 0.3968 - val_bce: 0.3763 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3188                                                                                                    \n",
      "  reload best: 0.3188\n",
      "Epoch 9/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3949 - bce: 0.3747 - logcosh: 0.0202 - val_loss: 0.3991 - val_bce: 0.3783 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3285                                                                                                    \n",
      "  reload best: 0.3285\n",
      "Epoch 10/100\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.3909 - bce: 0.3713 - logcosh: 0.0196 - val_loss: 0.3964 - val_bce: 0.3760 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.3161                                                                                                    \n",
      "  reload best: 0.3285\n",
      "Epoch 11/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3917 - bce: 0.3720 - logcosh: 0.0197 - val_loss: 0.4015 - val_bce: 0.3804 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3174                                                                                                    \n",
      "  reload best: 0.3285\n",
      "Epoch 12/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3917 - bce: 0.3719 - logcosh: 0.0198 - val_loss: 0.3961 - val_bce: 0.3757 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3165                                                                                                    \n",
      "  reload best: 0.3285\n",
      "Epoch 13/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3918 - bce: 0.3721 - logcosh: 0.0197 - val_loss: 0.3947 - val_bce: 0.3746 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3104                                                                                                    \n",
      "  reload best: 0.3285\n",
      "Epoch 14/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3911 - bce: 0.3714 - logcosh: 0.0197 - val_loss: 0.4006 - val_bce: 0.3794 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3177                                                                                                    \n",
      "  reload best: 0.3285\n",
      "Epoch 15/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3908 - bce: 0.3713 - logcosh: 0.0196 - val_loss: 0.3984 - val_bce: 0.3778 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3192                                                                                                    \n",
      "  reload best: 0.3285\n",
      "Epoch 16/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3906 - bce: 0.3710 - logcosh: 0.0196 - val_loss: 0.3962 - val_bce: 0.3758 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3204                                                                                                    \n",
      "  reload best: 0.3285\n",
      "Epoch 17/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3906 - bce: 0.3710 - logcosh: 0.0196 - val_loss: 0.3967 - val_bce: 0.3761 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3218                                                                                                    \n",
      "  reload best: 0.3285\n",
      "Epoch 18/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3900 - bce: 0.3705 - logcosh: 0.0195 - val_loss: 0.3995 - val_bce: 0.3786 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3144                                                                                                    \n",
      "  reload best: 0.3285\n",
      "Epoch 19/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3905 - bce: 0.3709 - logcosh: 0.0195 - val_loss: 0.4009 - val_bce: 0.3801 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3177                                                                                                    \n",
      "  reload best: 0.3285\n",
      "Epoch 20/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3913 - bce: 0.3717 - logcosh: 0.0196 - val_loss: 0.3982 - val_bce: 0.3777 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.318                                                                                                    \n",
      "  reload best: 0.3285\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 21/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3830 - bce: 0.3645 - logcosh: 0.0185 - val_loss: 0.3912 - val_bce: 0.3715 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3246                                                                                                    \n",
      "  reload best: 0.3285\n",
      "Epoch 22/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3824 - bce: 0.3639 - logcosh: 0.0185 - val_loss: 0.3916 - val_bce: 0.3718 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.328                                                                                                    \n",
      "  reload best: 0.3285\n",
      "Epoch 23/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3831 - bce: 0.3645 - logcosh: 0.0186 - val_loss: 0.3912 - val_bce: 0.3715 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.321                                                                                                    \n",
      "  reload best: 0.3285\n",
      "Epoch 24/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3825 - bce: 0.3640 - logcosh: 0.0185 - val_loss: 0.3907 - val_bce: 0.3710 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3247                                                                                                    \n",
      "  reload best: 0.3285\n",
      "Epoch 25/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3825 - bce: 0.3640 - logcosh: 0.0185 - val_loss: 0.3910 - val_bce: 0.3712 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3311                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 26/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3799 - bce: 0.3618 - logcosh: 0.0181 - val_loss: 0.3901 - val_bce: 0.3705 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.326                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 27/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3799 - bce: 0.3618 - logcosh: 0.0181 - val_loss: 0.3906 - val_bce: 0.3709 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.318                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 28/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3798 - bce: 0.3617 - logcosh: 0.0181 - val_loss: 0.3907 - val_bce: 0.3711 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3077                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 29/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3804 - bce: 0.3623 - logcosh: 0.0182 - val_loss: 0.3904 - val_bce: 0.3707 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3224                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 30/100\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.3802 - bce: 0.3621 - logcosh: 0.0182 - val_loss: 0.3903 - val_bce: 0.3707 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3194                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 31/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3804 - bce: 0.3622 - logcosh: 0.0182 - val_loss: 0.3915 - val_bce: 0.3717 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3243                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 32/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3800 - bce: 0.3618 - logcosh: 0.0181 - val_loss: 0.3910 - val_bce: 0.3713 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3307                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 33/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3793 - bce: 0.3613 - logcosh: 0.0181 - val_loss: 0.3902 - val_bce: 0.3706 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3279                                                                                                    \n",
      "  reload best: 0.3311\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 5.000000237487257e-06.\n",
      "Epoch 34/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3793 - bce: 0.3613 - logcosh: 0.0180 - val_loss: 0.3899 - val_bce: 0.3703 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3159                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 35/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3788 - bce: 0.3608 - logcosh: 0.0180 - val_loss: 0.3899 - val_bce: 0.3703 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.328                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 36/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3794 - bce: 0.3613 - logcosh: 0.0180 - val_loss: 0.3901 - val_bce: 0.3705 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3288                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 37/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3790 - bce: 0.3610 - logcosh: 0.0180 - val_loss: 0.3899 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3203                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 38/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3798 - bce: 0.3617 - logcosh: 0.0181 - val_loss: 0.3900 - val_bce: 0.3705 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3236                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 39/100\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.3796 - bce: 0.3615 - logcosh: 0.0181 - val_loss: 0.3900 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3231                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 40/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3794 - bce: 0.3614 - logcosh: 0.0181 - val_loss: 0.3900 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3159                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 41/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3790 - bce: 0.3610 - logcosh: 0.0180 - val_loss: 0.3900 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3247                                                                                                    \n",
      "  reload best: 0.3311\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 42/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3793 - bce: 0.3612 - logcosh: 0.0181 - val_loss: 0.3899 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3322                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 43/100\n",
      "4863/4863 [==============================] - 0s 102us/step - loss: 0.3790 - bce: 0.3610 - logcosh: 0.0180 - val_loss: 0.3899 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3234                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 44/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3791 - bce: 0.3611 - logcosh: 0.0180 - val_loss: 0.3899 - val_bce: 0.3703 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.327                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 45/100\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3785 - bce: 0.3606 - logcosh: 0.0179 - val_loss: 0.3899 - val_bce: 0.3703 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3244                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 46/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3789 - bce: 0.3609 - logcosh: 0.0180 - val_loss: 0.3899 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3255                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 47/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3787 - bce: 0.3607 - logcosh: 0.0179 - val_loss: 0.3899 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3195                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 48/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3792 - bce: 0.3612 - logcosh: 0.0180 - val_loss: 0.3899 - val_bce: 0.3703 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3259                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 49/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3788 - bce: 0.3609 - logcosh: 0.0180 - val_loss: 0.3899 - val_bce: 0.3703 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3225                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 50/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3787 - bce: 0.3608 - logcosh: 0.0180 - val_loss: 0.3899 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3287                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 51/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3789 - bce: 0.3609 - logcosh: 0.0180 - val_loss: 0.3899 - val_bce: 0.3703 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3201                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 52/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3788 - bce: 0.3608 - logcosh: 0.0179 - val_loss: 0.3899 - val_bce: 0.3703 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3216                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 53/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3792 - bce: 0.3612 - logcosh: 0.0180 - val_loss: 0.3899 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3205                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 54/100\n",
      "4863/4863 [==============================] - 0s 102us/step - loss: 0.3788 - bce: 0.3609 - logcosh: 0.0180 - val_loss: 0.3899 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.318                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 55/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3791 - bce: 0.3611 - logcosh: 0.0180 - val_loss: 0.3899 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3263                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 56/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3788 - bce: 0.3608 - logcosh: 0.0180 - val_loss: 0.3899 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3186                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 57/100\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.3786 - bce: 0.3607 - logcosh: 0.0179 - val_loss: 0.3899 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3219                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 58/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3791 - bce: 0.3610 - logcosh: 0.0180 - val_loss: 0.3899 - val_bce: 0.3703 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3259                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 59/100\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3792 - bce: 0.3612 - logcosh: 0.0180 - val_loss: 0.3899 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3262                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 60/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3792 - bce: 0.3612 - logcosh: 0.0180 - val_loss: 0.3899 - val_bce: 0.3703 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3288                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 61/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3790 - bce: 0.3610 - logcosh: 0.0180 - val_loss: 0.3899 - val_bce: 0.3703 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.323                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 62/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3788 - bce: 0.3608 - logcosh: 0.0179 - val_loss: 0.3899 - val_bce: 0.3703 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3213                                                                                                    \n",
      "  reload best: 0.3322\n",
      "Epoch 63/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3788 - bce: 0.3608 - logcosh: 0.0180 - val_loss: 0.3899 - val_bce: 0.3703 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3187                                                                                                    \n",
      "  reload best: 0.3322\n",
      "  val_spearman-rho: 0.3275                                                                                                    \n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/50\n",
      "4863/4863 [==============================] - 1s 140us/step - loss: 0.3863 - bce: 0.3672 - logcosh: 0.0190 - val_loss: 0.3966 - val_bce: 0.3762 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.3253                                                                                                    \n",
      "Epoch 2/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3877 - bce: 0.3685 - logcosh: 0.0192 - val_loss: 0.3982 - val_bce: 0.3774 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3187                                                                                                    \n",
      "Epoch 3/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3866 - bce: 0.3674 - logcosh: 0.0191 - val_loss: 0.4012 - val_bce: 0.3800 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.3241                                                                                                    \n",
      "Epoch 4/50\n",
      "4863/4863 [==============================] - 0s 81us/step - loss: 0.3872 - bce: 0.3680 - logcosh: 0.0192 - val_loss: 0.3980 - val_bce: 0.3772 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3258                                                                                                    \n",
      "Epoch 5/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3872 - bce: 0.3680 - logcosh: 0.0192 - val_loss: 0.3954 - val_bce: 0.3752 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3179                                                                                                    \n",
      "Epoch 6/50\n",
      "4863/4863 [==============================] - 0s 81us/step - loss: 0.3871 - bce: 0.3679 - logcosh: 0.0192 - val_loss: 0.3965 - val_bce: 0.3759 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3275                                                                                                    \n",
      "Epoch 7/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3871 - bce: 0.3679 - logcosh: 0.0192 - val_loss: 0.3997 - val_bce: 0.3788 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3217                                                                                                    \n",
      "Epoch 8/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3866 - bce: 0.3675 - logcosh: 0.0191 - val_loss: 0.3965 - val_bce: 0.3761 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3211                                                                                                    \n",
      "Epoch 9/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3862 - bce: 0.3671 - logcosh: 0.0191 - val_loss: 0.4067 - val_bce: 0.3846 - val_logcosh: 0.0220\n",
      "  val_spearman-rho: 0.3216                                                                                                    \n",
      "Epoch 10/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3866 - bce: 0.3675 - logcosh: 0.0191 - val_loss: 0.3981 - val_bce: 0.3775 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3179                                                                                                    \n",
      "Epoch 11/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3867 - bce: 0.3676 - logcosh: 0.0191 - val_loss: 0.3947 - val_bce: 0.3745 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3243                                                                                                    \n",
      "Epoch 12/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3872 - bce: 0.3680 - logcosh: 0.0192 - val_loss: 0.3995 - val_bce: 0.3783 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.3132                                                                                                    \n",
      "Epoch 13/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3876 - bce: 0.3684 - logcosh: 0.0193 - val_loss: 0.3942 - val_bce: 0.3741 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3221                                                                                                    \n",
      "Epoch 14/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3867 - bce: 0.3675 - logcosh: 0.0192 - val_loss: 0.3957 - val_bce: 0.3754 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.3168                                                                                                    \n",
      "Epoch 15/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3864 - bce: 0.3673 - logcosh: 0.0191 - val_loss: 0.3949 - val_bce: 0.3746 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3213                                                                                                    \n",
      "Epoch 16/50\n",
      "4863/4863 [==============================] - 0s 81us/step - loss: 0.3868 - bce: 0.3676 - logcosh: 0.0192 - val_loss: 0.3980 - val_bce: 0.3772 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.319                                                                                                    \n",
      "Epoch 17/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3860 - bce: 0.3669 - logcosh: 0.0190 - val_loss: 0.3953 - val_bce: 0.3748 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.3255                                                                                                    \n",
      "Epoch 18/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3864 - bce: 0.3673 - logcosh: 0.0191 - val_loss: 0.3958 - val_bce: 0.3752 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3246                                                                                                    \n",
      "Epoch 19/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3866 - bce: 0.3675 - logcosh: 0.0191 - val_loss: 0.3993 - val_bce: 0.3783 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3254                                                                                                    \n",
      "Epoch 20/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3862 - bce: 0.3671 - logcosh: 0.0191 - val_loss: 0.3995 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3237                                                                                                    \n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 21/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3785 - bce: 0.3605 - logcosh: 0.0179 - val_loss: 0.3901 - val_bce: 0.3705 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3303                                                                                                    \n",
      "Epoch 22/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3780 - bce: 0.3602 - logcosh: 0.0179 - val_loss: 0.3900 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3298                                                                                                    \n",
      "Epoch 23/50\n",
      "4863/4863 [==============================] - 0s 80us/step - loss: 0.3774 - bce: 0.3596 - logcosh: 0.0178 - val_loss: 0.3900 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3294                                                                                                    \n",
      "Epoch 24/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3778 - bce: 0.3600 - logcosh: 0.0178 - val_loss: 0.3901 - val_bce: 0.3705 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3232                                                                                                    \n",
      "Epoch 25/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3776 - bce: 0.3598 - logcosh: 0.0178 - val_loss: 0.3901 - val_bce: 0.3705 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3226                                                                                                    \n",
      "Epoch 26/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3775 - bce: 0.3597 - logcosh: 0.0178 - val_loss: 0.3906 - val_bce: 0.3710 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3163                                                                                                    \n",
      "Epoch 27/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3778 - bce: 0.3599 - logcosh: 0.0178 - val_loss: 0.3904 - val_bce: 0.3708 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3234                                                                                                    \n",
      "Epoch 28/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3774 - bce: 0.3596 - logcosh: 0.0178 - val_loss: 0.3906 - val_bce: 0.3709 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3246                                                                                                    \n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 29/50\n",
      "4863/4863 [==============================] - 0s 79us/step - loss: 0.3775 - bce: 0.3597 - logcosh: 0.0178 - val_loss: 0.3900 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3264                                                                                                    \n",
      "Epoch 30/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3772 - bce: 0.3595 - logcosh: 0.0178 - val_loss: 0.3900 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3251                                                                                                    \n",
      "Epoch 31/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3775 - bce: 0.3597 - logcosh: 0.0178 - val_loss: 0.3900 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3264                                                                                                    \n",
      "Epoch 32/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3773 - bce: 0.3595 - logcosh: 0.0178 - val_loss: 0.3900 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3169                                                                                                    \n",
      "Epoch 33/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3776 - bce: 0.3598 - logcosh: 0.0178 - val_loss: 0.3900 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.321                                                                                                    \n",
      "Epoch 34/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3774 - bce: 0.3596 - logcosh: 0.0178 - val_loss: 0.3900 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3216                                                                                                    \n",
      "Epoch 35/50\n",
      "4863/4863 [==============================] - 0s 80us/step - loss: 0.3775 - bce: 0.3597 - logcosh: 0.0178 - val_loss: 0.3900 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3266                                                                                                    \n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 36/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3771 - bce: 0.3593 - logcosh: 0.0177 - val_loss: 0.3900 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3288                                                                                                    \n",
      "Epoch 37/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3771 - bce: 0.3594 - logcosh: 0.0178 - val_loss: 0.3900 - val_bce: 0.3704 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3266                                                                                                    \n",
      "  val_spearman-rho: 0.3274                                                                                                    \n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 3936)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              16125952  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 18,239,006\n",
      "Trainable params: 18,239,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/100\n",
      "4863/4863 [==============================] - 1s 262us/step - loss: 3.5837 - bce: 0.7123 - logcosh: 0.0409 - val_loss: 1.5853 - val_bce: 0.4318 - val_logcosh: 0.0289\n",
      "  val_spearman-rho: 0.2828                                                                                                    \n",
      "  reload best: 0.2828\n",
      "Epoch 2/100\n",
      "4863/4863 [==============================] - 1s 177us/step - loss: 1.0666 - bce: 0.4123 - logcosh: 0.0261 - val_loss: 0.7916 - val_bce: 0.4233 - val_logcosh: 0.0286\n",
      "  val_spearman-rho: 0.2812                                                                                                    \n",
      "  reload best: 0.2828\n",
      "Epoch 3/100\n",
      "4863/4863 [==============================] - 1s 176us/step - loss: 1.0778 - bce: 0.4132 - logcosh: 0.0262 - val_loss: 0.7808 - val_bce: 0.4167 - val_logcosh: 0.0262\n",
      "  val_spearman-rho: 0.2783                                                                                                    \n",
      "  reload best: 0.2828\n",
      "Epoch 4/100\n",
      "4863/4863 [==============================] - 1s 197us/step - loss: 1.0576 - bce: 0.4123 - logcosh: 0.0260 - val_loss: 0.7538 - val_bce: 0.4107 - val_logcosh: 0.0263\n",
      "  val_spearman-rho: 0.2853                                                                                                    \n",
      "  reload best: 0.2853\n",
      "Epoch 5/100\n",
      "4863/4863 [==============================] - 1s 177us/step - loss: 0.6340 - bce: 0.3980 - logcosh: 0.0239 - val_loss: 0.5716 - val_bce: 0.4116 - val_logcosh: 0.0259\n",
      "  val_spearman-rho: 0.2791                                                                                                    \n",
      "  reload best: 0.2853\n",
      "Epoch 6/100\n",
      "4863/4863 [==============================] - 1s 179us/step - loss: 0.6356 - bce: 0.3981 - logcosh: 0.0239 - val_loss: 0.5676 - val_bce: 0.4105 - val_logcosh: 0.0259\n",
      "  val_spearman-rho: 0.2771                                                                                                    \n",
      "  reload best: 0.2853\n",
      "Epoch 7/100\n",
      "4863/4863 [==============================] - 1s 176us/step - loss: 0.6429 - bce: 0.4008 - logcosh: 0.0244 - val_loss: 0.5631 - val_bce: 0.4052 - val_logcosh: 0.0244\n",
      "  val_spearman-rho: 0.2679                                                                                                    \n",
      "  reload best: 0.2853\n",
      "Epoch 8/100\n",
      "4863/4863 [==============================] - 1s 175us/step - loss: 0.6361 - bce: 0.4001 - logcosh: 0.0242 - val_loss: 0.5707 - val_bce: 0.4149 - val_logcosh: 0.0264\n",
      "  val_spearman-rho: 0.2755                                                                                                    \n",
      "  reload best: 0.2853\n",
      "Epoch 9/100\n",
      "4863/4863 [==============================] - 1s 176us/step - loss: 0.6420 - bce: 0.4020 - logcosh: 0.0246 - val_loss: 0.5723 - val_bce: 0.4122 - val_logcosh: 0.0262\n",
      "  val_spearman-rho: 0.2627                                                                                                    \n",
      "  reload best: 0.2853\n",
      "Epoch 10/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.6327 - bce: 0.3984 - logcosh: 0.0241 - val_loss: 0.5557 - val_bce: 0.4023 - val_logcosh: 0.0245\n",
      "  val_spearman-rho: 0.2727                                                                                                    \n",
      "  reload best: 0.2853\n",
      "Epoch 11/100\n",
      "4863/4863 [==============================] - 1s 178us/step - loss: 0.6308 - bce: 0.3990 - logcosh: 0.0240 - val_loss: 0.5522 - val_bce: 0.4019 - val_logcosh: 0.0243\n",
      "  val_spearman-rho: 0.2788                                                                                                    \n",
      "  reload best: 0.2853\n",
      "Epoch 12/100\n",
      "4863/4863 [==============================] - 1s 177us/step - loss: 0.6302 - bce: 0.3993 - logcosh: 0.0242 - val_loss: 0.5546 - val_bce: 0.4032 - val_logcosh: 0.0244\n",
      "  val_spearman-rho: 0.2777                                                                                                    \n",
      "  reload best: 0.2853\n",
      "Epoch 13/100\n",
      "4863/4863 [==============================] - 1s 178us/step - loss: 0.6351 - bce: 0.3991 - logcosh: 0.0241 - val_loss: 0.5593 - val_bce: 0.4043 - val_logcosh: 0.0252\n",
      "  val_spearman-rho: 0.2761                                                                                                    \n",
      "  reload best: 0.2853\n",
      "Epoch 14/100\n",
      "4863/4863 [==============================] - 1s 177us/step - loss: 0.6292 - bce: 0.3984 - logcosh: 0.0241 - val_loss: 0.5462 - val_bce: 0.3967 - val_logcosh: 0.0236\n",
      "  val_spearman-rho: 0.2829                                                                                                    \n",
      "  reload best: 0.2853\n",
      "Epoch 15/100\n",
      "4863/4863 [==============================] - 1s 177us/step - loss: 0.6254 - bce: 0.3975 - logcosh: 0.0239 - val_loss: 0.5583 - val_bce: 0.4089 - val_logcosh: 0.0253\n",
      "  val_spearman-rho: 0.2675                                                                                                    \n",
      "  reload best: 0.2853\n",
      "Epoch 16/100\n",
      "4863/4863 [==============================] - 1s 177us/step - loss: 0.6312 - bce: 0.3995 - logcosh: 0.0242 - val_loss: 0.5588 - val_bce: 0.4064 - val_logcosh: 0.0257\n",
      "  val_spearman-rho: 0.2635                                                                                                    \n",
      "  reload best: 0.2853\n",
      "Epoch 17/100\n",
      "4863/4863 [==============================] - 1s 176us/step - loss: 0.6291 - bce: 0.3989 - logcosh: 0.0241 - val_loss: 0.5516 - val_bce: 0.4030 - val_logcosh: 0.0243\n",
      "  val_spearman-rho: 0.2727                                                                                                    \n",
      "  reload best: 0.2853\n",
      "Epoch 18/100\n",
      "4863/4863 [==============================] - 1s 174us/step - loss: 0.6287 - bce: 0.3991 - logcosh: 0.0240 - val_loss: 0.5563 - val_bce: 0.4066 - val_logcosh: 0.0246\n",
      "  val_spearman-rho: 0.2676                                                                                                    \n",
      "  reload best: 0.2853\n",
      "Epoch 19/100\n",
      "4863/4863 [==============================] - 1s 174us/step - loss: 0.6335 - bce: 0.4007 - logcosh: 0.0244 - val_loss: 0.5502 - val_bce: 0.4007 - val_logcosh: 0.0242\n",
      "  val_spearman-rho: 0.2618                                                                                                    \n",
      "  reload best: 0.2853\n",
      "Epoch 20/100\n",
      "4863/4863 [==============================] - 1s 177us/step - loss: 0.6282 - bce: 0.3982 - logcosh: 0.0240 - val_loss: 0.5522 - val_bce: 0.4025 - val_logcosh: 0.0243\n",
      "  val_spearman-rho: 0.2623                                                                                                    \n",
      "  reload best: 0.2853\n",
      "Epoch 21/100\n",
      "4863/4863 [==============================] - 1s 177us/step - loss: 0.6215 - bce: 0.3980 - logcosh: 0.0239 - val_loss: 0.5475 - val_bce: 0.4018 - val_logcosh: 0.0244\n",
      "  val_spearman-rho: 0.2655                                                                                                    \n",
      "  reload best: 0.2853\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 22/100\n",
      "4863/4863 [==============================] - 1s 176us/step - loss: 0.6925 - bce: 0.3828 - logcosh: 0.0215 - val_loss: 0.6694 - val_bce: 0.3885 - val_logcosh: 0.0224\n",
      "  val_spearman-rho: 0.2886                                                                                                    \n",
      "  reload best: 0.2886\n",
      "Epoch 23/100\n",
      "4863/4863 [==============================] - 1s 177us/step - loss: 0.6372 - bce: 0.3794 - logcosh: 0.0210 - val_loss: 0.6265 - val_bce: 0.3868 - val_logcosh: 0.0222\n",
      "  val_spearman-rho: 0.2858                                                                                                    \n",
      "  reload best: 0.2886\n",
      "Epoch 24/100\n",
      "4863/4863 [==============================] - 1s 175us/step - loss: 0.6385 - bce: 0.3799 - logcosh: 0.0210 - val_loss: 0.6286 - val_bce: 0.3880 - val_logcosh: 0.0224\n",
      "  val_spearman-rho: 0.2887                                                                                                    \n",
      "  reload best: 0.2887\n",
      "Epoch 25/100\n",
      "4863/4863 [==============================] - 1s 176us/step - loss: 0.6024 - bce: 0.3790 - logcosh: 0.0209 - val_loss: 0.5967 - val_bce: 0.3865 - val_logcosh: 0.0221\n",
      "  val_spearman-rho: 0.288                                                                                                    \n",
      "  reload best: 0.2887\n",
      "Epoch 26/100\n",
      "4863/4863 [==============================] - 1s 175us/step - loss: 0.6023 - bce: 0.3786 - logcosh: 0.0208 - val_loss: 0.5982 - val_bce: 0.3877 - val_logcosh: 0.0224\n",
      "  val_spearman-rho: 0.2934                                                                                                    \n",
      "  reload best: 0.2934\n",
      "Epoch 27/100\n",
      "4863/4863 [==============================] - 1s 198us/step - loss: 0.5739 - bce: 0.3773 - logcosh: 0.0206 - val_loss: 0.5739 - val_bce: 0.3872 - val_logcosh: 0.0223\n",
      "  val_spearman-rho: 0.292                                                                                                    \n",
      "  reload best: 0.2934\n",
      "Epoch 28/100\n",
      "4863/4863 [==============================] - 1s 177us/step - loss: 0.5757 - bce: 0.3784 - logcosh: 0.0208 - val_loss: 0.5740 - val_bce: 0.3869 - val_logcosh: 0.0223\n",
      "  val_spearman-rho: 0.2913                                                                                                    \n",
      "  reload best: 0.2934\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 5.000000237487257e-06.\n",
      "Epoch 29/100\n",
      "4863/4863 [==============================] - 1s 178us/step - loss: 0.5825 - bce: 0.3754 - logcosh: 0.0203 - val_loss: 0.5916 - val_bce: 0.3845 - val_logcosh: 0.0218\n",
      "  val_spearman-rho: 0.2923                                                                                                    \n",
      "  reload best: 0.2934\n",
      "  val_spearman-rho: 0.2925                                                                                                    \n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/50\n",
      "4863/4863 [==============================] - 1s 180us/step - loss: 0.5838 - bce: 0.3774 - logcosh: 0.0207 - val_loss: 0.5907 - val_bce: 0.3855 - val_logcosh: 0.0220\n",
      "  val_spearman-rho: 0.2919                                                                                                    \n",
      "Epoch 2/50\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.5787 - bce: 0.3772 - logcosh: 0.0206 - val_loss: 0.5900 - val_bce: 0.3889 - val_logcosh: 0.0226\n",
      "  val_spearman-rho: 0.2884                                                                                                    \n",
      "Epoch 3/50\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.5740 - bce: 0.3771 - logcosh: 0.0206 - val_loss: 0.5835 - val_bce: 0.3872 - val_logcosh: 0.0223\n",
      "  val_spearman-rho: 0.2896                                                                                                    \n",
      "Epoch 4/50\n",
      "4863/4863 [==============================] - 1s 126us/step - loss: 0.5693 - bce: 0.3770 - logcosh: 0.0206 - val_loss: 0.5773 - val_bce: 0.3858 - val_logcosh: 0.0221\n",
      "  val_spearman-rho: 0.2972                                                                                                    \n",
      "Epoch 5/50\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.5642 - bce: 0.3765 - logcosh: 0.0205 - val_loss: 0.5719 - val_bce: 0.3852 - val_logcosh: 0.0219\n",
      "  val_spearman-rho: 0.2974                                                                                                    \n",
      "Epoch 6/50\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.5602 - bce: 0.3769 - logcosh: 0.0206 - val_loss: 0.5712 - val_bce: 0.3881 - val_logcosh: 0.0225\n",
      "  val_spearman-rho: 0.2932                                                                                                    \n",
      "Epoch 7/50\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.5557 - bce: 0.3767 - logcosh: 0.0206 - val_loss: 0.5653 - val_bce: 0.3867 - val_logcosh: 0.0223\n",
      "  val_spearman-rho: 0.2908                                                                                                    \n",
      "Epoch 8/50\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.5514 - bce: 0.3766 - logcosh: 0.0205 - val_loss: 0.5605 - val_bce: 0.3862 - val_logcosh: 0.0221\n",
      "  val_spearman-rho: 0.3014                                                                                                    \n",
      "Epoch 9/50\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.5473 - bce: 0.3766 - logcosh: 0.0205 - val_loss: 0.5551 - val_bce: 0.3850 - val_logcosh: 0.0219\n",
      "  val_spearman-rho: 0.2884                                                                                                    \n",
      "Epoch 10/50\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.5426 - bce: 0.3761 - logcosh: 0.0204 - val_loss: 0.5515 - val_bce: 0.3853 - val_logcosh: 0.0220\n",
      "  val_spearman-rho: 0.2955                                                                                                    \n",
      "Epoch 11/50\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.5388 - bce: 0.3761 - logcosh: 0.0205 - val_loss: 0.5470 - val_bce: 0.3849 - val_logcosh: 0.0218\n",
      "  val_spearman-rho: 0.2917                                                                                                    \n",
      "Epoch 12/50\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.5350 - bce: 0.3762 - logcosh: 0.0205 - val_loss: 0.5462 - val_bce: 0.3874 - val_logcosh: 0.0224\n",
      "  val_spearman-rho: 0.2891                                                                                                    \n",
      "Epoch 13/50\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.5315 - bce: 0.3763 - logcosh: 0.0205 - val_loss: 0.5406 - val_bce: 0.3857 - val_logcosh: 0.0220\n",
      "  val_spearman-rho: 0.2915                                                                                                    \n",
      "Epoch 14/50\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.5278 - bce: 0.3762 - logcosh: 0.0205 - val_loss: 0.5365 - val_bce: 0.3852 - val_logcosh: 0.0219\n",
      "  val_spearman-rho: 0.2992                                                                                                    \n",
      "Epoch 15/50\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.5239 - bce: 0.3758 - logcosh: 0.0204 - val_loss: 0.5342 - val_bce: 0.3862 - val_logcosh: 0.0221\n",
      "  val_spearman-rho: 0.2936                                                                                                    \n",
      "Epoch 16/50\n",
      "4863/4863 [==============================] - 1s 124us/step - loss: 0.5206 - bce: 0.3760 - logcosh: 0.0204 - val_loss: 0.5301 - val_bce: 0.3856 - val_logcosh: 0.0220\n",
      "  val_spearman-rho: 0.2973                                                                                                    \n",
      "Epoch 17/50\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.5172 - bce: 0.3759 - logcosh: 0.0204 - val_loss: 0.5279 - val_bce: 0.3865 - val_logcosh: 0.0222\n",
      "  val_spearman-rho: 0.2909                                                                                                    \n",
      "Epoch 18/50\n",
      "4863/4863 [==============================] - 1s 121us/step - loss: 0.5135 - bce: 0.3755 - logcosh: 0.0204 - val_loss: 0.5240 - val_bce: 0.3859 - val_logcosh: 0.0221\n",
      "  val_spearman-rho: 0.2969                                                                                                    \n",
      "Epoch 19/50\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.5103 - bce: 0.3754 - logcosh: 0.0203 - val_loss: 0.5222 - val_bce: 0.3870 - val_logcosh: 0.0223\n",
      "  val_spearman-rho: 0.2895                                                                                                    \n",
      "Epoch 20/50\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.5076 - bce: 0.3757 - logcosh: 0.0204 - val_loss: 0.5177 - val_bce: 0.3857 - val_logcosh: 0.0221\n",
      "  val_spearman-rho: 0.3018                                                                                                    \n",
      "Epoch 21/50\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.5046 - bce: 0.3756 - logcosh: 0.0204 - val_loss: 0.5159 - val_bce: 0.3866 - val_logcosh: 0.0222\n",
      "  val_spearman-rho: 0.3009                                                                                                    \n",
      "Epoch 22/50\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.5015 - bce: 0.3754 - logcosh: 0.0203 - val_loss: 0.5138 - val_bce: 0.3871 - val_logcosh: 0.0224\n",
      "  val_spearman-rho: 0.3093                                                                                                    \n",
      "Epoch 23/50\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.4986 - bce: 0.3754 - logcosh: 0.0203 - val_loss: 0.5077 - val_bce: 0.3844 - val_logcosh: 0.0218\n",
      "  val_spearman-rho: 0.2992                                                                                                    \n",
      "Epoch 24/50\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.4959 - bce: 0.3754 - logcosh: 0.0203 - val_loss: 0.5075 - val_bce: 0.3864 - val_logcosh: 0.0222\n",
      "  val_spearman-rho: 0.2974                                                                                                    \n",
      "Epoch 25/50\n",
      "4863/4863 [==============================] - 1s 115us/step - loss: 0.4931 - bce: 0.3752 - logcosh: 0.0203 - val_loss: 0.5048 - val_bce: 0.3862 - val_logcosh: 0.0222\n",
      "  val_spearman-rho: 0.2988                                                                                                    \n",
      "Epoch 26/50\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.4904 - bce: 0.3751 - logcosh: 0.0203 - val_loss: 0.5039 - val_bce: 0.3876 - val_logcosh: 0.0225\n",
      "  val_spearman-rho: 0.2961                                                                                                    \n",
      "Epoch 27/50\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.4881 - bce: 0.3752 - logcosh: 0.0203 - val_loss: 0.4992 - val_bce: 0.3858 - val_logcosh: 0.0220\n",
      "  val_spearman-rho: 0.2947                                                                                                    \n",
      "Epoch 28/50\n",
      "4863/4863 [==============================] - 1s 138us/step - loss: 0.4859 - bce: 0.3753 - logcosh: 0.0203 - val_loss: 0.4972 - val_bce: 0.3860 - val_logcosh: 0.0221\n",
      "  val_spearman-rho: 0.2923                                                                                                    \n",
      "Epoch 29/50\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.4834 - bce: 0.3752 - logcosh: 0.0203 - val_loss: 0.4927 - val_bce: 0.3841 - val_logcosh: 0.0218\n",
      "  val_spearman-rho: 0.2915                                                                                                    \n",
      "Epoch 30/50\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.4807 - bce: 0.3747 - logcosh: 0.0202 - val_loss: 0.4897 - val_bce: 0.3834 - val_logcosh: 0.0216\n",
      "  val_spearman-rho: 0.2985                                                                                                    \n",
      "Epoch 31/50\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.4789 - bce: 0.3751 - logcosh: 0.0203 - val_loss: 0.4884 - val_bce: 0.3841 - val_logcosh: 0.0218\n",
      "  val_spearman-rho: 0.2946                                                                                                    \n",
      "Epoch 32/50\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.4763 - bce: 0.3746 - logcosh: 0.0202 - val_loss: 0.4875 - val_bce: 0.3851 - val_logcosh: 0.0220\n",
      "  val_spearman-rho: 0.2963                                                                                                    \n",
      "Epoch 33/50\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.4743 - bce: 0.3747 - logcosh: 0.0202 - val_loss: 0.4848 - val_bce: 0.3846 - val_logcosh: 0.0218\n",
      "  val_spearman-rho: 0.2999                                                                                                    \n",
      "Epoch 34/50\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.4720 - bce: 0.3745 - logcosh: 0.0202 - val_loss: 0.4828 - val_bce: 0.3845 - val_logcosh: 0.0219\n",
      "  val_spearman-rho: 0.3005                                                                                                    \n",
      "Epoch 35/50\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.4700 - bce: 0.3744 - logcosh: 0.0202 - val_loss: 0.4819 - val_bce: 0.3853 - val_logcosh: 0.0220\n",
      "  val_spearman-rho: 0.2986                                                                                                    \n",
      "Epoch 36/50\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.4682 - bce: 0.3744 - logcosh: 0.0202 - val_loss: 0.4799 - val_bce: 0.3853 - val_logcosh: 0.0219\n",
      "  val_spearman-rho: 0.2907                                                                                                    \n",
      "Epoch 37/50\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.4660 - bce: 0.3741 - logcosh: 0.0201 - val_loss: 0.4768 - val_bce: 0.3841 - val_logcosh: 0.0219\n",
      "  val_spearman-rho: 0.3004                                                                                                    \n",
      "Epoch 38/50\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.4646 - bce: 0.3744 - logcosh: 0.0202 - val_loss: 0.4751 - val_bce: 0.3842 - val_logcosh: 0.0218\n",
      "  val_spearman-rho: 0.3039                                                                                                    \n",
      "Epoch 39/50\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.4630 - bce: 0.3745 - logcosh: 0.0202 - val_loss: 0.4743 - val_bce: 0.3849 - val_logcosh: 0.0219\n",
      "  val_spearman-rho: 0.3024                                                                                                    \n",
      "Epoch 40/50\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.4613 - bce: 0.3744 - logcosh: 0.0202 - val_loss: 0.4760 - val_bce: 0.3877 - val_logcosh: 0.0224\n",
      "  val_spearman-rho: 0.2953                                                                                                    \n",
      "Epoch 41/50\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.4596 - bce: 0.3743 - logcosh: 0.0202 - val_loss: 0.4741 - val_bce: 0.3874 - val_logcosh: 0.0223\n",
      "  val_spearman-rho: 0.3021                                                                                                    \n",
      "Epoch 42/50\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.4576 - bce: 0.3739 - logcosh: 0.0201 - val_loss: 0.4715 - val_bce: 0.3866 - val_logcosh: 0.0221\n",
      "  val_spearman-rho: 0.2986                                                                                                    \n",
      "Epoch 43/50\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.4563 - bce: 0.3741 - logcosh: 0.0201 - val_loss: 0.4689 - val_bce: 0.3854 - val_logcosh: 0.0221\n",
      "  val_spearman-rho: 0.3026                                                                                                    \n",
      "Epoch 44/50\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.4546 - bce: 0.3739 - logcosh: 0.0201 - val_loss: 0.4688 - val_bce: 0.3867 - val_logcosh: 0.0222\n",
      "  val_spearman-rho: 0.3007                                                                                                    \n",
      "Epoch 45/50\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.4531 - bce: 0.3738 - logcosh: 0.0201 - val_loss: 0.4676 - val_bce: 0.3869 - val_logcosh: 0.0222\n",
      "  val_spearman-rho: 0.3124                                                                                                    \n",
      "Epoch 46/50\n",
      "4863/4863 [==============================] - 1s 131us/step - loss: 0.4519 - bce: 0.3739 - logcosh: 0.0201 - val_loss: 0.4634 - val_bce: 0.3844 - val_logcosh: 0.0219\n",
      "  val_spearman-rho: 0.2918                                                                                                    \n",
      "Epoch 47/50\n",
      "4863/4863 [==============================] - 1s 126us/step - loss: 0.4502 - bce: 0.3736 - logcosh: 0.0201 - val_loss: 0.4636 - val_bce: 0.3857 - val_logcosh: 0.0221\n",
      "  val_spearman-rho: 0.299                                                                                                    \n",
      "Epoch 48/50\n",
      "4863/4863 [==============================] - 1s 121us/step - loss: 0.4488 - bce: 0.3735 - logcosh: 0.0201 - val_loss: 0.4611 - val_bce: 0.3847 - val_logcosh: 0.0219\n",
      "  val_spearman-rho: 0.3057                                                                                                    \n",
      "Epoch 49/50\n",
      "4863/4863 [==============================] - 1s 125us/step - loss: 0.4473 - bce: 0.3734 - logcosh: 0.0200 - val_loss: 0.4589 - val_bce: 0.3840 - val_logcosh: 0.0217\n",
      "  val_spearman-rho: 0.3024                                                                                                    \n",
      "Epoch 50/50\n",
      "4863/4863 [==============================] - 1s 129us/step - loss: 0.4462 - bce: 0.3735 - logcosh: 0.0200 - val_loss: 0.4594 - val_bce: 0.3853 - val_logcosh: 0.0221\n",
      "  val_spearman-rho: 0.2944                                                                                                    \n",
      "  val_spearman-rho: 0.3036                                                                                                    \n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 3936)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               2015744   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 2,031,134\n",
      "Trainable params: 2,031,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/100\n",
      "4863/4863 [==============================] - 1s 155us/step - loss: 0.5684 - bce: 0.5309 - logcosh: 0.0375 - val_loss: 0.4221 - val_bce: 0.3982 - val_logcosh: 0.0239\n",
      "  val_spearman-rho: 0.2606                                                                                                    \n",
      "  reload best: 0.2606\n",
      "Epoch 2/100\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.4353 - bce: 0.4097 - logcosh: 0.0257 - val_loss: 0.4155 - val_bce: 0.3926 - val_logcosh: 0.0229\n",
      "  val_spearman-rho: 0.2832                                                                                                    \n",
      "  reload best: 0.2832\n",
      "Epoch 3/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.4239 - bce: 0.3997 - logcosh: 0.0242 - val_loss: 0.4045 - val_bce: 0.3831 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3024                                                                                                    \n",
      "  reload best: 0.3024\n",
      "Epoch 4/100\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.4156 - bce: 0.3926 - logcosh: 0.0230 - val_loss: 0.4061 - val_bce: 0.3846 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.3056                                                                                                    \n",
      "  reload best: 0.3056\n",
      "Epoch 5/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.4088 - bce: 0.3867 - logcosh: 0.0221 - val_loss: 0.4005 - val_bce: 0.3797 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3139                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 6/100\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.4043 - bce: 0.3828 - logcosh: 0.0215 - val_loss: 0.3999 - val_bce: 0.3794 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3143                                                                                                    \n",
      "  reload best: 0.3143\n",
      "Epoch 7/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3986 - bce: 0.3778 - logcosh: 0.0207 - val_loss: 0.4003 - val_bce: 0.3795 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3151                                                                                                    \n",
      "  reload best: 0.3151\n",
      "Epoch 8/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3966 - bce: 0.3761 - logcosh: 0.0205 - val_loss: 0.4007 - val_bce: 0.3800 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3202                                                                                                    \n",
      "  reload best: 0.3202\n",
      "Epoch 9/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3932 - bce: 0.3731 - logcosh: 0.0201 - val_loss: 0.3989 - val_bce: 0.3785 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.3202                                                                                                    \n",
      "  reload best: 0.3202\n",
      "Epoch 10/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3891 - bce: 0.3697 - logcosh: 0.0195 - val_loss: 0.4001 - val_bce: 0.3794 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3219                                                                                                    \n",
      "  reload best: 0.3219\n",
      "Epoch 11/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3849 - bce: 0.3660 - logcosh: 0.0189 - val_loss: 0.4000 - val_bce: 0.3792 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3218                                                                                                    \n",
      "  reload best: 0.3219\n",
      "Epoch 12/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3847 - bce: 0.3658 - logcosh: 0.0189 - val_loss: 0.4016 - val_bce: 0.3808 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3272                                                                                                    \n",
      "  reload best: 0.3272\n",
      "Epoch 13/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3836 - bce: 0.3648 - logcosh: 0.0187 - val_loss: 0.3980 - val_bce: 0.3777 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3182                                                                                                    \n",
      "  reload best: 0.3272\n",
      "Epoch 14/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3834 - bce: 0.3647 - logcosh: 0.0188 - val_loss: 0.3970 - val_bce: 0.3767 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.329                                                                                                    \n",
      "  reload best: 0.329\n",
      "Epoch 15/100\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.3801 - bce: 0.3618 - logcosh: 0.0183 - val_loss: 0.4022 - val_bce: 0.3812 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3287                                                                                                    \n",
      "  reload best: 0.329\n",
      "Epoch 16/100\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.3786 - bce: 0.3605 - logcosh: 0.0181 - val_loss: 0.4001 - val_bce: 0.3792 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3267                                                                                                    \n",
      "  reload best: 0.329\n",
      "Epoch 17/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3803 - bce: 0.3620 - logcosh: 0.0183 - val_loss: 0.4017 - val_bce: 0.3811 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3262                                                                                                    \n",
      "  reload best: 0.329\n",
      "Epoch 18/100\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.3803 - bce: 0.3620 - logcosh: 0.0183 - val_loss: 0.3952 - val_bce: 0.3752 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.3203                                                                                                    \n",
      "  reload best: 0.329\n",
      "Epoch 19/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3791 - bce: 0.3609 - logcosh: 0.0182 - val_loss: 0.4017 - val_bce: 0.3809 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3186                                                                                                    \n",
      "  reload best: 0.329\n",
      "Epoch 20/100\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3785 - bce: 0.3604 - logcosh: 0.0181 - val_loss: 0.4007 - val_bce: 0.3800 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3193                                                                                                    \n",
      "  reload best: 0.329\n",
      "Epoch 21/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3813 - bce: 0.3628 - logcosh: 0.0185 - val_loss: 0.4036 - val_bce: 0.3828 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3172                                                                                                    \n",
      "  reload best: 0.329\n",
      "Epoch 22/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3799 - bce: 0.3616 - logcosh: 0.0183 - val_loss: 0.4017 - val_bce: 0.3810 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3249                                                                                                    \n",
      "  reload best: 0.329\n",
      "Epoch 23/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3790 - bce: 0.3609 - logcosh: 0.0181 - val_loss: 0.3963 - val_bce: 0.3761 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3165                                                                                                    \n",
      "  reload best: 0.329\n",
      "Epoch 24/100\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3801 - bce: 0.3618 - logcosh: 0.0183 - val_loss: 0.4041 - val_bce: 0.3827 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.3188                                                                                                    \n",
      "  reload best: 0.329\n",
      "Epoch 25/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3799 - bce: 0.3616 - logcosh: 0.0182 - val_loss: 0.3996 - val_bce: 0.3790 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3246                                                                                                    \n",
      "  reload best: 0.329\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 26/100\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3710 - bce: 0.3540 - logcosh: 0.0170 - val_loss: 0.3936 - val_bce: 0.3738 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3271                                                                                                    \n",
      "  reload best: 0.329\n",
      "Epoch 27/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3712 - bce: 0.3542 - logcosh: 0.0171 - val_loss: 0.3930 - val_bce: 0.3734 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.329                                                                                                    \n",
      "  reload best: 0.329\n",
      "Epoch 28/100\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3710 - bce: 0.3539 - logcosh: 0.0170 - val_loss: 0.3942 - val_bce: 0.3743 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3237                                                                                                    \n",
      "  reload best: 0.329\n",
      "Epoch 29/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3712 - bce: 0.3541 - logcosh: 0.0171 - val_loss: 0.3932 - val_bce: 0.3734 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.328                                                                                                    \n",
      "  reload best: 0.329\n",
      "Epoch 30/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3712 - bce: 0.3541 - logcosh: 0.0171 - val_loss: 0.3929 - val_bce: 0.3732 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3239                                                                                                    \n",
      "  reload best: 0.329\n",
      "Epoch 31/100\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.3713 - bce: 0.3542 - logcosh: 0.0171 - val_loss: 0.3932 - val_bce: 0.3735 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3311                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 32/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3682 - bce: 0.3515 - logcosh: 0.0166 - val_loss: 0.3932 - val_bce: 0.3735 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.328                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 33/100\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3686 - bce: 0.3519 - logcosh: 0.0167 - val_loss: 0.3935 - val_bce: 0.3738 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3234                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 34/100\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.3690 - bce: 0.3522 - logcosh: 0.0168 - val_loss: 0.3934 - val_bce: 0.3736 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3259                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 35/100\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3690 - bce: 0.3522 - logcosh: 0.0168 - val_loss: 0.3928 - val_bce: 0.3730 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3206                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 36/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3682 - bce: 0.3515 - logcosh: 0.0167 - val_loss: 0.3928 - val_bce: 0.3732 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3311                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 37/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3680 - bce: 0.3514 - logcosh: 0.0166 - val_loss: 0.3936 - val_bce: 0.3737 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3249                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 38/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3683 - bce: 0.3516 - logcosh: 0.0167 - val_loss: 0.3931 - val_bce: 0.3734 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3207                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 39/100\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.3685 - bce: 0.3517 - logcosh: 0.0167 - val_loss: 0.3932 - val_bce: 0.3735 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3284                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 40/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3679 - bce: 0.3513 - logcosh: 0.0166 - val_loss: 0.3937 - val_bce: 0.3739 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.325                                                                                                    \n",
      "  reload best: 0.3311\n",
      "Epoch 41/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3679 - bce: 0.3513 - logcosh: 0.0166 - val_loss: 0.3928 - val_bce: 0.3731 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3342                                                                                                    \n",
      "  reload best: 0.3342\n",
      "Epoch 42/100\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3673 - bce: 0.3508 - logcosh: 0.0165 - val_loss: 0.3932 - val_bce: 0.3735 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.328                                                                                                    \n",
      "  reload best: 0.3342\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 5.000000237487257e-06.\n",
      "Epoch 43/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3660 - bce: 0.3497 - logcosh: 0.0164 - val_loss: 0.3924 - val_bce: 0.3728 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3172                                                                                                    \n",
      "  reload best: 0.3342\n",
      "Epoch 44/100\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.3666 - bce: 0.3501 - logcosh: 0.0164 - val_loss: 0.3924 - val_bce: 0.3728 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3251                                                                                                    \n",
      "  reload best: 0.3342\n",
      "Epoch 45/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3667 - bce: 0.3503 - logcosh: 0.0165 - val_loss: 0.3925 - val_bce: 0.3728 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3249                                                                                                    \n",
      "  reload best: 0.3342\n",
      "Epoch 46/100\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3664 - bce: 0.3500 - logcosh: 0.0164 - val_loss: 0.3922 - val_bce: 0.3726 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3251                                                                                                    \n",
      "  reload best: 0.3342\n",
      "Epoch 47/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3664 - bce: 0.3500 - logcosh: 0.0164 - val_loss: 0.3924 - val_bce: 0.3728 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3235                                                                                                    \n",
      "  reload best: 0.3342\n",
      "Epoch 48/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3666 - bce: 0.3502 - logcosh: 0.0165 - val_loss: 0.3924 - val_bce: 0.3728 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3245                                                                                                    \n",
      "  reload best: 0.3342\n",
      "Epoch 49/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3667 - bce: 0.3503 - logcosh: 0.0165 - val_loss: 0.3924 - val_bce: 0.3727 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3284                                                                                                    \n",
      "  reload best: 0.3342\n",
      "Epoch 50/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3666 - bce: 0.3502 - logcosh: 0.0164 - val_loss: 0.3924 - val_bce: 0.3728 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3264                                                                                                    \n",
      "  reload best: 0.3342\n",
      "Epoch 51/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3663 - bce: 0.3499 - logcosh: 0.0164 - val_loss: 0.3926 - val_bce: 0.3730 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3266                                                                                                    \n",
      "  reload best: 0.3342\n",
      "Epoch 52/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3665 - bce: 0.3501 - logcosh: 0.0164 - val_loss: 0.3923 - val_bce: 0.3727 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3267                                                                                                    \n",
      "  reload best: 0.3342\n",
      "Epoch 53/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3663 - bce: 0.3499 - logcosh: 0.0164 - val_loss: 0.3923 - val_bce: 0.3727 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3241                                                                                                    \n",
      "  reload best: 0.3342\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 54/100\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3668 - bce: 0.3503 - logcosh: 0.0165 - val_loss: 0.3923 - val_bce: 0.3727 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3259                                                                                                    \n",
      "  reload best: 0.3342\n",
      "Epoch 55/100\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3665 - bce: 0.3501 - logcosh: 0.0164 - val_loss: 0.3923 - val_bce: 0.3727 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3251                                                                                                    \n",
      "  reload best: 0.3342\n",
      "Epoch 56/100\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3668 - bce: 0.3504 - logcosh: 0.0165 - val_loss: 0.3923 - val_bce: 0.3727 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3214                                                                                                    \n",
      "  reload best: 0.3342\n",
      "Epoch 57/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3662 - bce: 0.3498 - logcosh: 0.0164 - val_loss: 0.3923 - val_bce: 0.3727 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3266                                                                                                    \n",
      "  reload best: 0.3342\n",
      "Epoch 58/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3663 - bce: 0.3499 - logcosh: 0.0164 - val_loss: 0.3923 - val_bce: 0.3727 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3285                                                                                                    \n",
      "  reload best: 0.3342\n",
      "Epoch 59/100\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.3665 - bce: 0.3501 - logcosh: 0.0164 - val_loss: 0.3923 - val_bce: 0.3727 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3236                                                                                                    \n",
      "  reload best: 0.3342\n",
      "Epoch 60/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3669 - bce: 0.3504 - logcosh: 0.0165 - val_loss: 0.3923 - val_bce: 0.3727 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3266                                                                                                    \n",
      "  reload best: 0.3342\n",
      "Epoch 61/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3668 - bce: 0.3503 - logcosh: 0.0165 - val_loss: 0.3923 - val_bce: 0.3727 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3235                                                                                                    \n",
      "  reload best: 0.3342\n",
      "  val_spearman-rho: 0.3277                                                                                                    \n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/50\n",
      "4863/4863 [==============================] - 1s 135us/step - loss: 0.3745 - bce: 0.3568 - logcosh: 0.0176 - val_loss: 0.3978 - val_bce: 0.3775 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.3256                                                                                                    \n",
      "Epoch 2/50\n",
      "4863/4863 [==============================] - 0s 81us/step - loss: 0.3746 - bce: 0.3570 - logcosh: 0.0176 - val_loss: 0.3990 - val_bce: 0.3785 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.3288                                                                                                    \n",
      "Epoch 3/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3754 - bce: 0.3577 - logcosh: 0.0177 - val_loss: 0.3993 - val_bce: 0.3785 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3179                                                                                                    \n",
      "Epoch 4/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3750 - bce: 0.3574 - logcosh: 0.0177 - val_loss: 0.3989 - val_bce: 0.3783 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3293                                                                                                    \n",
      "Epoch 5/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3748 - bce: 0.3572 - logcosh: 0.0177 - val_loss: 0.4038 - val_bce: 0.3831 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3287                                                                                                    \n",
      "Epoch 6/50\n",
      "4863/4863 [==============================] - 0s 81us/step - loss: 0.3741 - bce: 0.3566 - logcosh: 0.0175 - val_loss: 0.3962 - val_bce: 0.3759 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3181                                                                                                    \n",
      "Epoch 7/50\n",
      "4863/4863 [==============================] - 0s 81us/step - loss: 0.3736 - bce: 0.3562 - logcosh: 0.0175 - val_loss: 0.3996 - val_bce: 0.3787 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3227                                                                                                    \n",
      "Epoch 8/50\n",
      "4863/4863 [==============================] - 0s 80us/step - loss: 0.3747 - bce: 0.3570 - logcosh: 0.0177 - val_loss: 0.3994 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3257                                                                                                    \n",
      "Epoch 9/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3752 - bce: 0.3575 - logcosh: 0.0177 - val_loss: 0.4009 - val_bce: 0.3801 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.326                                                                                                    \n",
      "Epoch 10/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3751 - bce: 0.3574 - logcosh: 0.0177 - val_loss: 0.3971 - val_bce: 0.3767 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.326                                                                                                    \n",
      "Epoch 11/50\n",
      "4863/4863 [==============================] - 0s 80us/step - loss: 0.3748 - bce: 0.3572 - logcosh: 0.0177 - val_loss: 0.3969 - val_bce: 0.3767 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3325                                                                                                    \n",
      "Epoch 12/50\n",
      "4863/4863 [==============================] - 0s 80us/step - loss: 0.3737 - bce: 0.3562 - logcosh: 0.0175 - val_loss: 0.4005 - val_bce: 0.3797 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.329                                                                                                    \n",
      "Epoch 13/50\n",
      "4863/4863 [==============================] - 0s 81us/step - loss: 0.3740 - bce: 0.3565 - logcosh: 0.0176 - val_loss: 0.3970 - val_bce: 0.3764 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3224                                                                                                    \n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 14/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3665 - bce: 0.3500 - logcosh: 0.0164 - val_loss: 0.3921 - val_bce: 0.3725 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3259                                                                                                    \n",
      "Epoch 15/50\n",
      "4863/4863 [==============================] - 0s 80us/step - loss: 0.3658 - bce: 0.3495 - logcosh: 0.0163 - val_loss: 0.3927 - val_bce: 0.3730 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3225                                                                                                    \n",
      "Epoch 16/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3665 - bce: 0.3500 - logcosh: 0.0164 - val_loss: 0.3927 - val_bce: 0.3730 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3209                                                                                                    \n",
      "Epoch 17/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3664 - bce: 0.3499 - logcosh: 0.0164 - val_loss: 0.3930 - val_bce: 0.3733 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.326                                                                                                    \n",
      "Epoch 18/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3659 - bce: 0.3496 - logcosh: 0.0164 - val_loss: 0.3926 - val_bce: 0.3729 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3279                                                                                                    \n",
      "Epoch 19/50\n",
      "4863/4863 [==============================] - 0s 81us/step - loss: 0.3661 - bce: 0.3497 - logcosh: 0.0164 - val_loss: 0.3927 - val_bce: 0.3731 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3277                                                                                                    \n",
      "Epoch 20/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3662 - bce: 0.3498 - logcosh: 0.0164 - val_loss: 0.3927 - val_bce: 0.3730 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3273                                                                                                    \n",
      "Epoch 21/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3658 - bce: 0.3495 - logcosh: 0.0163 - val_loss: 0.3929 - val_bce: 0.3732 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3301                                                                                                    \n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 22/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3654 - bce: 0.3492 - logcosh: 0.0163 - val_loss: 0.3925 - val_bce: 0.3729 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3239                                                                                                    \n",
      "Epoch 23/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3656 - bce: 0.3493 - logcosh: 0.0163 - val_loss: 0.3925 - val_bce: 0.3728 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3322                                                                                                    \n",
      "Epoch 24/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3655 - bce: 0.3493 - logcosh: 0.0163 - val_loss: 0.3925 - val_bce: 0.3728 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3246                                                                                                    \n",
      "Epoch 25/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3657 - bce: 0.3494 - logcosh: 0.0163 - val_loss: 0.3925 - val_bce: 0.3728 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3225                                                                                                    \n",
      "Epoch 26/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3651 - bce: 0.3488 - logcosh: 0.0162 - val_loss: 0.3925 - val_bce: 0.3729 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.326                                                                                                    \n",
      "Epoch 27/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3655 - bce: 0.3492 - logcosh: 0.0163 - val_loss: 0.3925 - val_bce: 0.3729 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.3323                                                                                                    \n",
      "Epoch 28/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3658 - bce: 0.3495 - logcosh: 0.0164 - val_loss: 0.3925 - val_bce: 0.3729 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.335                                                                                                    \n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 29/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3652 - bce: 0.3490 - logcosh: 0.0162 - val_loss: 0.3925 - val_bce: 0.3728 - val_logcosh: 0.0196\n",
      "  val_spearman-rho: 0.326                                                                                                    \n",
      "  val_spearman-rho: 0.3246                                                                                                    \n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 3936)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               2015744   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 30)                7710      \n",
      "=================================================================\n",
      "Total params: 2,154,782\n",
      "Trainable params: 2,154,782\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4864 samples, validate on 1215 samples\n",
      "Epoch 1/100\n",
      "4864/4864 [==============================] - 1s 170us/step - loss: 0.4711 - bce: 0.4416 - logcosh: 0.0295 - val_loss: 0.4202 - val_bce: 0.3962 - val_logcosh: 0.0240\n",
      "  val_spearman-rho: 0.2524                                                                                                    \n",
      "  reload best: 0.2524\n",
      "Epoch 2/100\n",
      "4864/4864 [==============================] - 0s 97us/step - loss: 0.4154 - bce: 0.3923 - logcosh: 0.0231 - val_loss: 0.4137 - val_bce: 0.3909 - val_logcosh: 0.0228\n",
      "  val_spearman-rho: 0.2843                                                                                                    \n",
      "  reload best: 0.2843\n",
      "Epoch 3/100\n",
      "4864/4864 [==============================] - 1s 103us/step - loss: 0.4051 - bce: 0.3835 - logcosh: 0.0217 - val_loss: 0.4103 - val_bce: 0.3877 - val_logcosh: 0.0226\n",
      "  val_spearman-rho: 0.3018                                                                                                    \n",
      "  reload best: 0.3018\n",
      "Epoch 4/100\n",
      "4864/4864 [==============================] - 0s 101us/step - loss: 0.3988 - bce: 0.3780 - logcosh: 0.0208 - val_loss: 0.4019 - val_bce: 0.3806 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3079                                                                                                    \n",
      "  reload best: 0.3079\n",
      "Epoch 5/100\n",
      "4864/4864 [==============================] - 0s 99us/step - loss: 0.3947 - bce: 0.3745 - logcosh: 0.0202 - val_loss: 0.4019 - val_bce: 0.3807 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.3186                                                                                                    \n",
      "  reload best: 0.3186\n",
      "Epoch 6/100\n",
      "4864/4864 [==============================] - 0s 102us/step - loss: 0.3889 - bce: 0.3695 - logcosh: 0.0194 - val_loss: 0.4016 - val_bce: 0.3803 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3171                                                                                                    \n",
      "  reload best: 0.3186\n",
      "Epoch 7/100\n",
      "4864/4864 [==============================] - 0s 98us/step - loss: 0.3898 - bce: 0.3703 - logcosh: 0.0195 - val_loss: 0.3983 - val_bce: 0.3776 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3184                                                                                                    \n",
      "  reload best: 0.3186\n",
      "Epoch 8/100\n",
      "4864/4864 [==============================] - 1s 103us/step - loss: 0.3885 - bce: 0.3691 - logcosh: 0.0193 - val_loss: 0.3980 - val_bce: 0.3774 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3093                                                                                                    \n",
      "  reload best: 0.3186\n",
      "Epoch 9/100\n",
      "4864/4864 [==============================] - 1s 199us/step - loss: 0.3895 - bce: 0.3700 - logcosh: 0.0195 - val_loss: 0.3998 - val_bce: 0.3787 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3189                                                                                                    \n",
      "  reload best: 0.3189\n",
      "Epoch 10/100\n",
      "4864/4864 [==============================] - 1s 107us/step - loss: 0.3854 - bce: 0.3664 - logcosh: 0.0189 - val_loss: 0.3999 - val_bce: 0.3789 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3211                                                                                                    \n",
      "  reload best: 0.3211\n",
      "Epoch 11/100\n",
      "4864/4864 [==============================] - 1s 103us/step - loss: 0.3830 - bce: 0.3644 - logcosh: 0.0186 - val_loss: 0.3957 - val_bce: 0.3752 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.3177                                                                                                    \n",
      "  reload best: 0.3211\n",
      "Epoch 12/100\n",
      "4864/4864 [==============================] - 1s 114us/step - loss: 0.3817 - bce: 0.3633 - logcosh: 0.0184 - val_loss: 0.3972 - val_bce: 0.3767 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3191                                                                                                    \n",
      "  reload best: 0.3211\n",
      "Epoch 13/100\n",
      "4864/4864 [==============================] - 1s 107us/step - loss: 0.3820 - bce: 0.3636 - logcosh: 0.0185 - val_loss: 0.3988 - val_bce: 0.3779 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3082                                                                                                    \n",
      "  reload best: 0.3211\n",
      "Epoch 14/100\n",
      "4864/4864 [==============================] - 0s 100us/step - loss: 0.3825 - bce: 0.3639 - logcosh: 0.0186 - val_loss: 0.3970 - val_bce: 0.3765 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3279                                                                                                    \n",
      "  reload best: 0.3279\n",
      "Epoch 15/100\n",
      "4864/4864 [==============================] - 0s 102us/step - loss: 0.3791 - bce: 0.3610 - logcosh: 0.0181 - val_loss: 0.3979 - val_bce: 0.3772 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.324                                                                                                    \n",
      "  reload best: 0.3279\n",
      "Epoch 16/100\n",
      "4864/4864 [==============================] - 0s 97us/step - loss: 0.3793 - bce: 0.3612 - logcosh: 0.0181 - val_loss: 0.3982 - val_bce: 0.3776 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3355                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 17/100\n",
      "4864/4864 [==============================] - 0s 100us/step - loss: 0.3770 - bce: 0.3592 - logcosh: 0.0178 - val_loss: 0.3979 - val_bce: 0.3773 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3328                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 18/100\n",
      "4864/4864 [==============================] - 0s 94us/step - loss: 0.3766 - bce: 0.3589 - logcosh: 0.0177 - val_loss: 0.3995 - val_bce: 0.3785 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3262                                                                                                    \n",
      "  reload best: 0.3355\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 19/100\n",
      "4864/4864 [==============================] - 0s 103us/step - loss: 0.3697 - bce: 0.3529 - logcosh: 0.0167 - val_loss: 0.3922 - val_bce: 0.3724 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3243                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 20/100\n",
      "4864/4864 [==============================] - 0s 102us/step - loss: 0.3698 - bce: 0.3531 - logcosh: 0.0168 - val_loss: 0.3923 - val_bce: 0.3725 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3281                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 21/100\n",
      "4864/4864 [==============================] - 0s 99us/step - loss: 0.3695 - bce: 0.3528 - logcosh: 0.0167 - val_loss: 0.3928 - val_bce: 0.3728 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.3271                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 22/100\n",
      "4864/4864 [==============================] - 0s 101us/step - loss: 0.3696 - bce: 0.3528 - logcosh: 0.0167 - val_loss: 0.3918 - val_bce: 0.3721 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3233                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 23/100\n",
      "4864/4864 [==============================] - 0s 91us/step - loss: 0.3698 - bce: 0.3531 - logcosh: 0.0167 - val_loss: 0.3919 - val_bce: 0.3721 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.328                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 24/100\n",
      "4864/4864 [==============================] - 1s 104us/step - loss: 0.3697 - bce: 0.3530 - logcosh: 0.0167 - val_loss: 0.3928 - val_bce: 0.3728 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3265                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 25/100\n",
      "4864/4864 [==============================] - 0s 97us/step - loss: 0.3699 - bce: 0.3531 - logcosh: 0.0168 - val_loss: 0.3916 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3262                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 26/100\n",
      "4864/4864 [==============================] - 1s 105us/step - loss: 0.3695 - bce: 0.3528 - logcosh: 0.0167 - val_loss: 0.3930 - val_bce: 0.3731 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.334                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 27/100\n",
      "4864/4864 [==============================] - 0s 101us/step - loss: 0.3696 - bce: 0.3529 - logcosh: 0.0167 - val_loss: 0.3924 - val_bce: 0.3726 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3324                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 28/100\n",
      "4864/4864 [==============================] - 0s 103us/step - loss: 0.3695 - bce: 0.3528 - logcosh: 0.0167 - val_loss: 0.3921 - val_bce: 0.3723 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3267                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 29/100\n",
      "4864/4864 [==============================] - 1s 103us/step - loss: 0.3697 - bce: 0.3530 - logcosh: 0.0167 - val_loss: 0.3920 - val_bce: 0.3722 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3231                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 30/100\n",
      "4864/4864 [==============================] - 0s 93us/step - loss: 0.3695 - bce: 0.3528 - logcosh: 0.0167 - val_loss: 0.3929 - val_bce: 0.3729 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.3247                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 31/100\n",
      "4864/4864 [==============================] - 1s 105us/step - loss: 0.3695 - bce: 0.3528 - logcosh: 0.0167 - val_loss: 0.3927 - val_bce: 0.3727 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3295                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 32/100\n",
      "4864/4864 [==============================] - 0s 96us/step - loss: 0.3699 - bce: 0.3531 - logcosh: 0.0168 - val_loss: 0.3920 - val_bce: 0.3722 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3313                                                                                                    \n",
      "  reload best: 0.3355\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 5.000000237487257e-06.\n",
      "Epoch 33/100\n",
      "4864/4864 [==============================] - 1s 103us/step - loss: 0.3705 - bce: 0.3537 - logcosh: 0.0168 - val_loss: 0.3921 - val_bce: 0.3723 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3265                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 34/100\n",
      "4864/4864 [==============================] - 0s 100us/step - loss: 0.3705 - bce: 0.3537 - logcosh: 0.0168 - val_loss: 0.3921 - val_bce: 0.3723 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3227                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 35/100\n",
      "4864/4864 [==============================] - 0s 98us/step - loss: 0.3706 - bce: 0.3537 - logcosh: 0.0168 - val_loss: 0.3920 - val_bce: 0.3722 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3204                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 36/100\n",
      "4864/4864 [==============================] - 1s 106us/step - loss: 0.3705 - bce: 0.3536 - logcosh: 0.0168 - val_loss: 0.3921 - val_bce: 0.3723 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3229                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 37/100\n",
      "4864/4864 [==============================] - 0s 95us/step - loss: 0.3705 - bce: 0.3536 - logcosh: 0.0168 - val_loss: 0.3921 - val_bce: 0.3723 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3229                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 38/100\n",
      "4864/4864 [==============================] - 0s 97us/step - loss: 0.3706 - bce: 0.3538 - logcosh: 0.0168 - val_loss: 0.3920 - val_bce: 0.3722 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3307                                                                                                    \n",
      "  reload best: 0.3355\n",
      "Epoch 39/100\n",
      "4864/4864 [==============================] - 0s 98us/step - loss: 0.3706 - bce: 0.3537 - logcosh: 0.0168 - val_loss: 0.3920 - val_bce: 0.3722 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3238                                                                                                    \n",
      "  reload best: 0.3355\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 40/100\n",
      "4864/4864 [==============================] - 0s 101us/step - loss: 0.3729 - bce: 0.3557 - logcosh: 0.0172 - val_loss: 0.3938 - val_bce: 0.3738 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.326                                                                                                    \n",
      "  reload best: 0.3355\n",
      "  val_spearman-rho: 0.3264                                                                                                    \n",
      "Train on 4864 samples, validate on 1215 samples\n",
      "Epoch 1/50\n",
      "4864/4864 [==============================] - 1s 135us/step - loss: 0.3755 - bce: 0.3579 - logcosh: 0.0176 - val_loss: 0.3970 - val_bce: 0.3765 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3311                                                                                                    \n",
      "Epoch 2/50\n",
      "4864/4864 [==============================] - 0s 83us/step - loss: 0.3750 - bce: 0.3575 - logcosh: 0.0176 - val_loss: 0.3975 - val_bce: 0.3769 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3255                                                                                                    \n",
      "Epoch 3/50\n",
      "4864/4864 [==============================] - 0s 80us/step - loss: 0.3750 - bce: 0.3575 - logcosh: 0.0175 - val_loss: 0.3965 - val_bce: 0.3761 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.3232                                                                                                    \n",
      "Epoch 4/50\n",
      "4864/4864 [==============================] - 0s 84us/step - loss: 0.3751 - bce: 0.3576 - logcosh: 0.0176 - val_loss: 0.3955 - val_bce: 0.3752 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.3274                                                                                                    \n",
      "Epoch 5/50\n",
      "4864/4864 [==============================] - 0s 79us/step - loss: 0.3747 - bce: 0.3572 - logcosh: 0.0175 - val_loss: 0.3970 - val_bce: 0.3764 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.318                                                                                                    \n",
      "Epoch 6/50\n",
      "4864/4864 [==============================] - 0s 82us/step - loss: 0.3745 - bce: 0.3570 - logcosh: 0.0175 - val_loss: 0.3945 - val_bce: 0.3744 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.328                                                                                                    \n",
      "Epoch 7/50\n",
      "4864/4864 [==============================] - 0s 78us/step - loss: 0.3744 - bce: 0.3569 - logcosh: 0.0175 - val_loss: 0.4038 - val_bce: 0.3822 - val_logcosh: 0.0216\n",
      "  val_spearman-rho: 0.3297                                                                                                    \n",
      "Epoch 8/50\n",
      "4864/4864 [==============================] - 0s 83us/step - loss: 0.3745 - bce: 0.3571 - logcosh: 0.0175 - val_loss: 0.3994 - val_bce: 0.3785 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3264                                                                                                    \n",
      "Epoch 9/50\n",
      "4864/4864 [==============================] - 0s 81us/step - loss: 0.3743 - bce: 0.3569 - logcosh: 0.0174 - val_loss: 0.4011 - val_bce: 0.3801 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3247                                                                                                    \n",
      "Epoch 10/50\n",
      "4864/4864 [==============================] - 0s 82us/step - loss: 0.3746 - bce: 0.3571 - logcosh: 0.0175 - val_loss: 0.3953 - val_bce: 0.3750 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3204                                                                                                    \n",
      "Epoch 11/50\n",
      "4864/4864 [==============================] - 0s 79us/step - loss: 0.3741 - bce: 0.3567 - logcosh: 0.0174 - val_loss: 0.3992 - val_bce: 0.3783 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3205                                                                                                    \n",
      "Epoch 12/50\n",
      "4864/4864 [==============================] - 0s 81us/step - loss: 0.3745 - bce: 0.3570 - logcosh: 0.0175 - val_loss: 0.3965 - val_bce: 0.3760 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.331                                                                                                    \n",
      "Epoch 13/50\n",
      "4864/4864 [==============================] - 0s 81us/step - loss: 0.3743 - bce: 0.3568 - logcosh: 0.0174 - val_loss: 0.3957 - val_bce: 0.3754 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.3248                                                                                                    \n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 14/50\n",
      "4864/4864 [==============================] - 0s 85us/step - loss: 0.3681 - bce: 0.3516 - logcosh: 0.0165 - val_loss: 0.3915 - val_bce: 0.3717 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3277                                                                                                    \n",
      "Epoch 15/50\n",
      "4864/4864 [==============================] - 0s 82us/step - loss: 0.3676 - bce: 0.3511 - logcosh: 0.0164 - val_loss: 0.3916 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3256                                                                                                    \n",
      "Epoch 16/50\n",
      "4864/4864 [==============================] - 0s 80us/step - loss: 0.3675 - bce: 0.3511 - logcosh: 0.0164 - val_loss: 0.3919 - val_bce: 0.3721 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3277                                                                                                    \n",
      "Epoch 17/50\n",
      "4864/4864 [==============================] - 0s 84us/step - loss: 0.3675 - bce: 0.3510 - logcosh: 0.0164 - val_loss: 0.3918 - val_bce: 0.3721 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3274                                                                                                    \n",
      "Epoch 18/50\n",
      "4864/4864 [==============================] - 0s 80us/step - loss: 0.3674 - bce: 0.3510 - logcosh: 0.0164 - val_loss: 0.3918 - val_bce: 0.3720 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3232                                                                                                    \n",
      "Epoch 19/50\n",
      "4864/4864 [==============================] - 0s 84us/step - loss: 0.3674 - bce: 0.3510 - logcosh: 0.0164 - val_loss: 0.3919 - val_bce: 0.3721 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.32                                                                                                    \n",
      "Epoch 20/50\n",
      "4864/4864 [==============================] - 0s 81us/step - loss: 0.3674 - bce: 0.3509 - logcosh: 0.0164 - val_loss: 0.3920 - val_bce: 0.3722 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.33                                                                                                    \n",
      "Epoch 21/50\n",
      "4864/4864 [==============================] - 0s 84us/step - loss: 0.3674 - bce: 0.3509 - logcosh: 0.0164 - val_loss: 0.3919 - val_bce: 0.3721 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3264                                                                                                    \n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 22/50\n",
      "4864/4864 [==============================] - 0s 82us/step - loss: 0.3671 - bce: 0.3507 - logcosh: 0.0164 - val_loss: 0.3917 - val_bce: 0.3720 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3301                                                                                                    \n",
      "Epoch 23/50\n",
      "4864/4864 [==============================] - 0s 82us/step - loss: 0.3670 - bce: 0.3507 - logcosh: 0.0164 - val_loss: 0.3917 - val_bce: 0.3720 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3245                                                                                                    \n",
      "Epoch 24/50\n",
      "4864/4864 [==============================] - 0s 80us/step - loss: 0.3670 - bce: 0.3507 - logcosh: 0.0164 - val_loss: 0.3917 - val_bce: 0.3720 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3353                                                                                                    \n",
      "Epoch 25/50\n",
      "4864/4864 [==============================] - 0s 83us/step - loss: 0.3670 - bce: 0.3507 - logcosh: 0.0164 - val_loss: 0.3917 - val_bce: 0.3719 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3245                                                                                                    \n",
      "Epoch 26/50\n",
      "4864/4864 [==============================] - 0s 81us/step - loss: 0.3670 - bce: 0.3507 - logcosh: 0.0164 - val_loss: 0.3917 - val_bce: 0.3720 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3257                                                                                                    \n",
      "Epoch 27/50\n",
      "4864/4864 [==============================] - 0s 82us/step - loss: 0.3670 - bce: 0.3507 - logcosh: 0.0164 - val_loss: 0.3917 - val_bce: 0.3720 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3305                                                                                                    \n",
      "Epoch 28/50\n",
      "4864/4864 [==============================] - 0s 80us/step - loss: 0.3670 - bce: 0.3507 - logcosh: 0.0164 - val_loss: 0.3918 - val_bce: 0.3720 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3227                                                                                                    \n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 29/50\n",
      "4864/4864 [==============================] - 0s 80us/step - loss: 0.3670 - bce: 0.3506 - logcosh: 0.0164 - val_loss: 0.3918 - val_bce: 0.3720 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3285                                                                                                    \n",
      "  val_spearman-rho: 0.3231                                                                                                    \n",
      "Train on 6079 samples, validate on 6079 samples\n",
      "Epoch 1/30\n",
      "6079/6079 [==============================] - 1s 113us/step - loss: 0.3587 - val_loss: 0.3547\n",
      "  val_spearman-rho: 0.3871                                                                                                    \n",
      "Epoch 2/30\n",
      "6079/6079 [==============================] - 0s 69us/step - loss: 0.3553 - val_loss: 0.3541\n",
      "  val_spearman-rho: 0.3914                                                                                                    \n",
      "Epoch 3/30\n",
      "6079/6079 [==============================] - 0s 70us/step - loss: 0.3545 - val_loss: 0.3545\n",
      "  val_spearman-rho: 0.3964                                                                                                    \n",
      "Epoch 4/30\n",
      "6079/6079 [==============================] - 0s 67us/step - loss: 0.3540 - val_loss: 0.3516\n",
      "  val_spearman-rho: 0.398                                                                                                    \n",
      "Epoch 5/30\n",
      "6079/6079 [==============================] - 0s 71us/step - loss: 0.3518 - val_loss: 0.3528\n",
      "  val_spearman-rho: 0.4035                                                                                                    \n",
      "Epoch 6/30\n",
      "6079/6079 [==============================] - 0s 69us/step - loss: 0.3515 - val_loss: 0.3509\n",
      "  val_spearman-rho: 0.4038                                                                                                    \n",
      "Epoch 7/30\n",
      "6079/6079 [==============================] - 0s 68us/step - loss: 0.3506 - val_loss: 0.3486\n",
      "  val_spearman-rho: 0.4052                                                                                                    \n",
      "Epoch 8/30\n",
      "6079/6079 [==============================] - 0s 69us/step - loss: 0.3489 - val_loss: 0.3480\n",
      "  val_spearman-rho: 0.4097                                                                                                    \n",
      "Epoch 9/30\n",
      "6079/6079 [==============================] - 0s 71us/step - loss: 0.3485 - val_loss: 0.3477\n",
      "  val_spearman-rho: 0.4113                                                                                                    \n",
      "Epoch 10/30\n",
      "6079/6079 [==============================] - 0s 67us/step - loss: 0.3482 - val_loss: 0.3491\n",
      "  val_spearman-rho: 0.4186                                                                                                    \n",
      "Epoch 11/30\n",
      "6079/6079 [==============================] - 0s 67us/step - loss: 0.3471 - val_loss: 0.3455\n",
      "  val_spearman-rho: 0.4222                                                                                                    \n",
      "Epoch 12/30\n",
      "6079/6079 [==============================] - 0s 69us/step - loss: 0.3456 - val_loss: 0.3459\n",
      "  val_spearman-rho: 0.4213                                                                                                    \n",
      "Epoch 13/30\n",
      "6079/6079 [==============================] - 0s 66us/step - loss: 0.3448 - val_loss: 0.3428\n",
      "  val_spearman-rho: 0.4244                                                                                                    \n",
      "Epoch 14/30\n",
      "6079/6079 [==============================] - 0s 69us/step - loss: 0.3442 - val_loss: 0.3449\n",
      "  val_spearman-rho: 0.4299                                                                                                    \n",
      "Epoch 15/30\n",
      "6079/6079 [==============================] - 0s 68us/step - loss: 0.3427 - val_loss: 0.3406\n",
      "  val_spearman-rho: 0.4274                                                                                                    \n",
      "Epoch 16/30\n",
      "6079/6079 [==============================] - 0s 69us/step - loss: 0.3417 - val_loss: 0.3399\n",
      "  val_spearman-rho: 0.4316                                                                                                    \n",
      "Epoch 17/30\n",
      "6079/6079 [==============================] - 0s 68us/step - loss: 0.3419 - val_loss: 0.3409\n",
      "  val_spearman-rho: 0.4378                                                                                                    \n",
      "Epoch 18/30\n",
      "6079/6079 [==============================] - 0s 68us/step - loss: 0.3402 - val_loss: 0.3381\n",
      "  val_spearman-rho: 0.4382                                                                                                    \n",
      "Epoch 19/30\n",
      "6079/6079 [==============================] - 0s 67us/step - loss: 0.3399 - val_loss: 0.3385\n",
      "  val_spearman-rho: 0.4393                                                                                                    \n",
      "Epoch 20/30\n",
      "6079/6079 [==============================] - 0s 70us/step - loss: 0.3389 - val_loss: 0.3371\n",
      "  val_spearman-rho: 0.4416                                                                                                    \n",
      "Epoch 21/30\n",
      "6079/6079 [==============================] - 0s 68us/step - loss: 0.3378 - val_loss: 0.3355\n",
      "  val_spearman-rho: 0.4439                                                                                                    \n",
      "Epoch 22/30\n",
      "6079/6079 [==============================] - 0s 65us/step - loss: 0.3374 - val_loss: 0.3346\n",
      "  val_spearman-rho: 0.4438                                                                                                    \n",
      "Epoch 23/30\n",
      "6079/6079 [==============================] - 0s 70us/step - loss: 0.3361 - val_loss: 0.3341\n",
      "  val_spearman-rho: 0.4486                                                                                                    \n",
      "Epoch 24/30\n",
      "6079/6079 [==============================] - 0s 71us/step - loss: 0.3357 - val_loss: 0.3349\n",
      "  val_spearman-rho: 0.4484                                                                                                    \n",
      "Epoch 25/30\n",
      "6079/6079 [==============================] - 0s 69us/step - loss: 0.3343 - val_loss: 0.3323\n",
      "  val_spearman-rho: 0.4522                                                                                                    \n",
      "Epoch 26/30\n",
      "6079/6079 [==============================] - 0s 68us/step - loss: 0.3340 - val_loss: 0.3325\n",
      "  val_spearman-rho: 0.4544                                                                                                    \n",
      "Epoch 27/30\n",
      "6079/6079 [==============================] - 0s 72us/step - loss: 0.3330 - val_loss: 0.3320\n",
      "  val_spearman-rho: 0.4558                                                                                                    \n",
      "Epoch 28/30\n",
      "6079/6079 [==============================] - 0s 67us/step - loss: 0.3319 - val_loss: 0.3289\n",
      "  val_spearman-rho: 0.4602                                                                                                    \n",
      "Epoch 29/30\n",
      "6079/6079 [==============================] - 0s 67us/step - loss: 0.3318 - val_loss: 0.3315\n",
      "  val_spearman-rho: 0.4628                                                                                                    \n",
      "Epoch 30/30\n",
      "6079/6079 [==============================] - 0s 69us/step - loss: 0.3300 - val_loss: 0.3283\n",
      "  val_spearman-rho: 0.4652                                                                                                    \n",
      "  val_spearman-rho: 0.4656                                                                                                    \n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 3040)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 200)               608200    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               102912    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 726,502\n",
      "Trainable params: 726,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/100\n",
      "4863/4863 [==============================] - 1s 174us/step - loss: 0.6183 - bce: 0.5764 - logcosh: 0.0419 - val_loss: 0.4356 - val_bce: 0.4101 - val_logcosh: 0.0255\n",
      "  val_spearman-rho: 0.2439                                                                                                    \n",
      "  reload best: 0.2439\n",
      "Epoch 2/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.4630 - bce: 0.4337 - logcosh: 0.0293 - val_loss: 0.4165 - val_bce: 0.3933 - val_logcosh: 0.0232\n",
      "  val_spearman-rho: 0.2722                                                                                                    \n",
      "  reload best: 0.2722\n",
      "Epoch 3/100\n",
      "4863/4863 [==============================] - 1s 104us/step - loss: 0.4441 - bce: 0.4173 - logcosh: 0.0269 - val_loss: 0.4223 - val_bce: 0.3985 - val_logcosh: 0.0238\n",
      "  val_spearman-rho: 0.2809                                                                                                    \n",
      "  reload best: 0.2809\n",
      "Epoch 4/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.4341 - bce: 0.4085 - logcosh: 0.0255 - val_loss: 0.4213 - val_bce: 0.3979 - val_logcosh: 0.0234\n",
      "  val_spearman-rho: 0.2867                                                                                                    \n",
      "  reload best: 0.2867\n",
      "Epoch 5/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.4262 - bce: 0.4018 - logcosh: 0.0245 - val_loss: 0.4085 - val_bce: 0.3864 - val_logcosh: 0.0221\n",
      "  val_spearman-rho: 0.2928                                                                                                    \n",
      "  reload best: 0.2928\n",
      "Epoch 6/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.4215 - bce: 0.3977 - logcosh: 0.0238 - val_loss: 0.4175 - val_bce: 0.3939 - val_logcosh: 0.0236\n",
      "  val_spearman-rho: 0.2914                                                                                                    \n",
      "  reload best: 0.2928\n",
      "Epoch 7/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.4195 - bce: 0.3959 - logcosh: 0.0236 - val_loss: 0.4081 - val_bce: 0.3861 - val_logcosh: 0.0221\n",
      "  val_spearman-rho: 0.2952                                                                                                    \n",
      "  reload best: 0.2952\n",
      "Epoch 8/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.4149 - bce: 0.3920 - logcosh: 0.0229 - val_loss: 0.4081 - val_bce: 0.3861 - val_logcosh: 0.0220\n",
      "  val_spearman-rho: 0.2999                                                                                                    \n",
      "  reload best: 0.2999\n",
      "Epoch 9/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.4110 - bce: 0.3886 - logcosh: 0.0224 - val_loss: 0.4079 - val_bce: 0.3862 - val_logcosh: 0.0217\n",
      "  val_spearman-rho: 0.309                                                                                                    \n",
      "  reload best: 0.309\n",
      "Epoch 10/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.4095 - bce: 0.3873 - logcosh: 0.0222 - val_loss: 0.4021 - val_bce: 0.3810 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3104                                                                                                    \n",
      "  reload best: 0.3104\n",
      "Epoch 11/100\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.4055 - bce: 0.3838 - logcosh: 0.0216 - val_loss: 0.4120 - val_bce: 0.3897 - val_logcosh: 0.0223\n",
      "  val_spearman-rho: 0.3032                                                                                                    \n",
      "  reload best: 0.3104\n",
      "Epoch 12/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.4043 - bce: 0.3828 - logcosh: 0.0215 - val_loss: 0.4054 - val_bce: 0.3839 - val_logcosh: 0.0215\n",
      "  val_spearman-rho: 0.3099                                                                                                    \n",
      "  reload best: 0.3104\n",
      "Epoch 13/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.4065 - bce: 0.3846 - logcosh: 0.0219 - val_loss: 0.4007 - val_bce: 0.3797 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3104                                                                                                    \n",
      "  reload best: 0.3104\n",
      "Epoch 14/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.4010 - bce: 0.3799 - logcosh: 0.0211 - val_loss: 0.4040 - val_bce: 0.3828 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.3131                                                                                                    \n",
      "  reload best: 0.3131\n",
      "Epoch 15/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.4001 - bce: 0.3793 - logcosh: 0.0209 - val_loss: 0.4066 - val_bce: 0.3852 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.3134                                                                                                    \n",
      "  reload best: 0.3134\n",
      "Epoch 16/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3979 - bce: 0.3772 - logcosh: 0.0207 - val_loss: 0.3993 - val_bce: 0.3786 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3141                                                                                                    \n",
      "  reload best: 0.3141\n",
      "Epoch 17/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3972 - bce: 0.3767 - logcosh: 0.0205 - val_loss: 0.4021 - val_bce: 0.3810 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3128                                                                                                    \n",
      "  reload best: 0.3141\n",
      "Epoch 18/100\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.3980 - bce: 0.3773 - logcosh: 0.0206 - val_loss: 0.4014 - val_bce: 0.3804 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3157                                                                                                    \n",
      "  reload best: 0.3157\n",
      "Epoch 19/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3955 - bce: 0.3752 - logcosh: 0.0203 - val_loss: 0.4127 - val_bce: 0.3908 - val_logcosh: 0.0219\n",
      "  val_spearman-rho: 0.3198                                                                                                    \n",
      "  reload best: 0.3198\n",
      "Epoch 20/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3928 - bce: 0.3729 - logcosh: 0.0200 - val_loss: 0.4023 - val_bce: 0.3812 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3171                                                                                                    \n",
      "  reload best: 0.3198\n",
      "Epoch 21/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3947 - bce: 0.3745 - logcosh: 0.0202 - val_loss: 0.4063 - val_bce: 0.3847 - val_logcosh: 0.0217\n",
      "  val_spearman-rho: 0.3105                                                                                                    \n",
      "  reload best: 0.3198\n",
      "Epoch 22/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3937 - bce: 0.3736 - logcosh: 0.0201 - val_loss: 0.4019 - val_bce: 0.3807 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3169                                                                                                    \n",
      "  reload best: 0.3198\n",
      "Epoch 23/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3930 - bce: 0.3730 - logcosh: 0.0200 - val_loss: 0.4039 - val_bce: 0.3828 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3131                                                                                                    \n",
      "  reload best: 0.3198\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 24/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3834 - bce: 0.3648 - logcosh: 0.0187 - val_loss: 0.3960 - val_bce: 0.3757 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3168                                                                                                    \n",
      "  reload best: 0.3198\n",
      "Epoch 25/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3829 - bce: 0.3644 - logcosh: 0.0186 - val_loss: 0.3962 - val_bce: 0.3759 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3149                                                                                                    \n",
      "  reload best: 0.3198\n",
      "Epoch 26/100\n",
      "4863/4863 [==============================] - 1s 103us/step - loss: 0.3829 - bce: 0.3643 - logcosh: 0.0186 - val_loss: 0.3959 - val_bce: 0.3756 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3197                                                                                                    \n",
      "  reload best: 0.3198\n",
      "Epoch 27/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3831 - bce: 0.3645 - logcosh: 0.0186 - val_loss: 0.3972 - val_bce: 0.3768 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.3154                                                                                                    \n",
      "  reload best: 0.3198\n",
      "Epoch 28/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3830 - bce: 0.3644 - logcosh: 0.0186 - val_loss: 0.3959 - val_bce: 0.3757 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3066                                                                                                    \n",
      "  reload best: 0.3198\n",
      "Epoch 29/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3832 - bce: 0.3646 - logcosh: 0.0186 - val_loss: 0.3963 - val_bce: 0.3760 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3133                                                                                                    \n",
      "  reload best: 0.3198\n",
      "Epoch 30/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3822 - bce: 0.3637 - logcosh: 0.0185 - val_loss: 0.3959 - val_bce: 0.3756 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3199                                                                                                    \n",
      "  reload best: 0.3199\n",
      "Epoch 31/100\n",
      "4863/4863 [==============================] - 1s 104us/step - loss: 0.3799 - bce: 0.3617 - logcosh: 0.0182 - val_loss: 0.3965 - val_bce: 0.3762 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3204                                                                                                    \n",
      "  reload best: 0.3204\n",
      "Epoch 32/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3793 - bce: 0.3611 - logcosh: 0.0181 - val_loss: 0.3968 - val_bce: 0.3765 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.3199                                                                                                    \n",
      "  reload best: 0.3204\n",
      "Epoch 33/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.3792 - bce: 0.3611 - logcosh: 0.0181 - val_loss: 0.3959 - val_bce: 0.3757 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3125                                                                                                    \n",
      "  reload best: 0.3204\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 5.000000237487257e-06.\n",
      "Epoch 34/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3782 - bce: 0.3603 - logcosh: 0.0180 - val_loss: 0.3950 - val_bce: 0.3749 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3141                                                                                                    \n",
      "  reload best: 0.3204\n",
      "Epoch 35/100\n",
      "4863/4863 [==============================] - 1s 103us/step - loss: 0.3781 - bce: 0.3602 - logcosh: 0.0180 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3225                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 36/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3777 - bce: 0.3598 - logcosh: 0.0179 - val_loss: 0.3951 - val_bce: 0.3750 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3191                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 37/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3775 - bce: 0.3596 - logcosh: 0.0179 - val_loss: 0.3952 - val_bce: 0.3750 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3155                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 38/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3774 - bce: 0.3596 - logcosh: 0.0179 - val_loss: 0.3950 - val_bce: 0.3749 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3132                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 39/100\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.3776 - bce: 0.3597 - logcosh: 0.0179 - val_loss: 0.3951 - val_bce: 0.3749 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3165                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 40/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3780 - bce: 0.3600 - logcosh: 0.0179 - val_loss: 0.3951 - val_bce: 0.3749 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3178                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 41/100\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.3775 - bce: 0.3596 - logcosh: 0.0179 - val_loss: 0.3952 - val_bce: 0.3750 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3159                                                                                                    \n",
      "  reload best: 0.3225\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 42/100\n",
      "4863/4863 [==============================] - 0s 100us/step - loss: 0.3774 - bce: 0.3595 - logcosh: 0.0179 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3141                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 43/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3776 - bce: 0.3597 - logcosh: 0.0179 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3153                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 44/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3772 - bce: 0.3593 - logcosh: 0.0178 - val_loss: 0.3949 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3197                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 45/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3773 - bce: 0.3595 - logcosh: 0.0178 - val_loss: 0.3949 - val_bce: 0.3748 - val_logcosh: 0.0201\n",
      "  val_spearman-rho: 0.317                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 46/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.3775 - bce: 0.3596 - logcosh: 0.0179 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3105                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 47/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3779 - bce: 0.3599 - logcosh: 0.0179 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3177                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 48/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3773 - bce: 0.3595 - logcosh: 0.0178 - val_loss: 0.3949 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.319                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 49/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3775 - bce: 0.3596 - logcosh: 0.0179 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.313                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 50/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3771 - bce: 0.3593 - logcosh: 0.0178 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3211                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 51/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3770 - bce: 0.3592 - logcosh: 0.0178 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3202                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 52/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3774 - bce: 0.3596 - logcosh: 0.0179 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3209                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 53/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3775 - bce: 0.3596 - logcosh: 0.0179 - val_loss: 0.3949 - val_bce: 0.3748 - val_logcosh: 0.0201\n",
      "  val_spearman-rho: 0.319                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 54/100\n",
      "4863/4863 [==============================] - 0s 102us/step - loss: 0.3774 - bce: 0.3595 - logcosh: 0.0179 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0201\n",
      "  val_spearman-rho: 0.3209                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 55/100\n",
      "4863/4863 [==============================] - 1s 103us/step - loss: 0.3771 - bce: 0.3593 - logcosh: 0.0178 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3157                                                                                                    \n",
      "  reload best: 0.3225\n",
      "Epoch 56/100\n",
      "4863/4863 [==============================] - 1s 114us/step - loss: 0.3776 - bce: 0.3597 - logcosh: 0.0179 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3255                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 57/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3774 - bce: 0.3596 - logcosh: 0.0179 - val_loss: 0.3949 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3133                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 58/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.3770 - bce: 0.3592 - logcosh: 0.0178 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3203                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 59/100\n",
      "4863/4863 [==============================] - 1s 105us/step - loss: 0.3776 - bce: 0.3597 - logcosh: 0.0179 - val_loss: 0.3949 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3176                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 60/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3774 - bce: 0.3595 - logcosh: 0.0179 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3192                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 61/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3771 - bce: 0.3593 - logcosh: 0.0178 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3146                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 62/100\n",
      "4863/4863 [==============================] - 0s 100us/step - loss: 0.3776 - bce: 0.3597 - logcosh: 0.0179 - val_loss: 0.3949 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3203                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 63/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3769 - bce: 0.3591 - logcosh: 0.0178 - val_loss: 0.3949 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3137                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 64/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3777 - bce: 0.3598 - logcosh: 0.0179 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3289                                                                                                    \n",
      "  reload best: 0.3289\n",
      "Epoch 65/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3772 - bce: 0.3594 - logcosh: 0.0178 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3179                                                                                                    \n",
      "  reload best: 0.3289\n",
      "Epoch 66/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3770 - bce: 0.3592 - logcosh: 0.0178 - val_loss: 0.3950 - val_bce: 0.3749 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3161                                                                                                    \n",
      "  reload best: 0.3289\n",
      "Epoch 67/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3770 - bce: 0.3592 - logcosh: 0.0178 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3097                                                                                                    \n",
      "  reload best: 0.3289\n",
      "Epoch 68/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3770 - bce: 0.3592 - logcosh: 0.0178 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3176                                                                                                    \n",
      "  reload best: 0.3289\n",
      "  val_spearman-rho: 0.3163                                                                                                    \n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/50\n",
      "4863/4863 [==============================] - 1s 149us/step - loss: 0.4072 - bce: 0.3852 - logcosh: 0.0220 - val_loss: 0.4211 - val_bce: 0.3973 - val_logcosh: 0.0237\n",
      "  val_spearman-rho: 0.3146                                                                                                    \n",
      "Epoch 2/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.4058 - bce: 0.3840 - logcosh: 0.0218 - val_loss: 0.4215 - val_bce: 0.3975 - val_logcosh: 0.0240\n",
      "  val_spearman-rho: 0.3185                                                                                                    \n",
      "Epoch 3/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.4053 - bce: 0.3836 - logcosh: 0.0217 - val_loss: 0.4154 - val_bce: 0.3922 - val_logcosh: 0.0232\n",
      "  val_spearman-rho: 0.3181                                                                                                    \n",
      "Epoch 4/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.4055 - bce: 0.3838 - logcosh: 0.0217 - val_loss: 0.4177 - val_bce: 0.3941 - val_logcosh: 0.0236\n",
      "  val_spearman-rho: 0.3135                                                                                                    \n",
      "Epoch 5/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.4049 - bce: 0.3832 - logcosh: 0.0217 - val_loss: 0.4171 - val_bce: 0.3936 - val_logcosh: 0.0234\n",
      "  val_spearman-rho: 0.3167                                                                                                    \n",
      "Epoch 6/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.4044 - bce: 0.3827 - logcosh: 0.0217 - val_loss: 0.4185 - val_bce: 0.3947 - val_logcosh: 0.0238\n",
      "  val_spearman-rho: 0.3166                                                                                                    \n",
      "Epoch 7/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.4041 - bce: 0.3825 - logcosh: 0.0216 - val_loss: 0.4215 - val_bce: 0.3984 - val_logcosh: 0.0231\n",
      "  val_spearman-rho: 0.3162                                                                                                    \n",
      "Epoch 8/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.4046 - bce: 0.3830 - logcosh: 0.0216 - val_loss: 0.4216 - val_bce: 0.3973 - val_logcosh: 0.0243\n",
      "  val_spearman-rho: 0.3141                                                                                                    \n",
      "Epoch 9/50\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.4038 - bce: 0.3823 - logcosh: 0.0215 - val_loss: 0.4204 - val_bce: 0.3979 - val_logcosh: 0.0225\n",
      "  val_spearman-rho: 0.3115                                                                                                    \n",
      "Epoch 10/50\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.4045 - bce: 0.3829 - logcosh: 0.0216 - val_loss: 0.4165 - val_bce: 0.3931 - val_logcosh: 0.0233\n",
      "  val_spearman-rho: 0.3154                                                                                                    \n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 11/50\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3800 - bce: 0.3618 - logcosh: 0.0183 - val_loss: 0.3954 - val_bce: 0.3752 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3153                                                                                                    \n",
      "Epoch 12/50\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3788 - bce: 0.3607 - logcosh: 0.0181 - val_loss: 0.3958 - val_bce: 0.3755 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3127                                                                                                    \n",
      "Epoch 13/50\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.3782 - bce: 0.3602 - logcosh: 0.0180 - val_loss: 0.3955 - val_bce: 0.3752 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3211                                                                                                    \n",
      "Epoch 14/50\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3784 - bce: 0.3604 - logcosh: 0.0180 - val_loss: 0.3955 - val_bce: 0.3752 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3185                                                                                                    \n",
      "Epoch 15/50\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3781 - bce: 0.3601 - logcosh: 0.0180 - val_loss: 0.3956 - val_bce: 0.3754 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3136                                                                                                    \n",
      "Epoch 16/50\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.3782 - bce: 0.3602 - logcosh: 0.0180 - val_loss: 0.3961 - val_bce: 0.3758 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3126                                                                                                    \n",
      "Epoch 17/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3783 - bce: 0.3603 - logcosh: 0.0180 - val_loss: 0.3951 - val_bce: 0.3750 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3192                                                                                                    \n",
      "Epoch 18/50\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3778 - bce: 0.3599 - logcosh: 0.0179 - val_loss: 0.3958 - val_bce: 0.3755 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3239                                                                                                    \n",
      "Epoch 19/50\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3781 - bce: 0.3602 - logcosh: 0.0180 - val_loss: 0.3957 - val_bce: 0.3754 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3147                                                                                                    \n",
      "Epoch 20/50\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.3780 - bce: 0.3601 - logcosh: 0.0179 - val_loss: 0.3953 - val_bce: 0.3750 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3173                                                                                                    \n",
      "Epoch 21/50\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.3781 - bce: 0.3601 - logcosh: 0.0180 - val_loss: 0.3954 - val_bce: 0.3752 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3213                                                                                                    \n",
      "Epoch 22/50\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3775 - bce: 0.3596 - logcosh: 0.0179 - val_loss: 0.3957 - val_bce: 0.3755 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3225                                                                                                    \n",
      "Epoch 23/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3784 - bce: 0.3604 - logcosh: 0.0180 - val_loss: 0.3953 - val_bce: 0.3751 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3195                                                                                                    \n",
      "Epoch 24/50\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3782 - bce: 0.3602 - logcosh: 0.0180 - val_loss: 0.3955 - val_bce: 0.3753 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3205                                                                                                    \n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 25/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3773 - bce: 0.3594 - logcosh: 0.0179 - val_loss: 0.3950 - val_bce: 0.3749 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3252                                                                                                    \n",
      "Epoch 26/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3774 - bce: 0.3596 - logcosh: 0.0179 - val_loss: 0.3949 - val_bce: 0.3748 - val_logcosh: 0.0201\n",
      "  val_spearman-rho: 0.3213                                                                                                    \n",
      "Epoch 27/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3772 - bce: 0.3594 - logcosh: 0.0179 - val_loss: 0.3949 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3188                                                                                                    \n",
      "Epoch 28/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3774 - bce: 0.3595 - logcosh: 0.0178 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3161                                                                                                    \n",
      "Epoch 29/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3771 - bce: 0.3593 - logcosh: 0.0178 - val_loss: 0.3949 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3208                                                                                                    \n",
      "Epoch 30/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3774 - bce: 0.3595 - logcosh: 0.0179 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3168                                                                                                    \n",
      "Epoch 31/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3770 - bce: 0.3592 - logcosh: 0.0178 - val_loss: 0.3950 - val_bce: 0.3748 - val_logcosh: 0.0201\n",
      "  val_spearman-rho: 0.3121                                                                                                    \n",
      "Epoch 32/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3771 - bce: 0.3593 - logcosh: 0.0178 - val_loss: 0.3949 - val_bce: 0.3747 - val_logcosh: 0.0201\n",
      "  val_spearman-rho: 0.3176                                                                                                    \n",
      "Epoch 33/50\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.4244 - bce: 0.4004 - logcosh: 0.0241 - val_loss: 0.4156 - val_bce: 0.3921 - val_logcosh: 0.0235\n",
      "  val_spearman-rho: 0.2957                                                                                                    \n",
      "  reload best: 0.2957\n",
      "Epoch 6/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.4177 - bce: 0.3945 - logcosh: 0.0232 - val_loss: 0.4087 - val_bce: 0.3862 - val_logcosh: 0.0225\n",
      "  val_spearman-rho: 0.2946                                                                                                    \n",
      "  reload best: 0.2957\n",
      "Epoch 7/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.4205 - bce: 0.3969 - logcosh: 0.0236 - val_loss: 0.4119 - val_bce: 0.3891 - val_logcosh: 0.0228\n",
      "  val_spearman-rho: 0.2989                                                                                                    \n",
      "  reload best: 0.2989\n",
      "Epoch 8/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.4142 - bce: 0.3915 - logcosh: 0.0227 - val_loss: 0.4076 - val_bce: 0.3852 - val_logcosh: 0.0223\n",
      "  val_spearman-rho: 0.2921                                                                                                    \n",
      "  reload best: 0.2989\n",
      "Epoch 9/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.4167 - bce: 0.3936 - logcosh: 0.0231 - val_loss: 0.4108 - val_bce: 0.3880 - val_logcosh: 0.0227\n",
      "  val_spearman-rho: 0.2934                                                                                                    \n",
      "  reload best: 0.2989\n",
      "Epoch 10/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.4162 - bce: 0.3932 - logcosh: 0.0230 - val_loss: 0.4121 - val_bce: 0.3894 - val_logcosh: 0.0227\n",
      "  val_spearman-rho: 0.2941                                                                                                    \n",
      "  reload best: 0.2989\n",
      "Epoch 11/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.4147 - bce: 0.3919 - logcosh: 0.0228 - val_loss: 0.4095 - val_bce: 0.3872 - val_logcosh: 0.0223\n",
      "  val_spearman-rho: 0.2953                                                                                                    \n",
      "  reload best: 0.2989\n",
      "Epoch 12/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.4153 - bce: 0.3924 - logcosh: 0.0229 - val_loss: 0.4070 - val_bce: 0.3848 - val_logcosh: 0.0221\n",
      "  val_spearman-rho: 0.2972                                                                                                    \n",
      "  reload best: 0.2989\n",
      "Epoch 13/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.4137 - bce: 0.3910 - logcosh: 0.0227 - val_loss: 0.4101 - val_bce: 0.3874 - val_logcosh: 0.0227\n",
      "  val_spearman-rho: 0.2994                                                                                                    \n",
      "  reload best: 0.2994\n",
      "Epoch 14/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.4134 - bce: 0.3908 - logcosh: 0.0226 - val_loss: 0.4039 - val_bce: 0.3821 - val_logcosh: 0.0218\n",
      "  val_spearman-rho: 0.2997                                                                                                    \n",
      "  reload best: 0.2997\n",
      "Epoch 15/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.4070 - bce: 0.3852 - logcosh: 0.0218 - val_loss: 0.4164 - val_bce: 0.3930 - val_logcosh: 0.0234\n",
      "  val_spearman-rho: 0.3                                                                                                    \n",
      "  reload best: 0.3\n",
      "Epoch 16/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.4039 - bce: 0.3826 - logcosh: 0.0213 - val_loss: 0.4141 - val_bce: 0.3909 - val_logcosh: 0.0232\n",
      "  val_spearman-rho: 0.3017                                                                                                    \n",
      "  reload best: 0.3017\n",
      "Epoch 17/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.4010 - bce: 0.3800 - logcosh: 0.0210 - val_loss: 0.4108 - val_bce: 0.3885 - val_logcosh: 0.0223\n",
      "  val_spearman-rho: 0.305                                                                                                    \n",
      "  reload best: 0.305\n",
      "Epoch 18/100\n",
      "4863/4863 [==============================] - 0s 100us/step - loss: 0.3991 - bce: 0.3785 - logcosh: 0.0207 - val_loss: 0.4070 - val_bce: 0.3846 - val_logcosh: 0.0223\n",
      "  val_spearman-rho: 0.3048                                                                                                    \n",
      "  reload best: 0.305\n",
      "Epoch 19/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3995 - bce: 0.3788 - logcosh: 0.0207 - val_loss: 0.4109 - val_bce: 0.3886 - val_logcosh: 0.0224\n",
      "  val_spearman-rho: 0.2962                                                                                                    \n",
      "  reload best: 0.305\n",
      "Epoch 20/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.4007 - bce: 0.3798 - logcosh: 0.0209 - val_loss: 0.4069 - val_bce: 0.3847 - val_logcosh: 0.0222\n",
      "  val_spearman-rho: 0.3047                                                                                                    \n",
      "  reload best: 0.305\n",
      "Epoch 21/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.4002 - bce: 0.3794 - logcosh: 0.0208 - val_loss: 0.4061 - val_bce: 0.3838 - val_logcosh: 0.0223\n",
      "  val_spearman-rho: 0.3065                                                                                                    \n",
      "  reload best: 0.3065\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 22/100\n",
      "4863/4863 [==============================] - 0s 102us/step - loss: 0.3883 - bce: 0.3691 - logcosh: 0.0192 - val_loss: 0.3993 - val_bce: 0.3781 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.309                                                                                                    \n",
      "  reload best: 0.309\n",
      "Epoch 23/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3854 - bce: 0.3666 - logcosh: 0.0188 - val_loss: 0.3996 - val_bce: 0.3784 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.3029                                                                                                    \n",
      "  reload best: 0.309\n",
      "Epoch 24/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3852 - bce: 0.3665 - logcosh: 0.0188 - val_loss: 0.3990 - val_bce: 0.3778 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3114                                                                                                    \n",
      "  reload best: 0.3114\n",
      "Epoch 25/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3846 - bce: 0.3659 - logcosh: 0.0187 - val_loss: 0.3988 - val_bce: 0.3777 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3069                                                                                                    \n",
      "  reload best: 0.3114\n",
      "Epoch 26/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3842 - bce: 0.3656 - logcosh: 0.0186 - val_loss: 0.3997 - val_bce: 0.3785 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.3044                                                                                                    \n",
      "  reload best: 0.3114\n",
      "Epoch 27/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3842 - bce: 0.3655 - logcosh: 0.0187 - val_loss: 0.3996 - val_bce: 0.3784 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.3053                                                                                                    \n",
      "  reload best: 0.3114\n",
      "Epoch 28/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3846 - bce: 0.3659 - logcosh: 0.0187 - val_loss: 0.3993 - val_bce: 0.3781 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.308                                                                                                    \n",
      "  reload best: 0.3114\n",
      "Epoch 29/100\n",
      "4863/4863 [==============================] - 0s 100us/step - loss: 0.3845 - bce: 0.3658 - logcosh: 0.0187 - val_loss: 0.3993 - val_bce: 0.3781 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.3011                                                                                                    \n",
      "  reload best: 0.3114\n",
      "Epoch 30/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3845 - bce: 0.3658 - logcosh: 0.0187 - val_loss: 0.4004 - val_bce: 0.3791 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.3071                                                                                                    \n",
      "  reload best: 0.3114\n",
      "Epoch 31/100\n",
      "4863/4863 [==============================] - 1s 104us/step - loss: 0.3846 - bce: 0.3659 - logcosh: 0.0187 - val_loss: 0.4004 - val_bce: 0.3791 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3074                                                                                                    \n",
      "  reload best: 0.3114\n",
      "Epoch 32/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3843 - bce: 0.3657 - logcosh: 0.0187 - val_loss: 0.4002 - val_bce: 0.3789 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3023                                                                                                    \n",
      "  reload best: 0.3114\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 5.000000237487257e-06.\n",
      "Epoch 33/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3833 - bce: 0.3647 - logcosh: 0.0185 - val_loss: 0.3987 - val_bce: 0.3776 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3053                                                                                                    \n",
      "  reload best: 0.3114\n",
      "Epoch 34/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3834 - bce: 0.3648 - logcosh: 0.0185 - val_loss: 0.3986 - val_bce: 0.3775 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3088                                                                                                    \n",
      "  reload best: 0.3114\n",
      "Epoch 35/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3831 - bce: 0.3646 - logcosh: 0.0185 - val_loss: 0.3985 - val_bce: 0.3774 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.314                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 36/100\n",
      "4863/4863 [==============================] - 0s 102us/step - loss: 0.3833 - bce: 0.3648 - logcosh: 0.0185 - val_loss: 0.3984 - val_bce: 0.3774 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3124                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 37/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3824 - bce: 0.3640 - logcosh: 0.0184 - val_loss: 0.3986 - val_bce: 0.3775 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3097                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 38/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.3832 - bce: 0.3647 - logcosh: 0.0185 - val_loss: 0.3986 - val_bce: 0.3775 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3128                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 39/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3828 - bce: 0.3643 - logcosh: 0.0184 - val_loss: 0.3985 - val_bce: 0.3775 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3077                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 40/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3826 - bce: 0.3642 - logcosh: 0.0184 - val_loss: 0.3987 - val_bce: 0.3776 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3057                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 41/100\n",
      "4863/4863 [==============================] - 0s 102us/step - loss: 0.3826 - bce: 0.3642 - logcosh: 0.0184 - val_loss: 0.3984 - val_bce: 0.3774 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3088                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 42/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3829 - bce: 0.3645 - logcosh: 0.0185 - val_loss: 0.3984 - val_bce: 0.3773 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3048                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 43/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3829 - bce: 0.3644 - logcosh: 0.0184 - val_loss: 0.3985 - val_bce: 0.3775 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3028                                                                                                    \n",
      "  reload best: 0.314\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 44/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3829 - bce: 0.3644 - logcosh: 0.0185 - val_loss: 0.3984 - val_bce: 0.3774 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.309                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 45/100\n",
      "4863/4863 [==============================] - 1s 105us/step - loss: 0.3826 - bce: 0.3641 - logcosh: 0.0184 - val_loss: 0.3984 - val_bce: 0.3774 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.305                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 46/100\n",
      "4863/4863 [==============================] - 1s 108us/step - loss: 0.3827 - bce: 0.3643 - logcosh: 0.0184 - val_loss: 0.3984 - val_bce: 0.3774 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3097                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 47/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3824 - bce: 0.3640 - logcosh: 0.0184 - val_loss: 0.3984 - val_bce: 0.3774 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.31                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 48/100\n",
      "4863/4863 [==============================] - 0s 100us/step - loss: 0.3831 - bce: 0.3646 - logcosh: 0.0185 - val_loss: 0.3984 - val_bce: 0.3774 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3076                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 49/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3830 - bce: 0.3645 - logcosh: 0.0185 - val_loss: 0.3984 - val_bce: 0.3774 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3104                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 50/100\n",
      "4863/4863 [==============================] - 0s 100us/step - loss: 0.3827 - bce: 0.3643 - logcosh: 0.0184 - val_loss: 0.3984 - val_bce: 0.3774 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3065                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 51/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3830 - bce: 0.3645 - logcosh: 0.0185 - val_loss: 0.3984 - val_bce: 0.3774 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3018                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 52/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3829 - bce: 0.3644 - logcosh: 0.0184 - val_loss: 0.3985 - val_bce: 0.3774 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3094                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 53/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3829 - bce: 0.3644 - logcosh: 0.0185 - val_loss: 0.3985 - val_bce: 0.3774 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3049                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 54/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3826 - bce: 0.3642 - logcosh: 0.0184 - val_loss: 0.3984 - val_bce: 0.3774 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3071                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 55/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3827 - bce: 0.3643 - logcosh: 0.0185 - val_loss: 0.3985 - val_bce: 0.3774 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3022                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 56/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3829 - bce: 0.3644 - logcosh: 0.0185 - val_loss: 0.3984 - val_bce: 0.3774 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3046                                                                                                    \n",
      "  reload best: 0.314\n",
      "Epoch 57/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3829 - bce: 0.3644 - logcosh: 0.0184 - val_loss: 0.3984 - val_bce: 0.3774 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3074                                                                                                    \n",
      "  reload best: 0.314\n",
      "  val_spearman-rho: 0.3091                                                                                                    \n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/50\n",
      "4863/4863 [==============================] - 1s 149us/step - loss: 0.4185 - bce: 0.3949 - logcosh: 0.0236 - val_loss: 0.4307 - val_bce: 0.4051 - val_logcosh: 0.0256\n",
      "  val_spearman-rho: 0.3126                                                                                                    \n",
      "Epoch 2/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.4172 - bce: 0.3938 - logcosh: 0.0234 - val_loss: 0.4321 - val_bce: 0.4062 - val_logcosh: 0.0260\n",
      "  val_spearman-rho: 0.3081                                                                                                    \n",
      "Epoch 3/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.4178 - bce: 0.3944 - logcosh: 0.0234 - val_loss: 0.4388 - val_bce: 0.4117 - val_logcosh: 0.0271\n",
      "  val_spearman-rho: 0.3042                                                                                                    \n",
      "Epoch 4/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.4159 - bce: 0.3927 - logcosh: 0.0232 - val_loss: 0.4365 - val_bce: 0.4097 - val_logcosh: 0.0269\n",
      "  val_spearman-rho: 0.3015                                                                                                    \n",
      "Epoch 5/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.4175 - bce: 0.3940 - logcosh: 0.0235 - val_loss: 0.4294 - val_bce: 0.4038 - val_logcosh: 0.0256\n",
      "  val_spearman-rho: 0.307                                                                                                    \n",
      "Epoch 6/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.4147 - bce: 0.3917 - logcosh: 0.0230 - val_loss: 0.4331 - val_bce: 0.4067 - val_logcosh: 0.0264\n",
      "  val_spearman-rho: 0.3044                                                                                                    \n",
      "Epoch 7/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.4156 - bce: 0.3925 - logcosh: 0.0231 - val_loss: 0.4353 - val_bce: 0.4092 - val_logcosh: 0.0261\n",
      "  val_spearman-rho: 0.3106                                                                                                    \n",
      "Epoch 8/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.4137 - bce: 0.3908 - logcosh: 0.0229 - val_loss: 0.4294 - val_bce: 0.4035 - val_logcosh: 0.0259\n",
      "  val_spearman-rho: 0.3009                                                                                                    \n",
      "Epoch 9/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.4132 - bce: 0.3904 - logcosh: 0.0228 - val_loss: 0.4339 - val_bce: 0.4080 - val_logcosh: 0.0259\n",
      "  val_spearman-rho: 0.2962                                                                                                    \n",
      "Epoch 10/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.4139 - bce: 0.3911 - logcosh: 0.0228 - val_loss: 0.4256 - val_bce: 0.4009 - val_logcosh: 0.0247\n",
      "  val_spearman-rho: 0.3106                                                                                                    \n",
      "Epoch 11/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.4145 - bce: 0.3915 - logcosh: 0.0230 - val_loss: 0.4220 - val_bce: 0.3980 - val_logcosh: 0.0239\n",
      "  val_spearman-rho: 0.3058                                                                                                    \n",
      "Epoch 12/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.4147 - bce: 0.3917 - logcosh: 0.0231 - val_loss: 0.4199 - val_bce: 0.3966 - val_logcosh: 0.0233\n",
      "  val_spearman-rho: 0.3119                                                                                                    \n",
      "Epoch 13/50\n",
      "4863/4863 [==============================] - 0s 81us/step - loss: 0.4136 - bce: 0.3907 - logcosh: 0.0229 - val_loss: 0.4264 - val_bce: 0.4016 - val_logcosh: 0.0248\n",
      "  val_spearman-rho: 0.3055                                                                                                    \n",
      "Epoch 14/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.4130 - bce: 0.3901 - logcosh: 0.0229 - val_loss: 0.4239 - val_bce: 0.3990 - val_logcosh: 0.0249\n",
      "  val_spearman-rho: 0.315                                                                                                    \n",
      "Epoch 15/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.4144 - bce: 0.3914 - logcosh: 0.0230 - val_loss: 0.4260 - val_bce: 0.4007 - val_logcosh: 0.0253\n",
      "  val_spearman-rho: 0.3079                                                                                                    \n",
      "Epoch 16/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.4140 - bce: 0.3910 - logcosh: 0.0230 - val_loss: 0.4311 - val_bce: 0.4049 - val_logcosh: 0.0263\n",
      "  val_spearman-rho: 0.3072                                                                                                    \n",
      "Epoch 17/50\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.4123 - bce: 0.3896 - logcosh: 0.0227 - val_loss: 0.4271 - val_bce: 0.4026 - val_logcosh: 0.0246\n",
      "  val_spearman-rho: 0.3026                                                                                                    \n",
      "Epoch 18/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.4122 - bce: 0.3895 - logcosh: 0.0227 - val_loss: 0.4199 - val_bce: 0.3959 - val_logcosh: 0.0240\n",
      "  val_spearman-rho: 0.3053                                                                                                    \n",
      "Epoch 19/50\n",
      "4863/4863 [==============================] - 0s 81us/step - loss: 0.4118 - bce: 0.3892 - logcosh: 0.0226 - val_loss: 0.4239 - val_bce: 0.3990 - val_logcosh: 0.0249\n",
      "  val_spearman-rho: 0.3063                                                                                                    \n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 20/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3849 - bce: 0.3661 - logcosh: 0.0188 - val_loss: 0.3991 - val_bce: 0.3779 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.3064                                                                                                    \n",
      "Epoch 21/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3839 - bce: 0.3653 - logcosh: 0.0186 - val_loss: 0.3986 - val_bce: 0.3775 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.299                                                                                                    \n",
      "Epoch 22/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3833 - bce: 0.3648 - logcosh: 0.0185 - val_loss: 0.3986 - val_bce: 0.3776 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3127                                                                                                    \n",
      "Epoch 23/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3831 - bce: 0.3646 - logcosh: 0.0185 - val_loss: 0.3991 - val_bce: 0.3780 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.312                                                                                                    \n",
      "Epoch 24/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3836 - bce: 0.3651 - logcosh: 0.0186 - val_loss: 0.3996 - val_bce: 0.3784 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.3059                                                                                                    \n",
      "Epoch 25/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3835 - bce: 0.3650 - logcosh: 0.0186 - val_loss: 0.3994 - val_bce: 0.3782 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.3038                                                                                                    \n",
      "Epoch 26/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3836 - bce: 0.3650 - logcosh: 0.0186 - val_loss: 0.3993 - val_bce: 0.3781 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.3116                                                                                                    \n",
      "Epoch 27/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3835 - bce: 0.3649 - logcosh: 0.0186 - val_loss: 0.3992 - val_bce: 0.3780 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.3104                                                                                                    \n",
      "Epoch 28/50\n",
      "4863/4863 [==============================] - 0s 80us/step - loss: 0.3835 - bce: 0.3649 - logcosh: 0.0186 - val_loss: 0.3985 - val_bce: 0.3774 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.298                                                                                                    \n",
      "Epoch 29/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3833 - bce: 0.3648 - logcosh: 0.0185 - val_loss: 0.3989 - val_bce: 0.3778 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3124                                                                                                    \n",
      "Epoch 30/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3836 - bce: 0.3650 - logcosh: 0.0186 - val_loss: 0.3988 - val_bce: 0.3777 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3163                                                                                                    \n",
      "Epoch 31/50\n",
      "4863/4863 [==============================] - 0s 80us/step - loss: 0.3833 - bce: 0.3647 - logcosh: 0.0185 - val_loss: 0.3985 - val_bce: 0.3775 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3114                                                                                                    \n",
      "Epoch 32/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3835 - bce: 0.3649 - logcosh: 0.0186 - val_loss: 0.3989 - val_bce: 0.3778 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3034                                                                                                    \n",
      "Epoch 33/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3836 - bce: 0.3650 - logcosh: 0.0186 - val_loss: 0.3988 - val_bce: 0.3777 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3008                                                                                                    \n",
      "Epoch 34/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3833 - bce: 0.3648 - logcosh: 0.0185 - val_loss: 0.3989 - val_bce: 0.3778 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3067                                                                                                    \n",
      "Epoch 35/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3833 - bce: 0.3647 - logcosh: 0.0185 - val_loss: 0.3989 - val_bce: 0.3778 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3081                                                                                                    \n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 36/50\n",
      "4863/4863 [==============================] - 0s 80us/step - loss: 0.3828 - bce: 0.3643 - logcosh: 0.0185 - val_loss: 0.3983 - val_bce: 0.3773 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3068                                                                                                    \n",
      "Epoch 37/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3828 - bce: 0.3643 - logcosh: 0.0185 - val_loss: 0.3982 - val_bce: 0.3772 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3174                                                                                                    \n",
      "Epoch 38/50\n",
      "4863/4863 [==============================] - 0s 81us/step - loss: 0.3827 - bce: 0.3642 - logcosh: 0.0184 - val_loss: 0.3982 - val_bce: 0.3772 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3022                                                                                                    \n",
      "Epoch 39/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3823 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.3983 - val_bce: 0.3773 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3047                                                                                                    \n",
      "Epoch 40/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3825 - bce: 0.3641 - logcosh: 0.0184 - val_loss: 0.3982 - val_bce: 0.3772 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.308                                                                                                    \n",
      "Epoch 41/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3825 - bce: 0.3641 - logcosh: 0.0184 - val_loss: 0.3983 - val_bce: 0.3773 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3065                                                                                                    \n",
      "Epoch 42/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3823 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.3984 - val_bce: 0.3773 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3028                                                                                                    \n",
      "Epoch 43/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3826 - bce: 0.3642 - logcosh: 0.0184 - val_loss: 0.3984 - val_bce: 0.3773 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3063                                                                                                    \n",
      "Epoch 44/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3824 - bce: 0.3640 - logcosh: 0.0184 - val_loss: 0.3984 - val_bce: 0.3773 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3113                                                                                                    \n",
      "Epoch 45/50\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3830 - bce: 0.3645 - logcosh: 0.0185 - val_loss: 0.3983 - val_bce: 0.3772 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3021                                                                                                    \n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 46/50\n",
      "4863/4863 [==============================] - 0s 82us/step - loss: 0.3823 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.3983 - val_bce: 0.3772 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3065                                                                                                    \n",
      "Epoch 47/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3827 - bce: 0.3642 - logcosh: 0.0184 - val_loss: 0.3983 - val_bce: 0.3772 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3022                                                                                                    \n",
      "Epoch 48/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3827 - bce: 0.3642 - logcosh: 0.0184 - val_loss: 0.3983 - val_bce: 0.3772 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3108                                                                                                    \n",
      "Epoch 49/50\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3822 - bce: 0.3638 - logcosh: 0.0184 - val_loss: 0.3983 - val_bce: 0.3772 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3007                                                                                                    \n",
      "Epoch 50/50\n",
      "4863/4863 [==============================] - 0s 81us/step - loss: 0.3823 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.3983 - val_bce: 0.3772 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3088                                                                                                    \n",
      "  val_spearman-rho: 0.3153                                                                                                    \n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 3040)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                194624    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 30)                3870      \n",
      "=================================================================\n",
      "Total params: 206,814\n",
      "Trainable params: 206,814\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4864 samples, validate on 1215 samples\n",
      "Epoch 1/100\n",
      "4864/4864 [==============================] - 1s 175us/step - loss: 0.6422 - bce: 0.5942 - logcosh: 0.0480 - val_loss: 0.4418 - val_bce: 0.4155 - val_logcosh: 0.0264\n",
      "  val_spearman-rho: 0.1705                                                                                                    \n",
      "  reload best: 0.1705\n",
      "Epoch 2/100\n",
      "4864/4864 [==============================] - 0s 98us/step - loss: 0.4594 - bce: 0.4302 - logcosh: 0.0292 - val_loss: 0.4274 - val_bce: 0.4030 - val_logcosh: 0.0244\n",
      "  val_spearman-rho: 0.2228                                                                                                    \n",
      "  reload best: 0.2228\n",
      "Epoch 3/100\n",
      "4864/4864 [==============================] - 0s 102us/step - loss: 0.4420 - bce: 0.4152 - logcosh: 0.0268 - val_loss: 0.4216 - val_bce: 0.3980 - val_logcosh: 0.0236\n",
      "  val_spearman-rho: 0.2402                                                                                                    \n",
      "  reload best: 0.2402\n",
      "Epoch 4/100\n",
      "4864/4864 [==============================] - 0s 96us/step - loss: 0.4319 - bce: 0.4065 - logcosh: 0.0254 - val_loss: 0.4177 - val_bce: 0.3947 - val_logcosh: 0.0231\n",
      "  val_spearman-rho: 0.2557                                                                                                    \n",
      "  reload best: 0.2557\n",
      "Epoch 5/100\n",
      "4864/4864 [==============================] - 0s 91us/step - loss: 0.4264 - bce: 0.4018 - logcosh: 0.0246 - val_loss: 0.4197 - val_bce: 0.3964 - val_logcosh: 0.0233\n",
      "  val_spearman-rho: 0.2779                                                                                                    \n",
      "  reload best: 0.2779\n",
      "Epoch 6/100\n",
      "4864/4864 [==============================] - 0s 93us/step - loss: 0.4207 - bce: 0.3969 - logcosh: 0.0238 - val_loss: 0.4133 - val_bce: 0.3909 - val_logcosh: 0.0224\n",
      "  val_spearman-rho: 0.2823                                                                                                    \n",
      "  reload best: 0.2823\n",
      "Epoch 7/100\n",
      "4864/4864 [==============================] - 0s 92us/step - loss: 0.4173 - bce: 0.3940 - logcosh: 0.0233 - val_loss: 0.4131 - val_bce: 0.3908 - val_logcosh: 0.0223\n",
      "  val_spearman-rho: 0.2877                                                                                                    \n",
      "  reload best: 0.2877\n",
      "Epoch 8/100\n",
      "4864/4864 [==============================] - 0s 93us/step - loss: 0.4134 - bce: 0.3906 - logcosh: 0.0227 - val_loss: 0.4095 - val_bce: 0.3877 - val_logcosh: 0.0218\n",
      "  val_spearman-rho: 0.2871                                                                                                    \n",
      "  reload best: 0.2877\n",
      "Epoch 9/100\n",
      "4864/4864 [==============================] - 0s 93us/step - loss: 0.4135 - bce: 0.3907 - logcosh: 0.0228 - val_loss: 0.4102 - val_bce: 0.3882 - val_logcosh: 0.0220\n",
      "  val_spearman-rho: 0.2951                                                                                                    \n",
      "  reload best: 0.2951\n",
      "Epoch 10/100\n",
      "4864/4864 [==============================] - 0s 94us/step - loss: 0.4106 - bce: 0.3882 - logcosh: 0.0224 - val_loss: 0.4163 - val_bce: 0.3937 - val_logcosh: 0.0226\n",
      "  val_spearman-rho: 0.2967                                                                                                    \n",
      "  reload best: 0.2967\n",
      "Epoch 11/100\n",
      "4864/4864 [==============================] - 0s 88us/step - loss: 0.4090 - bce: 0.3869 - logcosh: 0.0221 - val_loss: 0.4075 - val_bce: 0.3859 - val_logcosh: 0.0215\n",
      "  val_spearman-rho: 0.3022                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 12/100\n",
      "4864/4864 [==============================] - 0s 95us/step - loss: 0.4068 - bce: 0.3850 - logcosh: 0.0219 - val_loss: 0.4136 - val_bce: 0.3911 - val_logcosh: 0.0225\n",
      "  val_spearman-rho: 0.2969                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 13/100\n",
      "4864/4864 [==============================] - 0s 91us/step - loss: 0.4074 - bce: 0.3855 - logcosh: 0.0219 - val_loss: 0.4081 - val_bce: 0.3865 - val_logcosh: 0.0217\n",
      "  val_spearman-rho: 0.3011                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 14/100\n",
      "4864/4864 [==============================] - 0s 93us/step - loss: 0.4059 - bce: 0.3842 - logcosh: 0.0217 - val_loss: 0.4098 - val_bce: 0.3879 - val_logcosh: 0.0219\n",
      "  val_spearman-rho: 0.2978                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 15/100\n",
      "4864/4864 [==============================] - 0s 92us/step - loss: 0.4059 - bce: 0.3842 - logcosh: 0.0217 - val_loss: 0.4105 - val_bce: 0.3885 - val_logcosh: 0.0220\n",
      "  val_spearman-rho: 0.2936                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 16/100\n",
      "4864/4864 [==============================] - 0s 93us/step - loss: 0.4059 - bce: 0.3842 - logcosh: 0.0217 - val_loss: 0.4087 - val_bce: 0.3871 - val_logcosh: 0.0216\n",
      "  val_spearman-rho: 0.2969                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 17/100\n",
      "4864/4864 [==============================] - 0s 91us/step - loss: 0.4061 - bce: 0.3844 - logcosh: 0.0218 - val_loss: 0.4074 - val_bce: 0.3859 - val_logcosh: 0.0215\n",
      "  val_spearman-rho: 0.2983                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 18/100\n",
      "4864/4864 [==============================] - 0s 91us/step - loss: 0.4058 - bce: 0.3841 - logcosh: 0.0217 - val_loss: 0.4083 - val_bce: 0.3867 - val_logcosh: 0.0216\n",
      "  val_spearman-rho: 0.2946                                                                                                    \n",
      "  reload best: 0.3022\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 19/100\n",
      "4864/4864 [==============================] - 0s 89us/step - loss: 0.4023 - bce: 0.3811 - logcosh: 0.0212 - val_loss: 0.4058 - val_bce: 0.3844 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2937                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 20/100\n",
      "4864/4864 [==============================] - 0s 94us/step - loss: 0.4018 - bce: 0.3806 - logcosh: 0.0211 - val_loss: 0.4061 - val_bce: 0.3848 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2978                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 21/100\n",
      "4864/4864 [==============================] - 0s 91us/step - loss: 0.4022 - bce: 0.3810 - logcosh: 0.0212 - val_loss: 0.4061 - val_bce: 0.3848 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2937                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 22/100\n",
      "4864/4864 [==============================] - 0s 93us/step - loss: 0.4023 - bce: 0.3811 - logcosh: 0.0212 - val_loss: 0.4064 - val_bce: 0.3851 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.2948                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 23/100\n",
      "4864/4864 [==============================] - 0s 96us/step - loss: 0.4026 - bce: 0.3813 - logcosh: 0.0213 - val_loss: 0.4061 - val_bce: 0.3848 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.2987                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 24/100\n",
      "4864/4864 [==============================] - 0s 92us/step - loss: 0.4015 - bce: 0.3804 - logcosh: 0.0211 - val_loss: 0.4064 - val_bce: 0.3849 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.2976                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 25/100\n",
      "4864/4864 [==============================] - 0s 96us/step - loss: 0.4018 - bce: 0.3807 - logcosh: 0.0211 - val_loss: 0.4057 - val_bce: 0.3844 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2932                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 26/100\n",
      "4864/4864 [==============================] - 0s 90us/step - loss: 0.4020 - bce: 0.3808 - logcosh: 0.0212 - val_loss: 0.4063 - val_bce: 0.3849 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.2925                                                                                                    \n",
      "  reload best: 0.3022\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 5.000000237487257e-06.\n",
      "Epoch 27/100\n",
      "4864/4864 [==============================] - 0s 93us/step - loss: 0.4026 - bce: 0.3814 - logcosh: 0.0212 - val_loss: 0.4061 - val_bce: 0.3847 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2904                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 28/100\n",
      "4864/4864 [==============================] - 0s 90us/step - loss: 0.4028 - bce: 0.3815 - logcosh: 0.0213 - val_loss: 0.4061 - val_bce: 0.3847 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.294                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 29/100\n",
      "4864/4864 [==============================] - 0s 96us/step - loss: 0.4029 - bce: 0.3816 - logcosh: 0.0213 - val_loss: 0.4061 - val_bce: 0.3848 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2999                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 30/100\n",
      "4864/4864 [==============================] - 0s 90us/step - loss: 0.4025 - bce: 0.3813 - logcosh: 0.0212 - val_loss: 0.4061 - val_bce: 0.3847 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2899                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 31/100\n",
      "4864/4864 [==============================] - 0s 96us/step - loss: 0.4021 - bce: 0.3809 - logcosh: 0.0212 - val_loss: 0.4061 - val_bce: 0.3848 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2941                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 32/100\n",
      "4864/4864 [==============================] - 0s 91us/step - loss: 0.4022 - bce: 0.3810 - logcosh: 0.0212 - val_loss: 0.4061 - val_bce: 0.3848 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2908                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 33/100\n",
      "4864/4864 [==============================] - 0s 94us/step - loss: 0.4026 - bce: 0.3813 - logcosh: 0.0212 - val_loss: 0.4061 - val_bce: 0.3847 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.293                                                                                                    \n",
      "  reload best: 0.3022\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 34/100\n",
      "4864/4864 [==============================] - 0s 94us/step - loss: 0.4034 - bce: 0.3820 - logcosh: 0.0213 - val_loss: 0.4067 - val_bce: 0.3852 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.3009                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 35/100\n",
      "4864/4864 [==============================] - 0s 94us/step - loss: 0.4033 - bce: 0.3820 - logcosh: 0.0214 - val_loss: 0.4066 - val_bce: 0.3852 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.2921                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 36/100\n",
      "4864/4864 [==============================] - 0s 93us/step - loss: 0.4030 - bce: 0.3817 - logcosh: 0.0213 - val_loss: 0.4066 - val_bce: 0.3852 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.2883                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 37/100\n",
      "4864/4864 [==============================] - 0s 93us/step - loss: 0.4040 - bce: 0.3826 - logcosh: 0.0214 - val_loss: 0.4066 - val_bce: 0.3852 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.2963                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 38/100\n",
      "4864/4864 [==============================] - 0s 93us/step - loss: 0.4031 - bce: 0.3818 - logcosh: 0.0213 - val_loss: 0.4067 - val_bce: 0.3852 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.2929                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 39/100\n",
      "4864/4864 [==============================] - 0s 91us/step - loss: 0.4033 - bce: 0.3819 - logcosh: 0.0213 - val_loss: 0.4067 - val_bce: 0.3852 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.2841                                                                                                    \n",
      "  reload best: 0.3022\n",
      "Epoch 40/100\n",
      "4864/4864 [==============================] - 0s 95us/step - loss: 0.4038 - bce: 0.3823 - logcosh: 0.0214 - val_loss: 0.4067 - val_bce: 0.3852 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.2921                                                                                                    \n",
      "  reload best: 0.3022\n",
      "  val_spearman-rho: 0.2917                                                                                                    \n",
      "Train on 4864 samples, validate on 1215 samples\n",
      "Epoch 1/50\n",
      "4864/4864 [==============================] - 1s 139us/step - loss: 0.4281 - bce: 0.4032 - logcosh: 0.0249 - val_loss: 0.4314 - val_bce: 0.4065 - val_logcosh: 0.0249\n",
      "  val_spearman-rho: 0.2912                                                                                                    \n",
      "Epoch 2/50\n",
      "4864/4864 [==============================] - 0s 81us/step - loss: 0.4279 - bce: 0.4029 - logcosh: 0.0249 - val_loss: 0.4227 - val_bce: 0.3989 - val_logcosh: 0.0238\n",
      "  val_spearman-rho: 0.2978                                                                                                    \n",
      "Epoch 3/50\n",
      "4864/4864 [==============================] - 0s 81us/step - loss: 0.4279 - bce: 0.4030 - logcosh: 0.0250 - val_loss: 0.4251 - val_bce: 0.4009 - val_logcosh: 0.0241\n",
      "  val_spearman-rho: 0.2905                                                                                                    \n",
      "Epoch 4/50\n",
      "4864/4864 [==============================] - 0s 83us/step - loss: 0.4285 - bce: 0.4034 - logcosh: 0.0251 - val_loss: 0.4201 - val_bce: 0.3967 - val_logcosh: 0.0234\n",
      "  val_spearman-rho: 0.3015                                                                                                    \n",
      "Epoch 5/50\n",
      "4864/4864 [==============================] - 0s 91us/step - loss: 0.4279 - bce: 0.4029 - logcosh: 0.0250 - val_loss: 0.4258 - val_bce: 0.4016 - val_logcosh: 0.0242\n",
      "  val_spearman-rho: 0.293                                                                                                    \n",
      "Epoch 6/50\n",
      "4864/4864 [==============================] - 0s 82us/step - loss: 0.4271 - bce: 0.4023 - logcosh: 0.0248 - val_loss: 0.4243 - val_bce: 0.4003 - val_logcosh: 0.0239\n",
      "  val_spearman-rho: 0.281                                                                                                    \n",
      "Epoch 7/50\n",
      "4864/4864 [==============================] - 0s 79us/step - loss: 0.4270 - bce: 0.4022 - logcosh: 0.0248 - val_loss: 0.4229 - val_bce: 0.3992 - val_logcosh: 0.0238\n",
      "  val_spearman-rho: 0.2985                                                                                                    \n",
      "Epoch 8/50\n",
      "4864/4864 [==============================] - 0s 85us/step - loss: 0.4266 - bce: 0.4018 - logcosh: 0.0248 - val_loss: 0.4225 - val_bce: 0.3988 - val_logcosh: 0.0237\n",
      "  val_spearman-rho: 0.2871                                                                                                    \n",
      "Epoch 9/50\n",
      "4864/4864 [==============================] - 0s 83us/step - loss: 0.4267 - bce: 0.4019 - logcosh: 0.0248 - val_loss: 0.4220 - val_bce: 0.3986 - val_logcosh: 0.0234\n",
      "  val_spearman-rho: 0.2836                                                                                                    \n",
      "Epoch 10/50\n",
      "4864/4864 [==============================] - 0s 81us/step - loss: 0.4259 - bce: 0.4012 - logcosh: 0.0247 - val_loss: 0.4260 - val_bce: 0.4018 - val_logcosh: 0.0242\n",
      "  val_spearman-rho: 0.2929                                                                                                    \n",
      "Epoch 11/50\n",
      "4864/4864 [==============================] - 0s 79us/step - loss: 0.4269 - bce: 0.4021 - logcosh: 0.0248 - val_loss: 0.4223 - val_bce: 0.3988 - val_logcosh: 0.0234\n",
      "  val_spearman-rho: 0.2851                                                                                                    \n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 12/50\n",
      "4864/4864 [==============================] - 0s 79us/step - loss: 0.4030 - bce: 0.3817 - logcosh: 0.0213 - val_loss: 0.4062 - val_bce: 0.3848 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.3007                                                                                                    \n",
      "Epoch 13/50\n",
      "4864/4864 [==============================] - 0s 81us/step - loss: 0.4018 - bce: 0.3806 - logcosh: 0.0212 - val_loss: 0.4064 - val_bce: 0.3850 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.3062                                                                                                    \n",
      "Epoch 14/50\n",
      "4864/4864 [==============================] - 0s 80us/step - loss: 0.4017 - bce: 0.3806 - logcosh: 0.0211 - val_loss: 0.4064 - val_bce: 0.3850 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.288                                                                                                    \n",
      "Epoch 15/50\n",
      "4864/4864 [==============================] - 0s 79us/step - loss: 0.4023 - bce: 0.3811 - logcosh: 0.0212 - val_loss: 0.4062 - val_bce: 0.3848 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.2983                                                                                                    \n",
      "Epoch 16/50\n",
      "4864/4864 [==============================] - 0s 78us/step - loss: 0.4020 - bce: 0.3808 - logcosh: 0.0212 - val_loss: 0.4062 - val_bce: 0.3848 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.2981                                                                                                    \n",
      "Epoch 17/50\n",
      "4864/4864 [==============================] - 0s 80us/step - loss: 0.4015 - bce: 0.3804 - logcosh: 0.0211 - val_loss: 0.4065 - val_bce: 0.3851 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.2836                                                                                                    \n",
      "Epoch 18/50\n",
      "4864/4864 [==============================] - 0s 78us/step - loss: 0.4017 - bce: 0.3806 - logcosh: 0.0211 - val_loss: 0.4060 - val_bce: 0.3846 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3002                                                                                                    \n",
      "Epoch 19/50\n",
      "4864/4864 [==============================] - 0s 82us/step - loss: 0.4018 - bce: 0.3807 - logcosh: 0.0212 - val_loss: 0.4061 - val_bce: 0.3848 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.292                                                                                                    \n",
      "Epoch 20/50\n",
      "4864/4864 [==============================] - 0s 78us/step - loss: 0.4020 - bce: 0.3809 - logcosh: 0.0211 - val_loss: 0.4064 - val_bce: 0.3850 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.2918                                                                                                    \n",
      "Epoch 21/50\n",
      "4864/4864 [==============================] - 0s 83us/step - loss: 0.4019 - bce: 0.3807 - logcosh: 0.0212 - val_loss: 0.4061 - val_bce: 0.3848 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.2985                                                                                                    \n",
      "Epoch 22/50\n",
      "4864/4864 [==============================] - 0s 78us/step - loss: 0.4019 - bce: 0.3807 - logcosh: 0.0212 - val_loss: 0.4059 - val_bce: 0.3846 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2961                                                                                                    \n",
      "Epoch 23/50\n",
      "4864/4864 [==============================] - 0s 78us/step - loss: 0.4023 - bce: 0.3811 - logcosh: 0.0212 - val_loss: 0.4067 - val_bce: 0.3852 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.2946                                                                                                    \n",
      "Epoch 24/50\n",
      "4864/4864 [==============================] - 0s 80us/step - loss: 0.4016 - bce: 0.3804 - logcosh: 0.0211 - val_loss: 0.4059 - val_bce: 0.3846 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2969                                                                                                    \n",
      "Epoch 25/50\n",
      "4864/4864 [==============================] - 0s 80us/step - loss: 0.4014 - bce: 0.3803 - logcosh: 0.0211 - val_loss: 0.4062 - val_bce: 0.3848 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.2972                                                                                                    \n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 26/50\n",
      "4864/4864 [==============================] - 0s 82us/step - loss: 0.4015 - bce: 0.3804 - logcosh: 0.0211 - val_loss: 0.4059 - val_bce: 0.3846 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2986                                                                                                    \n",
      "Epoch 27/50\n",
      "4864/4864 [==============================] - 0s 80us/step - loss: 0.4012 - bce: 0.3802 - logcosh: 0.0211 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2913                                                                                                    \n",
      "Epoch 28/50\n",
      "4864/4864 [==============================] - 0s 80us/step - loss: 0.4009 - bce: 0.3799 - logcosh: 0.0210 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2937                                                                                                    \n",
      "Epoch 29/50\n",
      "4864/4864 [==============================] - 0s 79us/step - loss: 0.4012 - bce: 0.3801 - logcosh: 0.0211 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2874                                                                                                    \n",
      "Epoch 30/50\n",
      "4864/4864 [==============================] - 0s 83us/step - loss: 0.4016 - bce: 0.3805 - logcosh: 0.0211 - val_loss: 0.4059 - val_bce: 0.3846 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2903                                                                                                    \n",
      "Epoch 31/50\n",
      "4864/4864 [==============================] - 0s 78us/step - loss: 0.4008 - bce: 0.3798 - logcosh: 0.0210 - val_loss: 0.4059 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2953                                                                                                    \n",
      "Epoch 32/50\n",
      "4864/4864 [==============================] - 0s 84us/step - loss: 0.4009 - bce: 0.3799 - logcosh: 0.0210 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2955                                                                                                    \n",
      "Epoch 33/50\n",
      "4864/4864 [==============================] - 0s 79us/step - loss: 0.4009 - bce: 0.3798 - logcosh: 0.0210 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2966                                                                                                    \n",
      "Epoch 34/50\n",
      "4864/4864 [==============================] - 0s 82us/step - loss: 0.4015 - bce: 0.3804 - logcosh: 0.0211 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3032                                                                                                    \n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 35/50\n",
      "4864/4864 [==============================] - 0s 79us/step - loss: 0.4012 - bce: 0.3801 - logcosh: 0.0211 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2939                                                                                                    \n",
      "Epoch 36/50\n",
      "4864/4864 [==============================] - 0s 79us/step - loss: 0.4011 - bce: 0.3800 - logcosh: 0.0211 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.295                                                                                                    \n",
      "Epoch 37/50\n",
      "4864/4864 [==============================] - 0s 78us/step - loss: 0.4012 - bce: 0.3801 - logcosh: 0.0211 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2894                                                                                                    \n",
      "Epoch 38/50\n",
      "4864/4864 [==============================] - 0s 80us/step - loss: 0.4008 - bce: 0.3798 - logcosh: 0.0210 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2977                                                                                                    \n",
      "Epoch 39/50\n",
      "4864/4864 [==============================] - 0s 81us/step - loss: 0.4013 - bce: 0.3802 - logcosh: 0.0211 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3005                                                                                                    \n",
      "Epoch 40/50\n",
      "4864/4864 [==============================] - 0s 80us/step - loss: 0.4012 - bce: 0.3802 - logcosh: 0.0211 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3007                                                                                                    \n",
      "Epoch 41/50\n",
      "4864/4864 [==============================] - 0s 83us/step - loss: 0.4011 - bce: 0.3800 - logcosh: 0.0211 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2952                                                                                                    \n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 42/50\n",
      "4864/4864 [==============================] - 0s 79us/step - loss: 0.4011 - bce: 0.3800 - logcosh: 0.0211 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2935                                                                                                    \n",
      "Epoch 43/50\n",
      "4864/4864 [==============================] - 0s 84us/step - loss: 0.4005 - bce: 0.3795 - logcosh: 0.0210 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2979                                                                                                    \n",
      "Epoch 44/50\n",
      "4864/4864 [==============================] - 0s 83us/step - loss: 0.4017 - bce: 0.3805 - logcosh: 0.0211 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3026                                                                                                    \n",
      "Epoch 45/50\n",
      "4864/4864 [==============================] - 0s 82us/step - loss: 0.4013 - bce: 0.3803 - logcosh: 0.0211 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2931                                                                                                    \n",
      "Epoch 46/50\n",
      "4864/4864 [==============================] - 0s 80us/step - loss: 0.4015 - bce: 0.3804 - logcosh: 0.0211 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2903                                                                                                    \n",
      "Epoch 47/50\n",
      "4864/4864 [==============================] - 0s 84us/step - loss: 0.4011 - bce: 0.3800 - logcosh: 0.0210 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2987                                                                                                    \n",
      "Epoch 48/50\n",
      "4864/4864 [==============================] - 0s 80us/step - loss: 0.4007 - bce: 0.3797 - logcosh: 0.0210 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2938                                                                                                    \n",
      "Epoch 49/50\n",
      "4864/4864 [==============================] - 0s 82us/step - loss: 0.4006 - bce: 0.3797 - logcosh: 0.0210 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2949                                                                                                    \n",
      "Epoch 50/50\n",
      "4864/4864 [==============================] - 0s 81us/step - loss: 0.4017 - bce: 0.3805 - logcosh: 0.0211 - val_loss: 0.4058 - val_bce: 0.3845 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3016                                                                                                    \n",
      "  val_spearman-rho: 0.304                                                                                                    \n",
      "Train on 6079 samples, validate on 6079 samples\n",
      "Epoch 1/30\n",
      "6079/6079 [==============================] - 1s 112us/step - loss: 0.3851 - val_loss: 0.3739\n",
      "  val_spearman-rho: 0.3298                                                                                                    \n",
      "Epoch 2/30\n",
      "6079/6079 [==============================] - 0s 66us/step - loss: 0.3824 - val_loss: 0.3727\n",
      "  val_spearman-rho: 0.3311                                                                                                    \n",
      "Epoch 3/30\n",
      "6079/6079 [==============================] - 0s 67us/step - loss: 0.3813 - val_loss: 0.3716\n",
      "  val_spearman-rho: 0.3326                                                                                                    \n",
      "Epoch 4/30\n",
      "6079/6079 [==============================] - 0s 63us/step - loss: 0.3807 - val_loss: 0.3707\n",
      "  val_spearman-rho: 0.3338                                                                                                    \n",
      "Epoch 5/30\n",
      "6079/6079 [==============================] - 0s 65us/step - loss: 0.3802 - val_loss: 0.3726\n",
      "  val_spearman-rho: 0.3374                                                                                                    \n",
      "Epoch 6/30\n",
      "6079/6079 [==============================] - 0s 65us/step - loss: 0.3797 - val_loss: 0.3703\n",
      "  val_spearman-rho: 0.3406                                                                                                    \n",
      "Epoch 7/30\n",
      "6079/6079 [==============================] - 0s 63us/step - loss: 0.3784 - val_loss: 0.3705\n",
      "  val_spearman-rho: 0.342                                                                                                    \n",
      "Epoch 8/30\n",
      "6079/6079 [==============================] - 0s 64us/step - loss: 0.3775 - val_loss: 0.3693\n",
      "  val_spearman-rho: 0.3386                                                                                                    \n",
      "Epoch 9/30\n",
      "6079/6079 [==============================] - 0s 61us/step - loss: 0.3772 - val_loss: 0.3690\n",
      "  val_spearman-rho: 0.3461                                                                                                    \n",
      "Epoch 10/30\n",
      "6079/6079 [==============================] - 0s 64us/step - loss: 0.3762 - val_loss: 0.3677\n",
      "  val_spearman-rho: 0.348                                                                                                    \n",
      "Epoch 11/30\n",
      "6079/6079 [==============================] - 0s 72us/step - loss: 0.3758 - val_loss: 0.3671\n",
      "  val_spearman-rho: 0.3473                                                                                                    \n",
      "Epoch 12/30\n",
      "6079/6079 [==============================] - 0s 68us/step - loss: 0.3751 - val_loss: 0.3669\n",
      "  val_spearman-rho: 0.3459                                                                                                    \n",
      "Epoch 13/30\n",
      "6079/6079 [==============================] - 0s 63us/step - loss: 0.3742 - val_loss: 0.3659\n",
      "  val_spearman-rho: 0.3507                                                                                                    \n",
      "Epoch 14/30\n",
      "6079/6079 [==============================] - 0s 67us/step - loss: 0.3743 - val_loss: 0.3658\n",
      "  val_spearman-rho: 0.3533                                                                                                    \n",
      "Epoch 15/30\n",
      "6079/6079 [==============================] - 0s 65us/step - loss: 0.3736 - val_loss: 0.3660\n",
      "  val_spearman-rho: 0.3524                                                                                                    \n",
      "Epoch 16/30\n",
      "6079/6079 [==============================] - 0s 63us/step - loss: 0.3730 - val_loss: 0.3649\n",
      "  val_spearman-rho: 0.3522                                                                                                    \n",
      "Epoch 17/30\n",
      "6079/6079 [==============================] - 0s 65us/step - loss: 0.3726 - val_loss: 0.3645\n",
      "  val_spearman-rho: 0.3513                                                                                                    \n",
      "Epoch 18/30\n",
      "6079/6079 [==============================] - 0s 65us/step - loss: 0.3723 - val_loss: 0.3641\n",
      "  val_spearman-rho: 0.3543                                                                                                    \n",
      "Epoch 19/30\n",
      "6079/6079 [==============================] - 0s 63us/step - loss: 0.3719 - val_loss: 0.3656\n",
      "  val_spearman-rho: 0.3587                                                                                                    \n",
      "Epoch 20/30\n",
      "6079/6079 [==============================] - 0s 62us/step - loss: 0.3711 - val_loss: 0.3628\n",
      "  val_spearman-rho: 0.36                                                                                                    \n",
      "Epoch 21/30\n",
      "6079/6079 [==============================] - 0s 63us/step - loss: 0.3708 - val_loss: 0.3634\n",
      "  val_spearman-rho: 0.3581                                                                                                    \n",
      "Epoch 22/30\n",
      "6079/6079 [==============================] - 0s 67us/step - loss: 0.3701 - val_loss: 0.3618\n",
      "  val_spearman-rho: 0.3583                                                                                                    \n",
      "Epoch 23/30\n",
      "6079/6079 [==============================] - 0s 65us/step - loss: 0.3702 - val_loss: 0.3622\n",
      "  val_spearman-rho: 0.3608                                                                                                    \n",
      "Epoch 24/30\n",
      "6079/6079 [==============================] - 0s 65us/step - loss: 0.3700 - val_loss: 0.3619\n",
      "  val_spearman-rho: 0.3652                                                                                                    \n",
      "Epoch 25/30\n",
      "6079/6079 [==============================] - 0s 66us/step - loss: 0.3692 - val_loss: 0.3614\n",
      "  val_spearman-rho: 0.3611                                                                                                    \n",
      "Epoch 26/30\n",
      "6079/6079 [==============================] - 0s 64us/step - loss: 0.3688 - val_loss: 0.3607\n",
      "  val_spearman-rho: 0.3659                                                                                                    \n",
      "Epoch 27/30\n",
      "6079/6079 [==============================] - 0s 63us/step - loss: 0.3684 - val_loss: 0.3604\n",
      "  val_spearman-rho: 0.3651                                                                                                    \n",
      "Epoch 28/30\n",
      "6079/6079 [==============================] - 0s 65us/step - loss: 0.3680 - val_loss: 0.3601\n",
      "  val_spearman-rho: 0.3684                                                                                                    \n",
      "Epoch 29/30\n",
      "6079/6079 [==============================] - 0s 65us/step - loss: 0.3681 - val_loss: 0.3612\n",
      "  val_spearman-rho: 0.367                                                                                                    \n",
      "Epoch 30/30\n",
      "6079/6079 [==============================] - 0s 63us/step - loss: 0.3674 - val_loss: 0.3594\n",
      "  val_spearman-rho: 0.3693                                                                                                    \n",
      "  val_spearman-rho: 0.3705                                                                                                    \n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 4576)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                292928    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 30)                3870      \n",
      "=================================================================\n",
      "Total params: 305,118\n",
      "Trainable params: 305,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/100\n",
      "4863/4863 [==============================] - 1s 187us/step - loss: 0.6269 - bce: 0.5796 - logcosh: 0.0474 - val_loss: 0.4315 - val_bce: 0.4064 - val_logcosh: 0.0251\n",
      "  val_spearman-rho: 0.1812                                                                                                    \n",
      "  reload best: 0.1812\n",
      "Epoch 2/100\n",
      "4863/4863 [==============================] - 1s 112us/step - loss: 0.4561 - bce: 0.4276 - logcosh: 0.0284 - val_loss: 0.4183 - val_bce: 0.3948 - val_logcosh: 0.0235\n",
      "  val_spearman-rho: 0.2433                                                                                                    \n",
      "  reload best: 0.2433\n",
      "Epoch 3/100\n",
      "4863/4863 [==============================] - 1s 107us/step - loss: 0.4369 - bce: 0.4111 - logcosh: 0.0258 - val_loss: 0.4116 - val_bce: 0.3892 - val_logcosh: 0.0225\n",
      "  val_spearman-rho: 0.268                                                                                                    \n",
      "  reload best: 0.268\n",
      "Epoch 4/100\n",
      "4863/4863 [==============================] - 1s 106us/step - loss: 0.4273 - bce: 0.4029 - logcosh: 0.0244 - val_loss: 0.4072 - val_bce: 0.3853 - val_logcosh: 0.0219\n",
      "  val_spearman-rho: 0.2845                                                                                                    \n",
      "  reload best: 0.2845\n",
      "Epoch 5/100\n",
      "4863/4863 [==============================] - 1s 106us/step - loss: 0.4221 - bce: 0.3984 - logcosh: 0.0237 - val_loss: 0.4037 - val_bce: 0.3823 - val_logcosh: 0.0215\n",
      "  val_spearman-rho: 0.2837                                                                                                    \n",
      "  reload best: 0.2845\n",
      "Epoch 6/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.4202 - bce: 0.3967 - logcosh: 0.0235 - val_loss: 0.4024 - val_bce: 0.3811 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.2884                                                                                                    \n",
      "  reload best: 0.2884\n",
      "Epoch 7/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.4137 - bce: 0.3911 - logcosh: 0.0226 - val_loss: 0.3999 - val_bce: 0.3790 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3057                                                                                                    \n",
      "  reload best: 0.3057\n",
      "Epoch 8/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.4102 - bce: 0.3881 - logcosh: 0.0221 - val_loss: 0.3991 - val_bce: 0.3782 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3073                                                                                                    \n",
      "  reload best: 0.3073\n",
      "Epoch 9/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.4060 - bce: 0.3845 - logcosh: 0.0215 - val_loss: 0.3972 - val_bce: 0.3766 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3048                                                                                                    \n",
      "  reload best: 0.3073\n",
      "Epoch 10/100\n",
      "4863/4863 [==============================] - 1s 105us/step - loss: 0.4054 - bce: 0.3840 - logcosh: 0.0214 - val_loss: 0.3964 - val_bce: 0.3759 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3029                                                                                                    \n",
      "  reload best: 0.3073\n",
      "Epoch 11/100\n",
      "4863/4863 [==============================] - 1s 104us/step - loss: 0.4065 - bce: 0.3849 - logcosh: 0.0216 - val_loss: 0.3973 - val_bce: 0.3766 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.299                                                                                                    \n",
      "  reload best: 0.3073\n",
      "Epoch 12/100\n",
      "4863/4863 [==============================] - 0s 102us/step - loss: 0.4066 - bce: 0.3851 - logcosh: 0.0216 - val_loss: 0.3961 - val_bce: 0.3757 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.3081                                                                                                    \n",
      "  reload best: 0.3081\n",
      "Epoch 13/100\n",
      "4863/4863 [==============================] - 1s 104us/step - loss: 0.4032 - bce: 0.3821 - logcosh: 0.0211 - val_loss: 0.4023 - val_bce: 0.3810 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.319                                                                                                    \n",
      "  reload best: 0.319\n",
      "Epoch 14/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3994 - bce: 0.3788 - logcosh: 0.0206 - val_loss: 0.3982 - val_bce: 0.3773 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3145                                                                                                    \n",
      "  reload best: 0.319\n",
      "Epoch 15/100\n",
      "4863/4863 [==============================] - 1s 104us/step - loss: 0.4006 - bce: 0.3798 - logcosh: 0.0207 - val_loss: 0.3957 - val_bce: 0.3753 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.3068                                                                                                    \n",
      "  reload best: 0.319\n",
      "Epoch 16/100\n",
      "4863/4863 [==============================] - 1s 103us/step - loss: 0.4003 - bce: 0.3796 - logcosh: 0.0207 - val_loss: 0.3951 - val_bce: 0.3748 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3077                                                                                                    \n",
      "  reload best: 0.319\n",
      "Epoch 17/100\n",
      "4863/4863 [==============================] - 1s 107us/step - loss: 0.4010 - bce: 0.3802 - logcosh: 0.0208 - val_loss: 0.3948 - val_bce: 0.3746 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3144                                                                                                    \n",
      "  reload best: 0.319\n",
      "Epoch 18/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.3998 - bce: 0.3791 - logcosh: 0.0206 - val_loss: 0.3927 - val_bce: 0.3726 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.3129                                                                                                    \n",
      "  reload best: 0.319\n",
      "Epoch 19/100\n",
      "4863/4863 [==============================] - 1s 104us/step - loss: 0.3986 - bce: 0.3781 - logcosh: 0.0205 - val_loss: 0.3960 - val_bce: 0.3756 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.314                                                                                                    \n",
      "  reload best: 0.319\n",
      "Epoch 20/100\n",
      "4863/4863 [==============================] - 1s 104us/step - loss: 0.4017 - bce: 0.3808 - logcosh: 0.0209 - val_loss: 0.3947 - val_bce: 0.3744 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3078                                                                                                    \n",
      "  reload best: 0.319\n",
      "Epoch 21/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.4002 - bce: 0.3795 - logcosh: 0.0207 - val_loss: 0.4005 - val_bce: 0.3793 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3083                                                                                                    \n",
      "  reload best: 0.319\n",
      "Epoch 22/100\n",
      "4863/4863 [==============================] - 1s 106us/step - loss: 0.3998 - bce: 0.3792 - logcosh: 0.0206 - val_loss: 0.3945 - val_bce: 0.3742 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3049                                                                                                    \n",
      "  reload best: 0.319\n",
      "Epoch 23/100\n",
      "4863/4863 [==============================] - 1s 114us/step - loss: 0.4005 - bce: 0.3798 - logcosh: 0.0208 - val_loss: 0.3941 - val_bce: 0.3739 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.314                                                                                                    \n",
      "  reload best: 0.319\n",
      "Epoch 24/100\n",
      "4863/4863 [==============================] - 1s 104us/step - loss: 0.3994 - bce: 0.3788 - logcosh: 0.0206 - val_loss: 0.3950 - val_bce: 0.3746 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3145                                                                                                    \n",
      "  reload best: 0.319\n",
      "Epoch 25/100\n",
      "4863/4863 [==============================] - 1s 105us/step - loss: 0.4007 - bce: 0.3799 - logcosh: 0.0208 - val_loss: 0.3961 - val_bce: 0.3756 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3255                                                                                                    \n",
      "  reload best: 0.3255\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 26/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.3930 - bce: 0.3733 - logcosh: 0.0197 - val_loss: 0.3915 - val_bce: 0.3716 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3172                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 27/100\n",
      "4863/4863 [==============================] - 1s 103us/step - loss: 0.3930 - bce: 0.3732 - logcosh: 0.0197 - val_loss: 0.3915 - val_bce: 0.3717 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3249                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 28/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3933 - bce: 0.3736 - logcosh: 0.0197 - val_loss: 0.3919 - val_bce: 0.3720 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3156                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 29/100\n",
      "4863/4863 [==============================] - 0s 103us/step - loss: 0.3928 - bce: 0.3732 - logcosh: 0.0197 - val_loss: 0.3918 - val_bce: 0.3719 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3069                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 30/100\n",
      "4863/4863 [==============================] - 1s 106us/step - loss: 0.3932 - bce: 0.3735 - logcosh: 0.0197 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.307                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 31/100\n",
      "4863/4863 [==============================] - 1s 104us/step - loss: 0.3933 - bce: 0.3735 - logcosh: 0.0198 - val_loss: 0.3927 - val_bce: 0.3727 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.3214                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 32/100\n",
      "4863/4863 [==============================] - 1s 108us/step - loss: 0.3926 - bce: 0.3730 - logcosh: 0.0196 - val_loss: 0.3922 - val_bce: 0.3723 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3198                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 33/100\n",
      "4863/4863 [==============================] - 1s 104us/step - loss: 0.3925 - bce: 0.3728 - logcosh: 0.0196 - val_loss: 0.3915 - val_bce: 0.3716 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3169                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 34/100\n",
      "4863/4863 [==============================] - 1s 111us/step - loss: 0.3930 - bce: 0.3733 - logcosh: 0.0197 - val_loss: 0.3913 - val_bce: 0.3715 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3154                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 35/100\n",
      "4863/4863 [==============================] - 1s 107us/step - loss: 0.3927 - bce: 0.3731 - logcosh: 0.0197 - val_loss: 0.3913 - val_bce: 0.3715 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3205                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 36/100\n",
      "4863/4863 [==============================] - 1s 106us/step - loss: 0.3928 - bce: 0.3732 - logcosh: 0.0197 - val_loss: 0.3917 - val_bce: 0.3718 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3185                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 37/100\n",
      "4863/4863 [==============================] - 0s 102us/step - loss: 0.3932 - bce: 0.3735 - logcosh: 0.0197 - val_loss: 0.3917 - val_bce: 0.3718 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3109                                                                                                    \n",
      "  reload best: 0.3255\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 5.000000237487257e-06.\n",
      "Epoch 38/100\n",
      "4863/4863 [==============================] - 1s 104us/step - loss: 0.3937 - bce: 0.3739 - logcosh: 0.0198 - val_loss: 0.3916 - val_bce: 0.3717 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3101                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 39/100\n",
      "4863/4863 [==============================] - 0s 102us/step - loss: 0.3936 - bce: 0.3738 - logcosh: 0.0198 - val_loss: 0.3916 - val_bce: 0.3718 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3106                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 40/100\n",
      "4863/4863 [==============================] - 0s 102us/step - loss: 0.3930 - bce: 0.3733 - logcosh: 0.0197 - val_loss: 0.3916 - val_bce: 0.3718 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3019                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 41/100\n",
      "4863/4863 [==============================] - 1s 105us/step - loss: 0.3933 - bce: 0.3736 - logcosh: 0.0198 - val_loss: 0.3916 - val_bce: 0.3718 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3116                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 42/100\n",
      "4863/4863 [==============================] - 1s 104us/step - loss: 0.3937 - bce: 0.3739 - logcosh: 0.0198 - val_loss: 0.3917 - val_bce: 0.3718 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3106                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 43/100\n",
      "4863/4863 [==============================] - 0s 100us/step - loss: 0.3940 - bce: 0.3741 - logcosh: 0.0199 - val_loss: 0.3916 - val_bce: 0.3717 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.317                                                                                                    \n",
      "  reload best: 0.3255\n",
      "Epoch 44/100\n",
      "4863/4863 [==============================] - 1s 105us/step - loss: 0.3934 - bce: 0.3737 - logcosh: 0.0198 - val_loss: 0.3916 - val_bce: 0.3718 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3113                                                                                                    \n",
      "  reload best: 0.3255\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 45/100\n",
      "4863/4863 [==============================] - 0s 100us/step - loss: 0.3957 - bce: 0.3756 - logcosh: 0.0201 - val_loss: 0.3927 - val_bce: 0.3727 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.308                                                                                                    \n",
      "  reload best: 0.3255\n",
      "  val_spearman-rho: 0.3133                                                                                                    \n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/50\n",
      "4863/4863 [==============================] - 1s 149us/step - loss: 0.4210 - bce: 0.3973 - logcosh: 0.0238 - val_loss: 0.4138 - val_bce: 0.3908 - val_logcosh: 0.0230\n",
      "  val_spearman-rho: 0.3187                                                                                                    \n",
      "Epoch 2/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.4196 - bce: 0.3960 - logcosh: 0.0236 - val_loss: 0.4068 - val_bce: 0.3850 - val_logcosh: 0.0217\n",
      "  val_spearman-rho: 0.3084                                                                                                    \n",
      "Epoch 3/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.4215 - bce: 0.3976 - logcosh: 0.0239 - val_loss: 0.4125 - val_bce: 0.3898 - val_logcosh: 0.0227\n",
      "  val_spearman-rho: 0.3051                                                                                                    \n",
      "Epoch 4/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.4208 - bce: 0.3971 - logcosh: 0.0237 - val_loss: 0.4119 - val_bce: 0.3892 - val_logcosh: 0.0227\n",
      "  val_spearman-rho: 0.3068                                                                                                    \n",
      "Epoch 5/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.4213 - bce: 0.3975 - logcosh: 0.0239 - val_loss: 0.4103 - val_bce: 0.3877 - val_logcosh: 0.0226\n",
      "  val_spearman-rho: 0.3032                                                                                                    \n",
      "Epoch 6/50\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.4189 - bce: 0.3953 - logcosh: 0.0235 - val_loss: 0.4143 - val_bce: 0.3911 - val_logcosh: 0.0232\n",
      "  val_spearman-rho: 0.3103                                                                                                    \n",
      "Epoch 7/50\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.4189 - bce: 0.3954 - logcosh: 0.0235 - val_loss: 0.4133 - val_bce: 0.3906 - val_logcosh: 0.0227\n",
      "  val_spearman-rho: 0.3196                                                                                                    \n",
      "Epoch 8/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.4181 - bce: 0.3947 - logcosh: 0.0234 - val_loss: 0.4130 - val_bce: 0.3903 - val_logcosh: 0.0228\n",
      "  val_spearman-rho: 0.307                                                                                                    \n",
      "Epoch 9/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.4188 - bce: 0.3954 - logcosh: 0.0235 - val_loss: 0.4085 - val_bce: 0.3864 - val_logcosh: 0.0221\n",
      "  val_spearman-rho: 0.3056                                                                                                    \n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 10/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3938 - bce: 0.3740 - logcosh: 0.0198 - val_loss: 0.3916 - val_bce: 0.3718 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.2993                                                                                                    \n",
      "Epoch 11/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3923 - bce: 0.3727 - logcosh: 0.0196 - val_loss: 0.3927 - val_bce: 0.3727 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.317                                                                                                    \n",
      "Epoch 12/50\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3926 - bce: 0.3730 - logcosh: 0.0197 - val_loss: 0.3915 - val_bce: 0.3717 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.313                                                                                                    \n",
      "Epoch 13/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3932 - bce: 0.3735 - logcosh: 0.0197 - val_loss: 0.3927 - val_bce: 0.3727 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.3059                                                                                                    \n",
      "Epoch 14/50\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.3925 - bce: 0.3729 - logcosh: 0.0197 - val_loss: 0.3916 - val_bce: 0.3718 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3151                                                                                                    \n",
      "Epoch 15/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3920 - bce: 0.3724 - logcosh: 0.0196 - val_loss: 0.3916 - val_bce: 0.3717 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3139                                                                                                    \n",
      "Epoch 16/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3925 - bce: 0.3728 - logcosh: 0.0196 - val_loss: 0.3913 - val_bce: 0.3715 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3175                                                                                                    \n",
      "Epoch 17/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3929 - bce: 0.3732 - logcosh: 0.0197 - val_loss: 0.3916 - val_bce: 0.3717 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3191                                                                                                    \n",
      "Epoch 18/50\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3926 - bce: 0.3729 - logcosh: 0.0196 - val_loss: 0.3918 - val_bce: 0.3719 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3223                                                                                                    \n",
      "Epoch 19/50\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3928 - bce: 0.3732 - logcosh: 0.0197 - val_loss: 0.3918 - val_bce: 0.3719 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3111                                                                                                    \n",
      "Epoch 20/50\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3922 - bce: 0.3726 - logcosh: 0.0196 - val_loss: 0.3919 - val_bce: 0.3721 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3134                                                                                                    \n",
      "Epoch 21/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3924 - bce: 0.3728 - logcosh: 0.0196 - val_loss: 0.3914 - val_bce: 0.3716 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3089                                                                                                    \n",
      "Epoch 22/50\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3928 - bce: 0.3731 - logcosh: 0.0197 - val_loss: 0.3922 - val_bce: 0.3722 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3163                                                                                                    \n",
      "Epoch 23/50\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3923 - bce: 0.3727 - logcosh: 0.0196 - val_loss: 0.3914 - val_bce: 0.3715 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.319                                                                                                    \n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 24/50\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3921 - bce: 0.3726 - logcosh: 0.0196 - val_loss: 0.3913 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3125                                                                                                    \n",
      "Epoch 25/50\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.3922 - bce: 0.3726 - logcosh: 0.0196 - val_loss: 0.3913 - val_bce: 0.3715 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3201                                                                                                    \n",
      "Epoch 26/50\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3916 - bce: 0.3721 - logcosh: 0.0195 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3041                                                                                                    \n",
      "Epoch 27/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3914 - bce: 0.3720 - logcosh: 0.0195 - val_loss: 0.3913 - val_bce: 0.3715 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3204                                                                                                    \n",
      "Epoch 28/50\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.3918 - bce: 0.3722 - logcosh: 0.0195 - val_loss: 0.3913 - val_bce: 0.3715 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3269                                                                                                    \n",
      "Epoch 29/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3919 - bce: 0.3724 - logcosh: 0.0195 - val_loss: 0.3913 - val_bce: 0.3715 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3166                                                                                                    \n",
      "Epoch 30/50\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3923 - bce: 0.3727 - logcosh: 0.0196 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.313                                                                                                    \n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 31/50\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.3918 - bce: 0.3723 - logcosh: 0.0195 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3212                                                                                                    \n",
      "Epoch 32/50\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.3916 - bce: 0.3721 - logcosh: 0.0195 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3158                                                                                                    \n",
      "Epoch 33/50\n",
      "4863/4863 [==============================] - 0s 92us/step - loss: 0.3919 - bce: 0.3723 - logcosh: 0.0195 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3126                                                                                                    \n",
      "Epoch 34/50\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3918 - bce: 0.3722 - logcosh: 0.0196 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3119                                                                                                    \n",
      "Epoch 35/50\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3918 - bce: 0.3722 - logcosh: 0.0195 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3136                                                                                                    \n",
      "Epoch 36/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3920 - bce: 0.3724 - logcosh: 0.0196 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3188                                                                                                    \n",
      "Epoch 37/50\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3917 - bce: 0.3722 - logcosh: 0.0195 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3187                                                                                                    \n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 38/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3912 - bce: 0.3718 - logcosh: 0.0194 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3132                                                                                                    \n",
      "Epoch 39/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3919 - bce: 0.3724 - logcosh: 0.0195 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3104                                                                                                    \n",
      "Epoch 40/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3915 - bce: 0.3720 - logcosh: 0.0195 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.316                                                                                                    \n",
      "Epoch 41/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3920 - bce: 0.3724 - logcosh: 0.0195 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3251                                                                                                    \n",
      "Epoch 42/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3917 - bce: 0.3722 - logcosh: 0.0195 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3298                                                                                                    \n",
      "Epoch 43/50\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3916 - bce: 0.3721 - logcosh: 0.0195 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3241                                                                                                    \n",
      "Epoch 44/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3919 - bce: 0.3723 - logcosh: 0.0196 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3164                                                                                                    \n",
      "Epoch 45/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3922 - bce: 0.3726 - logcosh: 0.0196 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3104                                                                                                    \n",
      "Epoch 46/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3913 - bce: 0.3718 - logcosh: 0.0195 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3132                                                                                                    \n",
      "Epoch 47/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3915 - bce: 0.3720 - logcosh: 0.0195 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3217                                                                                                    \n",
      "Epoch 48/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3918 - bce: 0.3722 - logcosh: 0.0195 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3143                                                                                                    \n",
      "Epoch 49/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3916 - bce: 0.3721 - logcosh: 0.0195 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.313                                                                                                    \n",
      "Epoch 50/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3918 - bce: 0.3723 - logcosh: 0.0195 - val_loss: 0.3912 - val_bce: 0.3714 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3124                                                                                                    \n",
      "  val_spearman-rho: 0.3148                                                                                                    \n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 4576)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 64)                292928    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 30)                3870      \n",
      "=================================================================\n",
      "Total params: 305,118\n",
      "Trainable params: 305,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/100\n",
      "4863/4863 [==============================] - 1s 166us/step - loss: 0.6020 - bce: 0.5559 - logcosh: 0.0460 - val_loss: 0.4307 - val_bce: 0.4057 - val_logcosh: 0.0250\n",
      "  val_spearman-rho: 0.1863                                                                                                    \n",
      "  reload best: 0.1863\n",
      "Epoch 2/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.4551 - bce: 0.4266 - logcosh: 0.0285 - val_loss: 0.4208 - val_bce: 0.3974 - val_logcosh: 0.0234\n",
      "  val_spearman-rho: 0.2368                                                                                                    \n",
      "  reload best: 0.2368\n",
      "Epoch 3/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.4362 - bce: 0.4104 - logcosh: 0.0258 - val_loss: 0.4140 - val_bce: 0.3914 - val_logcosh: 0.0226\n",
      "  val_spearman-rho: 0.2528                                                                                                    \n",
      "  reload best: 0.2528\n",
      "Epoch 4/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.4256 - bce: 0.4013 - logcosh: 0.0244 - val_loss: 0.4096 - val_bce: 0.3875 - val_logcosh: 0.0221\n",
      "  val_spearman-rho: 0.2709                                                                                                    \n",
      "  reload best: 0.2709\n",
      "Epoch 5/100\n",
      "4863/4863 [==============================] - 0s 100us/step - loss: 0.4177 - bce: 0.3945 - logcosh: 0.0232 - val_loss: 0.4057 - val_bce: 0.3842 - val_logcosh: 0.0215\n",
      "  val_spearman-rho: 0.279                                                                                                    \n",
      "  reload best: 0.279\n",
      "Epoch 6/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.4129 - bce: 0.3904 - logcosh: 0.0225 - val_loss: 0.4020 - val_bce: 0.3810 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.285                                                                                                    \n",
      "  reload best: 0.285\n",
      "Epoch 7/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.4079 - bce: 0.3861 - logcosh: 0.0219 - val_loss: 0.4002 - val_bce: 0.3795 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.2925                                                                                                    \n",
      "  reload best: 0.2925\n",
      "Epoch 8/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.4035 - bce: 0.3823 - logcosh: 0.0212 - val_loss: 0.3975 - val_bce: 0.3771 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.2976                                                                                                    \n",
      "  reload best: 0.2976\n",
      "Epoch 9/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.4011 - bce: 0.3802 - logcosh: 0.0209 - val_loss: 0.4011 - val_bce: 0.3804 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.2946                                                                                                    \n",
      "  reload best: 0.2976\n",
      "Epoch 10/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.4000 - bce: 0.3793 - logcosh: 0.0207 - val_loss: 0.3989 - val_bce: 0.3783 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.2948                                                                                                    \n",
      "  reload best: 0.2976\n",
      "Epoch 11/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.4007 - bce: 0.3799 - logcosh: 0.0208 - val_loss: 0.4018 - val_bce: 0.3808 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3                                                                                                    \n",
      "  reload best: 0.3\n",
      "Epoch 12/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3990 - bce: 0.3784 - logcosh: 0.0206 - val_loss: 0.3986 - val_bce: 0.3780 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.2988                                                                                                    \n",
      "  reload best: 0.3\n",
      "Epoch 13/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3982 - bce: 0.3777 - logcosh: 0.0205 - val_loss: 0.4028 - val_bce: 0.3817 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.2992                                                                                                    \n",
      "  reload best: 0.3\n",
      "Epoch 14/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3990 - bce: 0.3784 - logcosh: 0.0207 - val_loss: 0.3982 - val_bce: 0.3776 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3024                                                                                                    \n",
      "  reload best: 0.3024\n",
      "Epoch 15/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3983 - bce: 0.3778 - logcosh: 0.0205 - val_loss: 0.4007 - val_bce: 0.3798 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3018                                                                                                    \n",
      "  reload best: 0.3024\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 16/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3912 - bce: 0.3717 - logcosh: 0.0195 - val_loss: 0.3951 - val_bce: 0.3750 - val_logcosh: 0.0201\n",
      "  val_spearman-rho: 0.3043                                                                                                    \n",
      "  reload best: 0.3043\n",
      "Epoch 17/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3906 - bce: 0.3712 - logcosh: 0.0194 - val_loss: 0.3947 - val_bce: 0.3747 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.3075                                                                                                    \n",
      "  reload best: 0.3075\n",
      "Epoch 18/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3899 - bce: 0.3706 - logcosh: 0.0193 - val_loss: 0.3944 - val_bce: 0.3744 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.3112                                                                                                    \n",
      "  reload best: 0.3112\n",
      "Epoch 19/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3892 - bce: 0.3699 - logcosh: 0.0192 - val_loss: 0.3942 - val_bce: 0.3743 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.307                                                                                                    \n",
      "  reload best: 0.3112\n",
      "Epoch 20/100\n",
      "4863/4863 [==============================] - 0s 102us/step - loss: 0.3896 - bce: 0.3702 - logcosh: 0.0193 - val_loss: 0.3941 - val_bce: 0.3742 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3069                                                                                                    \n",
      "  reload best: 0.3112\n",
      "Epoch 21/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.3888 - bce: 0.3696 - logcosh: 0.0192 - val_loss: 0.3942 - val_bce: 0.3743 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.2967                                                                                                    \n",
      "  reload best: 0.3112\n",
      "Epoch 22/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3899 - bce: 0.3705 - logcosh: 0.0193 - val_loss: 0.3944 - val_bce: 0.3745 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.3073                                                                                                    \n",
      "  reload best: 0.3112\n",
      "Epoch 23/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3896 - bce: 0.3703 - logcosh: 0.0193 - val_loss: 0.3942 - val_bce: 0.3743 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3077                                                                                                    \n",
      "  reload best: 0.3112\n",
      "Epoch 24/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3894 - bce: 0.3702 - logcosh: 0.0193 - val_loss: 0.3942 - val_bce: 0.3742 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3078                                                                                                    \n",
      "  reload best: 0.3112\n",
      "Epoch 25/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.3898 - bce: 0.3705 - logcosh: 0.0193 - val_loss: 0.3945 - val_bce: 0.3745 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.3139                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 26/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3888 - bce: 0.3696 - logcosh: 0.0192 - val_loss: 0.3942 - val_bce: 0.3743 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.3058                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 27/100\n",
      "4863/4863 [==============================] - 1s 107us/step - loss: 0.3889 - bce: 0.3696 - logcosh: 0.0192 - val_loss: 0.3944 - val_bce: 0.3745 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.3106                                                                                                    \n",
      "  reload best: 0.3139\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 5.000000237487257e-06.\n",
      "Epoch 28/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.3884 - bce: 0.3692 - logcosh: 0.0192 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3024                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 29/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3885 - bce: 0.3694 - logcosh: 0.0192 - val_loss: 0.3939 - val_bce: 0.3740 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3034                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 30/100\n",
      "4863/4863 [==============================] - 1s 103us/step - loss: 0.3884 - bce: 0.3693 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3089                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 31/100\n",
      "4863/4863 [==============================] - 1s 111us/step - loss: 0.3887 - bce: 0.3695 - logcosh: 0.0192 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3088                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 32/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3885 - bce: 0.3694 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3033                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 33/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.3886 - bce: 0.3695 - logcosh: 0.0192 - val_loss: 0.3939 - val_bce: 0.3740 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3028                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 34/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.3884 - bce: 0.3692 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3139                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 35/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3884 - bce: 0.3693 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3047                                                                                                    \n",
      "  reload best: 0.3139\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 36/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3878 - bce: 0.3688 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3061                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 37/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3886 - bce: 0.3695 - logcosh: 0.0192 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.2996                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 38/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3883 - bce: 0.3692 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.2971                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 39/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3883 - bce: 0.3692 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3075                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 40/100\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3881 - bce: 0.3690 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3027                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 41/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3885 - bce: 0.3694 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3085                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 42/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3885 - bce: 0.3693 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3094                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 43/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3883 - bce: 0.3692 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3096                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 44/100\n",
      "4863/4863 [==============================] - 1s 103us/step - loss: 0.3881 - bce: 0.3690 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3082                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 45/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3886 - bce: 0.3695 - logcosh: 0.0192 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3102                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 46/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3881 - bce: 0.3690 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3021                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 47/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3882 - bce: 0.3691 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3047                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 48/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3882 - bce: 0.3691 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3001                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 49/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3882 - bce: 0.3691 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.303                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 50/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3883 - bce: 0.3692 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3059                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 51/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3882 - bce: 0.3691 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3027                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 52/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3880 - bce: 0.3689 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3067                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 53/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3882 - bce: 0.3691 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3092                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 54/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3883 - bce: 0.3692 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.309                                                                                                    \n",
      "  reload best: 0.3139\n",
      "  val_spearman-rho: 0.3126                                                                                                    \n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/50\n",
      "4863/4863 [==============================] - 1s 145us/step - loss: 0.4198 - bce: 0.3961 - logcosh: 0.0237 - val_loss: 0.4236 - val_bce: 0.3994 - val_logcosh: 0.0243\n",
      "  val_spearman-rho: 0.297                                                                                                    \n",
      "Epoch 2/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.4180 - bce: 0.3945 - logcosh: 0.0235 - val_loss: 0.4203 - val_bce: 0.3965 - val_logcosh: 0.0238\n",
      "  val_spearman-rho: 0.2937                                                                                                    \n",
      "Epoch 3/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.4183 - bce: 0.3948 - logcosh: 0.0236 - val_loss: 0.4169 - val_bce: 0.3934 - val_logcosh: 0.0234\n",
      "  val_spearman-rho: 0.2944                                                                                                    \n",
      "Epoch 4/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.4195 - bce: 0.3958 - logcosh: 0.0237 - val_loss: 0.4187 - val_bce: 0.3950 - val_logcosh: 0.0236\n",
      "  val_spearman-rho: 0.3005                                                                                                    \n",
      "Epoch 5/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.4179 - bce: 0.3944 - logcosh: 0.0235 - val_loss: 0.4148 - val_bce: 0.3920 - val_logcosh: 0.0228\n",
      "  val_spearman-rho: 0.2933                                                                                                    \n",
      "Epoch 6/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.4169 - bce: 0.3936 - logcosh: 0.0233 - val_loss: 0.4161 - val_bce: 0.3930 - val_logcosh: 0.0232\n",
      "  val_spearman-rho: 0.2986                                                                                                    \n",
      "Epoch 7/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.4181 - bce: 0.3947 - logcosh: 0.0235 - val_loss: 0.4133 - val_bce: 0.3904 - val_logcosh: 0.0228\n",
      "  val_spearman-rho: 0.3009                                                                                                    \n",
      "Epoch 8/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.4184 - bce: 0.3949 - logcosh: 0.0235 - val_loss: 0.4133 - val_bce: 0.3905 - val_logcosh: 0.0228\n",
      "  val_spearman-rho: 0.2985                                                                                                    \n",
      "Epoch 9/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.4170 - bce: 0.3937 - logcosh: 0.0233 - val_loss: 0.4223 - val_bce: 0.3982 - val_logcosh: 0.0241\n",
      "  val_spearman-rho: 0.298                                                                                                    \n",
      "Epoch 10/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.4150 - bce: 0.3920 - logcosh: 0.0230 - val_loss: 0.4262 - val_bce: 0.4013 - val_logcosh: 0.0249\n",
      "  val_spearman-rho: 0.306                                                                                                    \n",
      "Epoch 11/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.4161 - bce: 0.3929 - logcosh: 0.0232 - val_loss: 0.4184 - val_bce: 0.3948 - val_logcosh: 0.0237\n",
      "  val_spearman-rho: 0.2995                                                                                                    \n",
      "Epoch 12/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.4166 - bce: 0.3934 - logcosh: 0.0233 - val_loss: 0.4173 - val_bce: 0.3940 - val_logcosh: 0.0233\n",
      "  val_spearman-rho: 0.3006                                                                                                    \n",
      "Epoch 13/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.4163 - bce: 0.3931 - logcosh: 0.0232 - val_loss: 0.4159 - val_bce: 0.3929 - val_logcosh: 0.0230\n",
      "  val_spearman-rho: 0.3067                                                                                                    \n",
      "Epoch 14/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.4147 - bce: 0.3917 - logcosh: 0.0230 - val_loss: 0.4123 - val_bce: 0.3895 - val_logcosh: 0.0228\n",
      "  val_spearman-rho: 0.3051                                                                                                    \n",
      "Epoch 15/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.4164 - bce: 0.3932 - logcosh: 0.0232 - val_loss: 0.4237 - val_bce: 0.3993 - val_logcosh: 0.0244\n",
      "  val_spearman-rho: 0.3035                                                                                                    \n",
      "Epoch 16/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.4155 - bce: 0.3924 - logcosh: 0.0231 - val_loss: 0.4177 - val_bce: 0.3942 - val_logcosh: 0.0236\n",
      "  val_spearman-rho: 0.3014                                                                                                    \n",
      "Epoch 17/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.4155 - bce: 0.3924 - logcosh: 0.0231 - val_loss: 0.4141 - val_bce: 0.3913 - val_logcosh: 0.0228\n",
      "  val_spearman-rho: 0.2994                                                                                                    \n",
      "Epoch 18/50\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.4168 - bce: 0.3935 - logcosh: 0.0233 - val_loss: 0.4163 - val_bce: 0.3933 - val_logcosh: 0.0230\n",
      "  val_spearman-rho: 0.2946                                                                                                    \n",
      "Epoch 19/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.4157 - bce: 0.3925 - logcosh: 0.0231 - val_loss: 0.4144 - val_bce: 0.3914 - val_logcosh: 0.0230\n",
      "  val_spearman-rho: 0.2972                                                                                                    \n",
      "Epoch 20/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.4159 - bce: 0.3927 - logcosh: 0.0232 - val_loss: 0.4267 - val_bce: 0.4019 - val_logcosh: 0.0248\n",
      "  val_spearman-rho: 0.305                                                                                                    \n",
      "Epoch 21/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.4159 - bce: 0.3928 - logcosh: 0.0232 - val_loss: 0.4193 - val_bce: 0.3955 - val_logcosh: 0.0238\n",
      "  val_spearman-rho: 0.3033                                                                                                    \n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 22/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3902 - bce: 0.3708 - logcosh: 0.0194 - val_loss: 0.3947 - val_bce: 0.3747 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.313                                                                                                    \n",
      "Epoch 23/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3891 - bce: 0.3699 - logcosh: 0.0192 - val_loss: 0.3942 - val_bce: 0.3743 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.307                                                                                                    \n",
      "Epoch 24/50\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3891 - bce: 0.3699 - logcosh: 0.0193 - val_loss: 0.3943 - val_bce: 0.3743 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3153                                                                                                    \n",
      "Epoch 25/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3898 - bce: 0.3705 - logcosh: 0.0193 - val_loss: 0.3941 - val_bce: 0.3742 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3136                                                                                                    \n",
      "Epoch 26/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3891 - bce: 0.3698 - logcosh: 0.0192 - val_loss: 0.3941 - val_bce: 0.3742 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3055                                                                                                    \n",
      "Epoch 27/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3893 - bce: 0.3700 - logcosh: 0.0193 - val_loss: 0.3941 - val_bce: 0.3742 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3095                                                                                                    \n",
      "Epoch 28/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3896 - bce: 0.3703 - logcosh: 0.0193 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3098                                                                                                    \n",
      "Epoch 29/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3895 - bce: 0.3702 - logcosh: 0.0193 - val_loss: 0.3941 - val_bce: 0.3742 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3076                                                                                                    \n",
      "Epoch 30/50\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3888 - bce: 0.3696 - logcosh: 0.0192 - val_loss: 0.3942 - val_bce: 0.3743 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3049                                                                                                    \n",
      "Epoch 31/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3886 - bce: 0.3694 - logcosh: 0.0192 - val_loss: 0.3940 - val_bce: 0.3741 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3105                                                                                                    \n",
      "Epoch 32/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3891 - bce: 0.3699 - logcosh: 0.0193 - val_loss: 0.3946 - val_bce: 0.3746 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.3051                                                                                                    \n",
      "Epoch 33/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3890 - bce: 0.3698 - logcosh: 0.0192 - val_loss: 0.3945 - val_bce: 0.3746 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.3109                                                                                                    \n",
      "Epoch 34/50\n",
      "4863/4863 [==============================] - 0s 94us/step - loss: 0.3889 - bce: 0.3697 - logcosh: 0.0192 - val_loss: 0.3949 - val_bce: 0.3749 - val_logcosh: 0.0201\n",
      "  val_spearman-rho: 0.3117                                                                                                    \n",
      "Epoch 35/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3887 - bce: 0.3695 - logcosh: 0.0192 - val_loss: 0.3939 - val_bce: 0.3741 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3102                                                                                                    \n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 36/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3882 - bce: 0.3691 - logcosh: 0.0191 - val_loss: 0.3939 - val_bce: 0.3740 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3011                                                                                                    \n",
      "Epoch 37/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3883 - bce: 0.3692 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3081                                                                                                    \n",
      "Epoch 38/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3880 - bce: 0.3689 - logcosh: 0.0191 - val_loss: 0.3940 - val_bce: 0.3741 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.31                                                                                                    \n",
      "Epoch 39/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3880 - bce: 0.3689 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3126                                                                                                    \n",
      "Epoch 40/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3884 - bce: 0.3693 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3101                                                                                                    \n",
      "Epoch 41/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3882 - bce: 0.3691 - logcosh: 0.0191 - val_loss: 0.3937 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3029                                                                                                    \n",
      "Epoch 42/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3877 - bce: 0.3687 - logcosh: 0.0191 - val_loss: 0.3937 - val_bce: 0.3738 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3055                                                                                                    \n",
      "Epoch 43/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3880 - bce: 0.3689 - logcosh: 0.0191 - val_loss: 0.3939 - val_bce: 0.3740 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3057                                                                                                    \n",
      "Epoch 44/50\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3885 - bce: 0.3693 - logcosh: 0.0192 - val_loss: 0.3937 - val_bce: 0.3738 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3082                                                                                                    \n",
      "Epoch 45/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3882 - bce: 0.3691 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.2945                                                                                                    \n",
      "Epoch 46/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3884 - bce: 0.3693 - logcosh: 0.0191 - val_loss: 0.3939 - val_bce: 0.3740 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3156                                                                                                    \n",
      "Epoch 47/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3880 - bce: 0.3689 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3075                                                                                                    \n",
      "Epoch 48/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3884 - bce: 0.3692 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3097                                                                                                    \n",
      "Epoch 49/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3880 - bce: 0.3689 - logcosh: 0.0191 - val_loss: 0.3939 - val_bce: 0.3740 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3143                                                                                                    \n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 50/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3881 - bce: 0.3690 - logcosh: 0.0191 - val_loss: 0.3938 - val_bce: 0.3739 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3051                                                                                                    \n",
      "  val_spearman-rho: 0.3043                                                                                                    \n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 4576)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                292928    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 30)                3870      \n",
      "=================================================================\n",
      "Total params: 305,118\n",
      "Trainable params: 305,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/100\n",
      "4863/4863 [==============================] - 1s 176us/step - loss: 0.5677 - bce: 0.5255 - logcosh: 0.0422 - val_loss: 0.4354 - val_bce: 0.4096 - val_logcosh: 0.0257\n",
      "  val_spearman-rho: 0.1988                                                                                                    \n",
      "  reload best: 0.1988\n",
      "Epoch 2/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.4506 - bce: 0.4229 - logcosh: 0.0277 - val_loss: 0.4222 - val_bce: 0.3983 - val_logcosh: 0.0238\n",
      "  val_spearman-rho: 0.2537                                                                                                    \n",
      "  reload best: 0.2537\n",
      "Epoch 3/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.4352 - bce: 0.4095 - logcosh: 0.0256 - val_loss: 0.4137 - val_bce: 0.3910 - val_logcosh: 0.0227\n",
      "  val_spearman-rho: 0.2724                                                                                                    \n",
      "  reload best: 0.2724\n",
      "Epoch 4/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.4271 - bce: 0.4026 - logcosh: 0.0245 - val_loss: 0.4156 - val_bce: 0.3925 - val_logcosh: 0.0231\n",
      "  val_spearman-rho: 0.2753                                                                                                    \n",
      "  reload best: 0.2753\n",
      "Epoch 5/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.4202 - bce: 0.3966 - logcosh: 0.0236 - val_loss: 0.4091 - val_bce: 0.3870 - val_logcosh: 0.0221\n",
      "  val_spearman-rho: 0.2805                                                                                                    \n",
      "  reload best: 0.2805\n",
      "Epoch 6/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.4146 - bce: 0.3918 - logcosh: 0.0228 - val_loss: 0.4043 - val_bce: 0.3830 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.2967                                                                                                    \n",
      "  reload best: 0.2967\n",
      "Epoch 7/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.4102 - bce: 0.3880 - logcosh: 0.0221 - val_loss: 0.4011 - val_bce: 0.3801 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3053                                                                                                    \n",
      "  reload best: 0.3053\n",
      "Epoch 8/100\n",
      "4863/4863 [==============================] - 1s 104us/step - loss: 0.4058 - bce: 0.3843 - logcosh: 0.0215 - val_loss: 0.3987 - val_bce: 0.3781 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3076                                                                                                    \n",
      "  reload best: 0.3076\n",
      "Epoch 9/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.4014 - bce: 0.3805 - logcosh: 0.0209 - val_loss: 0.4012 - val_bce: 0.3802 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3084                                                                                                    \n",
      "  reload best: 0.3084\n",
      "Epoch 10/100\n",
      "4863/4863 [==============================] - 0s 100us/step - loss: 0.3996 - bce: 0.3789 - logcosh: 0.0207 - val_loss: 0.3990 - val_bce: 0.3783 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3209                                                                                                    \n",
      "  reload best: 0.3209\n",
      "Epoch 11/100\n",
      "4863/4863 [==============================] - 1s 104us/step - loss: 0.3971 - bce: 0.3768 - logcosh: 0.0203 - val_loss: 0.3966 - val_bce: 0.3762 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.3215                                                                                                    \n",
      "  reload best: 0.3215\n",
      "Epoch 12/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3949 - bce: 0.3749 - logcosh: 0.0201 - val_loss: 0.3972 - val_bce: 0.3767 - val_logcosh: 0.0205\n",
      "  val_spearman-rho: 0.3098                                                                                                    \n",
      "  reload best: 0.3215\n",
      "Epoch 13/100\n",
      "4863/4863 [==============================] - 1s 104us/step - loss: 0.3942 - bce: 0.3742 - logcosh: 0.0200 - val_loss: 0.3957 - val_bce: 0.3755 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3226                                                                                                    \n",
      "  reload best: 0.3226\n",
      "Epoch 14/100\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3924 - bce: 0.3727 - logcosh: 0.0197 - val_loss: 0.4000 - val_bce: 0.3791 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3201                                                                                                    \n",
      "  reload best: 0.3226\n",
      "Epoch 15/100\n",
      "4863/4863 [==============================] - 0s 102us/step - loss: 0.3916 - bce: 0.3720 - logcosh: 0.0196 - val_loss: 0.3969 - val_bce: 0.3765 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.3227                                                                                                    \n",
      "  reload best: 0.3227\n",
      "Epoch 16/100\n",
      "4863/4863 [==============================] - 0s 95us/step - loss: 0.3907 - bce: 0.3712 - logcosh: 0.0195 - val_loss: 0.3992 - val_bce: 0.3785 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3145                                                                                                    \n",
      "  reload best: 0.3227\n",
      "Epoch 17/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3905 - bce: 0.3711 - logcosh: 0.0194 - val_loss: 0.3965 - val_bce: 0.3761 - val_logcosh: 0.0204\n",
      "  val_spearman-rho: 0.3257                                                                                                    \n",
      "  reload best: 0.3257\n",
      "Epoch 18/100\n",
      "4863/4863 [==============================] - 1s 103us/step - loss: 0.3886 - bce: 0.3694 - logcosh: 0.0192 - val_loss: 0.4000 - val_bce: 0.3791 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3189                                                                                                    \n",
      "  reload best: 0.3257\n",
      "Epoch 19/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3888 - bce: 0.3696 - logcosh: 0.0192 - val_loss: 0.3976 - val_bce: 0.3770 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3202                                                                                                    \n",
      "  reload best: 0.3257\n",
      "Epoch 20/100\n",
      "4863/4863 [==============================] - 1s 103us/step - loss: 0.3887 - bce: 0.3695 - logcosh: 0.0192 - val_loss: 0.3960 - val_bce: 0.3757 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3229                                                                                                    \n",
      "  reload best: 0.3257\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 21/100\n",
      "4863/4863 [==============================] - 0s 100us/step - loss: 0.3842 - bce: 0.3657 - logcosh: 0.0186 - val_loss: 0.3931 - val_bce: 0.3733 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3167                                                                                                    \n",
      "  reload best: 0.3257\n",
      "Epoch 22/100\n",
      "4863/4863 [==============================] - 0s 103us/step - loss: 0.3842 - bce: 0.3656 - logcosh: 0.0186 - val_loss: 0.3920 - val_bce: 0.3722 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3256                                                                                                    \n",
      "  reload best: 0.3257\n",
      "Epoch 23/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3845 - bce: 0.3658 - logcosh: 0.0186 - val_loss: 0.3925 - val_bce: 0.3727 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3234                                                                                                    \n",
      "  reload best: 0.3257\n",
      "Epoch 24/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.3844 - bce: 0.3658 - logcosh: 0.0186 - val_loss: 0.3924 - val_bce: 0.3726 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3305                                                                                                    \n",
      "  reload best: 0.3305\n",
      "Epoch 25/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.3836 - bce: 0.3651 - logcosh: 0.0185 - val_loss: 0.3919 - val_bce: 0.3722 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3256                                                                                                    \n",
      "  reload best: 0.3305\n",
      "Epoch 26/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3834 - bce: 0.3649 - logcosh: 0.0185 - val_loss: 0.3922 - val_bce: 0.3724 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3275                                                                                                    \n",
      "  reload best: 0.3305\n",
      "Epoch 27/100\n",
      "4863/4863 [==============================] - 0s 102us/step - loss: 0.3832 - bce: 0.3648 - logcosh: 0.0184 - val_loss: 0.3918 - val_bce: 0.3720 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.319                                                                                                    \n",
      "  reload best: 0.3305\n",
      "Epoch 28/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3829 - bce: 0.3645 - logcosh: 0.0184 - val_loss: 0.3922 - val_bce: 0.3724 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3264                                                                                                    \n",
      "  reload best: 0.3305\n",
      "Epoch 29/100\n",
      "4863/4863 [==============================] - 0s 100us/step - loss: 0.3828 - bce: 0.3645 - logcosh: 0.0184 - val_loss: 0.3922 - val_bce: 0.3724 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3292                                                                                                    \n",
      "  reload best: 0.3305\n",
      "Epoch 30/100\n",
      "4863/4863 [==============================] - 0s 100us/step - loss: 0.3834 - bce: 0.3649 - logcosh: 0.0185 - val_loss: 0.3925 - val_bce: 0.3727 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3193                                                                                                    \n",
      "  reload best: 0.3305\n",
      "Epoch 31/100\n",
      "4863/4863 [==============================] - 1s 104us/step - loss: 0.3837 - bce: 0.3652 - logcosh: 0.0185 - val_loss: 0.3922 - val_bce: 0.3724 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3222                                                                                                    \n",
      "  reload best: 0.3305\n",
      "Epoch 32/100\n",
      "4863/4863 [==============================] - 0s 102us/step - loss: 0.3829 - bce: 0.3645 - logcosh: 0.0184 - val_loss: 0.3923 - val_bce: 0.3725 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3192                                                                                                    \n",
      "  reload best: 0.3305\n",
      "Epoch 33/100\n",
      "4863/4863 [==============================] - 0s 97us/step - loss: 0.3835 - bce: 0.3650 - logcosh: 0.0185 - val_loss: 0.3922 - val_bce: 0.3724 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3325                                                                                                    \n",
      "  reload best: 0.3325\n",
      "Epoch 34/100\n",
      "4863/4863 [==============================] - 0s 101us/step - loss: 0.3827 - bce: 0.3643 - logcosh: 0.0184 - val_loss: 0.3922 - val_bce: 0.3724 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3251                                                                                                    \n",
      "  reload best: 0.3325\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 5.000000237487257e-06.\n",
      "Epoch 35/100\n",
      "4863/4863 [==============================] - 0s 100us/step - loss: 0.3823 - bce: 0.3640 - logcosh: 0.0183 - val_loss: 0.3919 - val_bce: 0.3721 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3164                                                                                                    \n",
      "  reload best: 0.3325\n",
      "Epoch 36/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3822 - bce: 0.3639 - logcosh: 0.0183 - val_loss: 0.3918 - val_bce: 0.3721 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3183                                                                                                    \n",
      "  reload best: 0.3325\n",
      "Epoch 37/100\n",
      "4863/4863 [==============================] - 0s 99us/step - loss: 0.3827 - bce: 0.3644 - logcosh: 0.0184 - val_loss: 0.3918 - val_bce: 0.3721 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3168                                                                                                    \n",
      "  reload best: 0.3325\n",
      "Epoch 38/100\n",
      "4863/4863 [==============================] - 0s 98us/step - loss: 0.3820 - bce: 0.3638 - logcosh: 0.0183 - val_loss: 0.3918 - val_bce: 0.3721 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3261                                                                                                    \n",
      "  reload best: 0.3325\n",
      "Epoch 39/100\n",
      "4863/4863 [==============================] - 0s 100us/step - loss: 0.3822 - bce: 0.3639 - logcosh: 0.0183 - val_loss: 0.3918 - val_bce: 0.3721 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3252                                                                                                    \n",
      "  reload best: 0.3325\n",
      "Epoch 40/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3824 - bce: 0.3641 - logcosh: 0.0183 - val_loss: 0.3918 - val_bce: 0.3721 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3302                                                                                                    \n",
      "  reload best: 0.3325\n",
      "Epoch 41/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3822 - bce: 0.3639 - logcosh: 0.0183 - val_loss: 0.3919 - val_bce: 0.3721 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3241                                                                                                    \n",
      "  reload best: 0.3325\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 42/100\n",
      "4863/4863 [==============================] - 0s 96us/step - loss: 0.3824 - bce: 0.3641 - logcosh: 0.0183 - val_loss: 0.3919 - val_bce: 0.3721 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3287                                                                                                    \n",
      "  reload best: 0.3325\n",
      "  val_spearman-rho: 0.3281                                                                                                    \n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/50\n",
      "4863/4863 [==============================] - 1s 145us/step - loss: 0.4200 - bce: 0.3966 - logcosh: 0.0235 - val_loss: 0.4304 - val_bce: 0.4053 - val_logcosh: 0.0251\n",
      "  val_spearman-rho: 0.3155                                                                                                    \n",
      "Epoch 2/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.4201 - bce: 0.3965 - logcosh: 0.0236 - val_loss: 0.4343 - val_bce: 0.4082 - val_logcosh: 0.0261\n",
      "  val_spearman-rho: 0.3236                                                                                                    \n",
      "Epoch 3/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.4191 - bce: 0.3956 - logcosh: 0.0235 - val_loss: 0.4357 - val_bce: 0.4094 - val_logcosh: 0.0263\n",
      "  val_spearman-rho: 0.3286                                                                                                    \n",
      "Epoch 4/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.4178 - bce: 0.3945 - logcosh: 0.0233 - val_loss: 0.4379 - val_bce: 0.4115 - val_logcosh: 0.0264\n",
      "  val_spearman-rho: 0.3148                                                                                                    \n",
      "Epoch 5/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.4202 - bce: 0.3966 - logcosh: 0.0236 - val_loss: 0.4258 - val_bce: 0.4011 - val_logcosh: 0.0248\n",
      "  val_spearman-rho: 0.316                                                                                                    \n",
      "Epoch 6/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.4197 - bce: 0.3962 - logcosh: 0.0236 - val_loss: 0.4316 - val_bce: 0.4062 - val_logcosh: 0.0253\n",
      "  val_spearman-rho: 0.3095                                                                                                    \n",
      "Epoch 7/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.4183 - bce: 0.3949 - logcosh: 0.0234 - val_loss: 0.4451 - val_bce: 0.4178 - val_logcosh: 0.0273\n",
      "  val_spearman-rho: 0.3218                                                                                                    \n",
      "Epoch 8/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.4174 - bce: 0.3942 - logcosh: 0.0232 - val_loss: 0.4355 - val_bce: 0.4094 - val_logcosh: 0.0261\n",
      "  val_spearman-rho: 0.3239                                                                                                    \n",
      "Epoch 9/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.4182 - bce: 0.3949 - logcosh: 0.0233 - val_loss: 0.4351 - val_bce: 0.4086 - val_logcosh: 0.0265\n",
      "  val_spearman-rho: 0.3213                                                                                                    \n",
      "Epoch 10/50\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.4179 - bce: 0.3946 - logcosh: 0.0233 - val_loss: 0.4288 - val_bce: 0.4035 - val_logcosh: 0.0253\n",
      "  val_spearman-rho: 0.322                                                                                                    \n",
      "Epoch 11/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.4167 - bce: 0.3936 - logcosh: 0.0231 - val_loss: 0.4322 - val_bce: 0.4067 - val_logcosh: 0.0255\n",
      "  val_spearman-rho: 0.3234                                                                                                    \n",
      "Epoch 12/50\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.4167 - bce: 0.3936 - logcosh: 0.0231 - val_loss: 0.4344 - val_bce: 0.4085 - val_logcosh: 0.0259\n",
      "  val_spearman-rho: 0.3159                                                                                                    \n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 13/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3847 - bce: 0.3660 - logcosh: 0.0186 - val_loss: 0.3921 - val_bce: 0.3723 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3252                                                                                                    \n",
      "Epoch 14/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3833 - bce: 0.3648 - logcosh: 0.0184 - val_loss: 0.3929 - val_bce: 0.3730 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3256                                                                                                    \n",
      "Epoch 15/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3829 - bce: 0.3645 - logcosh: 0.0184 - val_loss: 0.3940 - val_bce: 0.3739 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.3177                                                                                                    \n",
      "Epoch 16/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3827 - bce: 0.3644 - logcosh: 0.0184 - val_loss: 0.3919 - val_bce: 0.3722 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3246                                                                                                    \n",
      "Epoch 17/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3832 - bce: 0.3648 - logcosh: 0.0184 - val_loss: 0.3924 - val_bce: 0.3726 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3184                                                                                                    \n",
      "Epoch 18/50\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3830 - bce: 0.3646 - logcosh: 0.0184 - val_loss: 0.3925 - val_bce: 0.3727 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3202                                                                                                    \n",
      "Epoch 19/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3832 - bce: 0.3647 - logcosh: 0.0184 - val_loss: 0.3927 - val_bce: 0.3728 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.328                                                                                                    \n",
      "Epoch 20/50\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.3826 - bce: 0.3642 - logcosh: 0.0184 - val_loss: 0.3922 - val_bce: 0.3725 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.322                                                                                                    \n",
      "Epoch 21/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3831 - bce: 0.3646 - logcosh: 0.0184 - val_loss: 0.3918 - val_bce: 0.3721 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3253                                                                                                    \n",
      "Epoch 22/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3831 - bce: 0.3647 - logcosh: 0.0184 - val_loss: 0.3922 - val_bce: 0.3724 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3305                                                                                                    \n",
      "Epoch 23/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3833 - bce: 0.3648 - logcosh: 0.0184 - val_loss: 0.3926 - val_bce: 0.3727 - val_logcosh: 0.0199\n",
      "  val_spearman-rho: 0.3243                                                                                                    \n",
      "Epoch 24/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3827 - bce: 0.3644 - logcosh: 0.0184 - val_loss: 0.3921 - val_bce: 0.3723 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3166                                                                                                    \n",
      "Epoch 25/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3826 - bce: 0.3642 - logcosh: 0.0184 - val_loss: 0.3926 - val_bce: 0.3728 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3209                                                                                                    \n",
      "Epoch 26/50\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3829 - bce: 0.3645 - logcosh: 0.0184 - val_loss: 0.3919 - val_bce: 0.3721 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3214                                                                                                    \n",
      "Epoch 27/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3830 - bce: 0.3646 - logcosh: 0.0184 - val_loss: 0.3920 - val_bce: 0.3723 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3245                                                                                                    \n",
      "Epoch 28/50\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.3820 - bce: 0.3638 - logcosh: 0.0183 - val_loss: 0.3923 - val_bce: 0.3724 - val_logcosh: 0.0198\n",
      "  val_spearman-rho: 0.3157                                                                                                    \n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 29/50\n",
      "4863/4863 [==============================] - 0s 84us/step - loss: 0.3823 - bce: 0.3640 - logcosh: 0.0183 - val_loss: 0.3916 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3281                                                                                                    \n",
      "Epoch 30/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3821 - bce: 0.3638 - logcosh: 0.0183 - val_loss: 0.3917 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3226                                                                                                    \n",
      "Epoch 31/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3821 - bce: 0.3638 - logcosh: 0.0183 - val_loss: 0.3917 - val_bce: 0.3720 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3319                                                                                                    \n",
      "Epoch 32/50\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3822 - bce: 0.3639 - logcosh: 0.0183 - val_loss: 0.3917 - val_bce: 0.3720 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3251                                                                                                    \n",
      "Epoch 33/50\n",
      "4863/4863 [==============================] - 0s 87us/step - loss: 0.3822 - bce: 0.3639 - logcosh: 0.0183 - val_loss: 0.3917 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3268                                                                                                    \n",
      "Epoch 34/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3820 - bce: 0.3637 - logcosh: 0.0183 - val_loss: 0.3917 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3213                                                                                                    \n",
      "Epoch 35/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3821 - bce: 0.3638 - logcosh: 0.0183 - val_loss: 0.3917 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3216                                                                                                    \n",
      "Epoch 36/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3818 - bce: 0.3636 - logcosh: 0.0182 - val_loss: 0.3916 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.328                                                                                                    \n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 37/50\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3827 - bce: 0.3644 - logcosh: 0.0184 - val_loss: 0.3916 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3291                                                                                                    \n",
      "Epoch 38/50\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3817 - bce: 0.3635 - logcosh: 0.0182 - val_loss: 0.3916 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3274                                                                                                    \n",
      "Epoch 39/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3820 - bce: 0.3637 - logcosh: 0.0183 - val_loss: 0.3916 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3226                                                                                                    \n",
      "Epoch 40/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3821 - bce: 0.3638 - logcosh: 0.0183 - val_loss: 0.3916 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3342                                                                                                    \n",
      "Epoch 41/50\n",
      "4863/4863 [==============================] - 0s 83us/step - loss: 0.3820 - bce: 0.3638 - logcosh: 0.0183 - val_loss: 0.3916 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3192                                                                                                    \n",
      "Epoch 42/50\n",
      "4863/4863 [==============================] - 0s 88us/step - loss: 0.3820 - bce: 0.3638 - logcosh: 0.0183 - val_loss: 0.3916 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3218                                                                                                    \n",
      "Epoch 43/50\n",
      "4863/4863 [==============================] - 0s 85us/step - loss: 0.3821 - bce: 0.3638 - logcosh: 0.0183 - val_loss: 0.3916 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3294                                                                                                    \n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 44/50\n",
      "4863/4863 [==============================] - 0s 93us/step - loss: 0.3821 - bce: 0.3638 - logcosh: 0.0183 - val_loss: 0.3916 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3228                                                                                                    \n",
      "Epoch 45/50\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.3824 - bce: 0.3641 - logcosh: 0.0183 - val_loss: 0.3916 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3203                                                                                                    \n",
      "Epoch 46/50\n",
      "4863/4863 [==============================] - 0s 90us/step - loss: 0.3819 - bce: 0.3636 - logcosh: 0.0183 - val_loss: 0.3916 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3247                                                                                                    \n",
      "Epoch 47/50\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.3818 - bce: 0.3635 - logcosh: 0.0182 - val_loss: 0.3916 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3233                                                                                                    \n",
      "Epoch 48/50\n",
      "4863/4863 [==============================] - 0s 91us/step - loss: 0.3816 - bce: 0.3634 - logcosh: 0.0182 - val_loss: 0.3916 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3279                                                                                                    \n",
      "Epoch 49/50\n",
      "4863/4863 [==============================] - 0s 86us/step - loss: 0.3818 - bce: 0.3635 - logcosh: 0.0182 - val_loss: 0.3916 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3286                                                                                                    \n",
      "Epoch 50/50\n",
      "4863/4863 [==============================] - 0s 89us/step - loss: 0.3818 - bce: 0.3636 - logcosh: 0.0182 - val_loss: 0.3916 - val_bce: 0.3719 - val_logcosh: 0.0197\n",
      "  val_spearman-rho: 0.3238                                                                                                    \n",
      "  val_spearman-rho: 0.3209                                                                                                    \n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 4576)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4096)              18747392  \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 20,860,446\n",
      "Trainable params: 20,860,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/100\n",
      "4863/4863 [==============================] - 1s 275us/step - loss: 3.3983 - bce: 0.7031 - logcosh: 0.0386 - val_loss: 1.3009 - val_bce: 0.4201 - val_logcosh: 0.0272\n",
      "  val_spearman-rho: 0.2811                                                                                                    \n",
      "  reload best: 0.2811\n",
      "Epoch 2/100\n",
      "4863/4863 [==============================] - 1s 195us/step - loss: 0.8805 - bce: 0.4034 - logcosh: 0.0249 - val_loss: 0.6548 - val_bce: 0.4030 - val_logcosh: 0.0241\n",
      "  val_spearman-rho: 0.2833                                                                                                    \n",
      "  reload best: 0.2833\n",
      "Epoch 3/100\n",
      "4863/4863 [==============================] - 1s 193us/step - loss: 0.5592 - bce: 0.3921 - logcosh: 0.0231 - val_loss: 0.5101 - val_bce: 0.3988 - val_logcosh: 0.0239\n",
      "  val_spearman-rho: 0.2915                                                                                                    \n",
      "  reload best: 0.2915\n",
      "Epoch 4/100\n",
      "4863/4863 [==============================] - 1s 193us/step - loss: 0.4726 - bce: 0.3869 - logcosh: 0.0223 - val_loss: 0.4638 - val_bce: 0.3955 - val_logcosh: 0.0232\n",
      "  val_spearman-rho: 0.3002                                                                                                    \n",
      "  reload best: 0.3002\n",
      "Epoch 5/100\n",
      "4863/4863 [==============================] - 1s 192us/step - loss: 0.4394 - bce: 0.3818 - logcosh: 0.0214 - val_loss: 0.4425 - val_bce: 0.3908 - val_logcosh: 0.0225\n",
      "  val_spearman-rho: 0.2914                                                                                                    \n",
      "  reload best: 0.3002\n",
      "Epoch 6/100\n",
      "4863/4863 [==============================] - 1s 209us/step - loss: 0.4406 - bce: 0.3823 - logcosh: 0.0215 - val_loss: 0.4456 - val_bce: 0.3923 - val_logcosh: 0.0231\n",
      "  val_spearman-rho: 0.2933                                                                                                    \n",
      "  reload best: 0.3002\n",
      "Epoch 7/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4383 - bce: 0.3808 - logcosh: 0.0213 - val_loss: 0.4410 - val_bce: 0.3901 - val_logcosh: 0.0225\n",
      "  val_spearman-rho: 0.2977                                                                                                    \n",
      "  reload best: 0.3002\n",
      "Epoch 8/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4394 - bce: 0.3815 - logcosh: 0.0213 - val_loss: 0.4415 - val_bce: 0.3908 - val_logcosh: 0.0228\n",
      "  val_spearman-rho: 0.2965                                                                                                    \n",
      "  reload best: 0.3002\n",
      "Epoch 9/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4393 - bce: 0.3819 - logcosh: 0.0214 - val_loss: 0.4514 - val_bce: 0.3996 - val_logcosh: 0.0236\n",
      "  val_spearman-rho: 0.2965                                                                                                    \n",
      "  reload best: 0.3002\n",
      "Epoch 10/100\n",
      "4863/4863 [==============================] - 1s 196us/step - loss: 0.4384 - bce: 0.3814 - logcosh: 0.0213 - val_loss: 0.4453 - val_bce: 0.3934 - val_logcosh: 0.0230\n",
      "  val_spearman-rho: 0.2983                                                                                                    \n",
      "  reload best: 0.3002\n",
      "Epoch 11/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4380 - bce: 0.3812 - logcosh: 0.0213 - val_loss: 0.4462 - val_bce: 0.3951 - val_logcosh: 0.0232\n",
      "  val_spearman-rho: 0.2994                                                                                                    \n",
      "  reload best: 0.3002\n",
      "Epoch 12/100\n",
      "4863/4863 [==============================] - 1s 191us/step - loss: 0.4382 - bce: 0.3813 - logcosh: 0.0213 - val_loss: 0.4392 - val_bce: 0.3897 - val_logcosh: 0.0224\n",
      "  val_spearman-rho: 0.2981                                                                                                    \n",
      "  reload best: 0.3002\n",
      "Epoch 13/100\n",
      "4863/4863 [==============================] - 1s 191us/step - loss: 0.4411 - bce: 0.3836 - logcosh: 0.0217 - val_loss: 0.4416 - val_bce: 0.3911 - val_logcosh: 0.0227\n",
      "  val_spearman-rho: 0.2881                                                                                                    \n",
      "  reload best: 0.3002\n",
      "Epoch 14/100\n",
      "4863/4863 [==============================] - 1s 191us/step - loss: 0.4424 - bce: 0.3839 - logcosh: 0.0217 - val_loss: 0.4415 - val_bce: 0.3910 - val_logcosh: 0.0227\n",
      "  val_spearman-rho: 0.2918                                                                                                    \n",
      "  reload best: 0.3002\n",
      "Epoch 15/100\n",
      "4863/4863 [==============================] - 1s 193us/step - loss: 0.4392 - bce: 0.3822 - logcosh: 0.0215 - val_loss: 0.4497 - val_bce: 0.3989 - val_logcosh: 0.0241\n",
      "  val_spearman-rho: 0.2845                                                                                                    \n",
      "  reload best: 0.3002\n",
      "Epoch 16/100\n",
      "4863/4863 [==============================] - 1s 196us/step - loss: 0.4402 - bce: 0.3835 - logcosh: 0.0216 - val_loss: 0.4397 - val_bce: 0.3902 - val_logcosh: 0.0226\n",
      "  val_spearman-rho: 0.2891                                                                                                    \n",
      "  reload best: 0.3002\n",
      "Epoch 17/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4380 - bce: 0.3816 - logcosh: 0.0214 - val_loss: 0.4393 - val_bce: 0.3895 - val_logcosh: 0.0224\n",
      "  val_spearman-rho: 0.2913                                                                                                    \n",
      "  reload best: 0.3002\n",
      "Epoch 18/100\n",
      "4863/4863 [==============================] - 1s 193us/step - loss: 0.4376 - bce: 0.3814 - logcosh: 0.0213 - val_loss: 0.4473 - val_bce: 0.3972 - val_logcosh: 0.0232\n",
      "  val_spearman-rho: 0.2869                                                                                                    \n",
      "  reload best: 0.3002\n",
      "Epoch 19/100\n",
      "4863/4863 [==============================] - 1s 193us/step - loss: 0.4412 - bce: 0.3837 - logcosh: 0.0217 - val_loss: 0.4440 - val_bce: 0.3926 - val_logcosh: 0.0229\n",
      "  val_spearman-rho: 0.2867                                                                                                    \n",
      "  reload best: 0.3002\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 20/100\n",
      "4863/4863 [==============================] - 1s 193us/step - loss: 0.4322 - bce: 0.3714 - logcosh: 0.0197 - val_loss: 0.4418 - val_bce: 0.3825 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3034                                                                                                    \n",
      "  reload best: 0.3034\n",
      "Epoch 21/100\n",
      "4863/4863 [==============================] - 1s 201us/step - loss: 0.4250 - bce: 0.3694 - logcosh: 0.0193 - val_loss: 0.4382 - val_bce: 0.3824 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3139                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 22/100\n",
      "4863/4863 [==============================] - 1s 195us/step - loss: 0.4215 - bce: 0.3690 - logcosh: 0.0193 - val_loss: 0.4358 - val_bce: 0.3826 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3107                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 23/100\n",
      "4863/4863 [==============================] - 1s 202us/step - loss: 0.4212 - bce: 0.3688 - logcosh: 0.0193 - val_loss: 0.4361 - val_bce: 0.3829 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.309                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 24/100\n",
      "4863/4863 [==============================] - 1s 193us/step - loss: 0.4216 - bce: 0.3691 - logcosh: 0.0193 - val_loss: 0.4363 - val_bce: 0.3830 - val_logcosh: 0.0215\n",
      "  val_spearman-rho: 0.3127                                                                                                    \n",
      "  reload best: 0.3139\n",
      "Epoch 25/100\n",
      "4863/4863 [==============================] - 1s 191us/step - loss: 0.4215 - bce: 0.3691 - logcosh: 0.0193 - val_loss: 0.4352 - val_bce: 0.3821 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3161                                                                                                    \n",
      "  reload best: 0.3161\n",
      "Epoch 26/100\n",
      "4863/4863 [==============================] - 1s 191us/step - loss: 0.4178 - bce: 0.3681 - logcosh: 0.0191 - val_loss: 0.4313 - val_bce: 0.3806 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3116                                                                                                    \n",
      "  reload best: 0.3161\n",
      "Epoch 27/100\n",
      "4863/4863 [==============================] - 1s 193us/step - loss: 0.4179 - bce: 0.3681 - logcosh: 0.0192 - val_loss: 0.4338 - val_bce: 0.3829 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.3147                                                                                                    \n",
      "  reload best: 0.3161\n",
      "Epoch 28/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4179 - bce: 0.3682 - logcosh: 0.0191 - val_loss: 0.4329 - val_bce: 0.3822 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3147                                                                                                    \n",
      "  reload best: 0.3161\n",
      "Epoch 29/100\n",
      "4863/4863 [==============================] - 1s 193us/step - loss: 0.4181 - bce: 0.3684 - logcosh: 0.0192 - val_loss: 0.4313 - val_bce: 0.3808 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.3155                                                                                                    \n",
      "  reload best: 0.3161\n",
      "Epoch 30/100\n",
      "4863/4863 [==============================] - 1s 198us/step - loss: 0.4182 - bce: 0.3685 - logcosh: 0.0192 - val_loss: 0.4323 - val_bce: 0.3818 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3112                                                                                                    \n",
      "  reload best: 0.3161\n",
      "Epoch 31/100\n",
      "4863/4863 [==============================] - 1s 197us/step - loss: 0.4181 - bce: 0.3684 - logcosh: 0.0192 - val_loss: 0.4317 - val_bce: 0.3811 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.3107                                                                                                    \n",
      "  reload best: 0.3161\n",
      "Epoch 32/100\n",
      "4863/4863 [==============================] - 1s 195us/step - loss: 0.4184 - bce: 0.3686 - logcosh: 0.0192 - val_loss: 0.4307 - val_bce: 0.3804 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3176                                                                                                    \n",
      "  reload best: 0.3176\n",
      "Epoch 33/100\n",
      "4863/4863 [==============================] - 1s 193us/step - loss: 0.4152 - bce: 0.3678 - logcosh: 0.0191 - val_loss: 0.4305 - val_bce: 0.3819 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.3095                                                                                                    \n",
      "  reload best: 0.3176\n",
      "Epoch 34/100\n",
      "4863/4863 [==============================] - 1s 196us/step - loss: 0.4158 - bce: 0.3682 - logcosh: 0.0192 - val_loss: 0.4296 - val_bce: 0.3810 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.3186                                                                                                    \n",
      "  reload best: 0.3186\n",
      "Epoch 35/100\n",
      "4863/4863 [==============================] - 1s 196us/step - loss: 0.4126 - bce: 0.3671 - logcosh: 0.0190 - val_loss: 0.4291 - val_bce: 0.3822 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3152                                                                                                    \n",
      "  reload best: 0.3186\n",
      "Epoch 36/100\n",
      "4863/4863 [==============================] - 1s 195us/step - loss: 0.4132 - bce: 0.3676 - logcosh: 0.0191 - val_loss: 0.4310 - val_bce: 0.3838 - val_logcosh: 0.0215\n",
      "  val_spearman-rho: 0.3122                                                                                                    \n",
      "  reload best: 0.3186\n",
      "Epoch 37/100\n",
      "4863/4863 [==============================] - 1s 193us/step - loss: 0.4122 - bce: 0.3668 - logcosh: 0.0189 - val_loss: 0.4279 - val_bce: 0.3812 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3093                                                                                                    \n",
      "  reload best: 0.3186\n",
      "Epoch 38/100\n",
      "4863/4863 [==============================] - 1s 198us/step - loss: 0.4127 - bce: 0.3672 - logcosh: 0.0190 - val_loss: 0.4285 - val_bce: 0.3818 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3164                                                                                                    \n",
      "  reload best: 0.3186\n",
      "Epoch 39/100\n",
      "4863/4863 [==============================] - 1s 197us/step - loss: 0.4124 - bce: 0.3670 - logcosh: 0.0190 - val_loss: 0.4281 - val_bce: 0.3814 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.306                                                                                                    \n",
      "  reload best: 0.3186\n",
      "Epoch 40/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4131 - bce: 0.3676 - logcosh: 0.0191 - val_loss: 0.4270 - val_bce: 0.3804 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3165                                                                                                    \n",
      "  reload best: 0.3186\n",
      "Epoch 41/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4130 - bce: 0.3675 - logcosh: 0.0191 - val_loss: 0.4286 - val_bce: 0.3819 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3073                                                                                                    \n",
      "  reload best: 0.3186\n",
      "Epoch 42/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4125 - bce: 0.3671 - logcosh: 0.0190 - val_loss: 0.4270 - val_bce: 0.3806 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.314                                                                                                    \n",
      "  reload best: 0.3186\n",
      "Epoch 43/100\n",
      "4863/4863 [==============================] - 1s 193us/step - loss: 0.4125 - bce: 0.3671 - logcosh: 0.0190 - val_loss: 0.4273 - val_bce: 0.3808 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3105                                                                                                    \n",
      "  reload best: 0.3186\n",
      "Epoch 44/100\n",
      "4863/4863 [==============================] - 1s 195us/step - loss: 0.4126 - bce: 0.3672 - logcosh: 0.0190 - val_loss: 0.4300 - val_bce: 0.3832 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.3118                                                                                                    \n",
      "  reload best: 0.3186\n",
      "Epoch 45/100\n",
      "4863/4863 [==============================] - 1s 196us/step - loss: 0.4125 - bce: 0.3672 - logcosh: 0.0190 - val_loss: 0.4307 - val_bce: 0.3837 - val_logcosh: 0.0216\n",
      "  val_spearman-rho: 0.3094                                                                                                    \n",
      "  reload best: 0.3186\n",
      "Epoch 46/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4123 - bce: 0.3669 - logcosh: 0.0189 - val_loss: 0.4281 - val_bce: 0.3816 - val_logcosh: 0.0212\n",
      "  val_spearman-rho: 0.3145                                                                                                    \n",
      "  reload best: 0.3186\n",
      "Epoch 47/100\n",
      "4863/4863 [==============================] - 1s 196us/step - loss: 0.4127 - bce: 0.3673 - logcosh: 0.0190 - val_loss: 0.4285 - val_bce: 0.3819 - val_logcosh: 0.0213\n",
      "  val_spearman-rho: 0.3119                                                                                                    \n",
      "  reload best: 0.3186\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 5.000000237487257e-06.\n",
      "Epoch 48/100\n",
      "4863/4863 [==============================] - 1s 192us/step - loss: 0.4107 - bce: 0.3649 - logcosh: 0.0186 - val_loss: 0.4269 - val_bce: 0.3791 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3238                                                                                                    \n",
      "  reload best: 0.3238\n",
      "Epoch 49/100\n",
      "4863/4863 [==============================] - 1s 198us/step - loss: 0.4098 - bce: 0.3644 - logcosh: 0.0185 - val_loss: 0.4266 - val_bce: 0.3791 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3211                                                                                                    \n",
      "  reload best: 0.3238\n",
      "Epoch 50/100\n",
      "4863/4863 [==============================] - 1s 195us/step - loss: 0.4097 - bce: 0.3643 - logcosh: 0.0185 - val_loss: 0.4265 - val_bce: 0.3790 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3163                                                                                                    \n",
      "  reload best: 0.3238\n",
      "Epoch 51/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4097 - bce: 0.3644 - logcosh: 0.0185 - val_loss: 0.4262 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3118                                                                                                    \n",
      "  reload best: 0.3238\n",
      "Epoch 52/100\n",
      "4863/4863 [==============================] - 1s 196us/step - loss: 0.4098 - bce: 0.3645 - logcosh: 0.0185 - val_loss: 0.4265 - val_bce: 0.3790 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3115                                                                                                    \n",
      "  reload best: 0.3238\n",
      "Epoch 53/100\n",
      "4863/4863 [==============================] - 1s 295us/step - loss: 0.4097 - bce: 0.3644 - logcosh: 0.0185 - val_loss: 0.4266 - val_bce: 0.3791 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3193                                                                                                    \n",
      "  reload best: 0.3238\n",
      "Epoch 54/100\n",
      "4863/4863 [==============================] - 1s 202us/step - loss: 0.4097 - bce: 0.3644 - logcosh: 0.0185 - val_loss: 0.4267 - val_bce: 0.3793 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3128                                                                                                    \n",
      "  reload best: 0.3238\n",
      "Epoch 55/100\n",
      "4863/4863 [==============================] - 1s 203us/step - loss: 0.4097 - bce: 0.3643 - logcosh: 0.0185 - val_loss: 0.4266 - val_bce: 0.3792 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3222                                                                                                    \n",
      "  reload best: 0.3238\n",
      "Epoch 56/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4098 - bce: 0.3644 - logcosh: 0.0185 - val_loss: 0.4269 - val_bce: 0.3794 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3185                                                                                                    \n",
      "  reload best: 0.3238\n",
      "Epoch 57/100\n",
      "4863/4863 [==============================] - 1s 193us/step - loss: 0.4097 - bce: 0.3643 - logcosh: 0.0185 - val_loss: 0.4265 - val_bce: 0.3791 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3163                                                                                                    \n",
      "  reload best: 0.3238\n",
      "Epoch 58/100\n",
      "4863/4863 [==============================] - 1s 196us/step - loss: 0.4098 - bce: 0.3644 - logcosh: 0.0185 - val_loss: 0.4262 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3245                                                                                                    \n",
      "  reload best: 0.3245\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 59/100\n",
      "4863/4863 [==============================] - 1s 192us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3207                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 60/100\n",
      "4863/4863 [==============================] - 1s 190us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3789 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3163                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 61/100\n",
      "4863/4863 [==============================] - 1s 192us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4263 - val_bce: 0.3789 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3222                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 62/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4261 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3176                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 63/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4263 - val_bce: 0.3790 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3186                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 64/100\n",
      "4863/4863 [==============================] - 1s 200us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3162                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 65/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3789 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3161                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 66/100\n",
      "4863/4863 [==============================] - 1s 195us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4263 - val_bce: 0.3789 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3223                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 67/100\n",
      "4863/4863 [==============================] - 1s 192us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4263 - val_bce: 0.3789 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3124                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 68/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3156                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 69/100\n",
      "4863/4863 [==============================] - 1s 193us/step - loss: 0.4089 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4263 - val_bce: 0.3789 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3125                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 70/100\n",
      "4863/4863 [==============================] - 1s 196us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4261 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.314                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 71/100\n",
      "4863/4863 [==============================] - 1s 191us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3137                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 72/100\n",
      "4863/4863 [==============================] - 1s 188us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3789 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3143                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 73/100\n",
      "4863/4863 [==============================] - 1s 193us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3789 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3097                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 74/100\n",
      "4863/4863 [==============================] - 1s 202us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3174                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 75/100\n",
      "4863/4863 [==============================] - 1s 195us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3168                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 76/100\n",
      "4863/4863 [==============================] - 1s 193us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3789 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3169                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 77/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3789 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3142                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 78/100\n",
      "4863/4863 [==============================] - 1s 196us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4261 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3149                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 79/100\n",
      "4863/4863 [==============================] - 1s 192us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4263 - val_bce: 0.3789 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.315                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 80/100\n",
      "4863/4863 [==============================] - 1s 195us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3789 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3143                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 81/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3214                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 82/100\n",
      "4863/4863 [==============================] - 1s 195us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4261 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3212                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 83/100\n",
      "4863/4863 [==============================] - 1s 189us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3789 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.314                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 84/100\n",
      "4863/4863 [==============================] - 1s 191us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4261 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3225                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 85/100\n",
      "4863/4863 [==============================] - 1s 195us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3789 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3164                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 86/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3789 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.316                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 87/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4261 - val_bce: 0.3787 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3132                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 88/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4261 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3157                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 89/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3789 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.317                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 90/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4261 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3177                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 91/100\n",
      "4863/4863 [==============================] - 1s 195us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4263 - val_bce: 0.3789 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3201                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 92/100\n",
      "4863/4863 [==============================] - 1s 193us/step - loss: 0.4089 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3199                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 93/100\n",
      "4863/4863 [==============================] - 1s 193us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3789 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3189                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 94/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4261 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3209                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 95/100\n",
      "4863/4863 [==============================] - 1s 192us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3138                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 96/100\n",
      "4863/4863 [==============================] - 1s 192us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3118                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 97/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3789 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3183                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 98/100\n",
      "4863/4863 [==============================] - 1s 197us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4262 - val_bce: 0.3789 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3188                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 99/100\n",
      "4863/4863 [==============================] - 1s 195us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4261 - val_bce: 0.3787 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3239                                                                                                    \n",
      "  reload best: 0.3245\n",
      "Epoch 100/100\n",
      "4863/4863 [==============================] - 1s 194us/step - loss: 0.4090 - bce: 0.3639 - logcosh: 0.0184 - val_loss: 0.4261 - val_bce: 0.3787 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3104                                                                                                    \n",
      "  reload best: 0.3245\n",
      "  val_spearman-rho: 0.3178                                                                                                    \n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/50\n",
      "4863/4863 [==============================] - 1s 193us/step - loss: 0.4099 - bce: 0.3649 - logcosh: 0.0186 - val_loss: 0.4303 - val_bce: 0.3828 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.3146                                                                                                    \n",
      "Epoch 2/50\n",
      "4863/4863 [==============================] - 1s 129us/step - loss: 0.4094 - bce: 0.3650 - logcosh: 0.0186 - val_loss: 0.4255 - val_bce: 0.3793 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.319                                                                                                    \n",
      "Epoch 3/50\n",
      "4863/4863 [==============================] - 1s 130us/step - loss: 0.4082 - bce: 0.3645 - logcosh: 0.0185 - val_loss: 0.4265 - val_bce: 0.3807 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.317                                                                                                    \n",
      "Epoch 4/50\n",
      "4863/4863 [==============================] - 1s 127us/step - loss: 0.4076 - bce: 0.3646 - logcosh: 0.0186 - val_loss: 0.4272 - val_bce: 0.3818 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3162                                                                                                    \n",
      "Epoch 5/50\n",
      "4863/4863 [==============================] - 1s 126us/step - loss: 0.4067 - bce: 0.3643 - logcosh: 0.0185 - val_loss: 0.4243 - val_bce: 0.3798 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3208                                                                                                    \n",
      "Epoch 6/50\n",
      "4863/4863 [==============================] - 1s 132us/step - loss: 0.4061 - bce: 0.3642 - logcosh: 0.0185 - val_loss: 0.4239 - val_bce: 0.3799 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3231                                                                                                    \n",
      "Epoch 7/50\n",
      "4863/4863 [==============================] - 1s 137us/step - loss: 0.4054 - bce: 0.3641 - logcosh: 0.0185 - val_loss: 0.4224 - val_bce: 0.3791 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3187                                                                                                    \n",
      "Epoch 8/50\n",
      "4863/4863 [==============================] - 1s 130us/step - loss: 0.4045 - bce: 0.3638 - logcosh: 0.0184 - val_loss: 0.4237 - val_bce: 0.3807 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3177                                                                                                    \n",
      "Epoch 9/50\n",
      "4863/4863 [==============================] - 1s 150us/step - loss: 0.4039 - bce: 0.3638 - logcosh: 0.0184 - val_loss: 0.4225 - val_bce: 0.3801 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3257                                                                                                    \n",
      "Epoch 10/50\n",
      "4863/4863 [==============================] - 1s 128us/step - loss: 0.4035 - bce: 0.3638 - logcosh: 0.0185 - val_loss: 0.4205 - val_bce: 0.3788 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3204                                                                                                    \n",
      "Epoch 11/50\n",
      "4863/4863 [==============================] - 1s 127us/step - loss: 0.4025 - bce: 0.3634 - logcosh: 0.0184 - val_loss: 0.4209 - val_bce: 0.3796 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3194                                                                                                    \n",
      "Epoch 12/50\n",
      "4863/4863 [==============================] - 1s 132us/step - loss: 0.4020 - bce: 0.3634 - logcosh: 0.0184 - val_loss: 0.4208 - val_bce: 0.3799 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3171                                                                                                    \n",
      "Epoch 13/50\n",
      "4863/4863 [==============================] - 1s 129us/step - loss: 0.4015 - bce: 0.3634 - logcosh: 0.0184 - val_loss: 0.4201 - val_bce: 0.3796 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.319                                                                                                    \n",
      "Epoch 14/50\n",
      "4863/4863 [==============================] - 1s 127us/step - loss: 0.4011 - bce: 0.3634 - logcosh: 0.0184 - val_loss: 0.4208 - val_bce: 0.3807 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3164                                                                                                    \n",
      "Epoch 15/50\n",
      "4863/4863 [==============================] - 1s 131us/step - loss: 0.4004 - bce: 0.3632 - logcosh: 0.0183 - val_loss: 0.4188 - val_bce: 0.3794 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3199                                                                                                    \n",
      "Epoch 16/50\n",
      "4863/4863 [==============================] - 1s 132us/step - loss: 0.3999 - bce: 0.3631 - logcosh: 0.0183 - val_loss: 0.4187 - val_bce: 0.3796 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3178                                                                                                    \n",
      "Epoch 17/50\n",
      "4863/4863 [==============================] - 1s 151us/step - loss: 0.3995 - bce: 0.3631 - logcosh: 0.0184 - val_loss: 0.4198 - val_bce: 0.3809 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3226                                                                                                    \n",
      "Epoch 18/50\n",
      "4863/4863 [==============================] - 1s 124us/step - loss: 0.3992 - bce: 0.3632 - logcosh: 0.0184 - val_loss: 0.4170 - val_bce: 0.3789 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3272                                                                                                    \n",
      "Epoch 19/50\n",
      "4863/4863 [==============================] - 1s 132us/step - loss: 0.3985 - bce: 0.3630 - logcosh: 0.0183 - val_loss: 0.4171 - val_bce: 0.3793 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3137                                                                                                    \n",
      "Epoch 20/50\n",
      "4863/4863 [==============================] - 1s 132us/step - loss: 0.3980 - bce: 0.3628 - logcosh: 0.0183 - val_loss: 0.4167 - val_bce: 0.3792 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3149                                                                                                    \n",
      "Epoch 21/50\n",
      "4863/4863 [==============================] - 1s 124us/step - loss: 0.3975 - bce: 0.3627 - logcosh: 0.0183 - val_loss: 0.4165 - val_bce: 0.3795 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3192                                                                                                    \n",
      "Epoch 22/50\n",
      "4863/4863 [==============================] - 1s 127us/step - loss: 0.3968 - bce: 0.3624 - logcosh: 0.0182 - val_loss: 0.4159 - val_bce: 0.3792 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3122                                                                                                    \n",
      "Epoch 23/50\n",
      "4863/4863 [==============================] - 1s 126us/step - loss: 0.3966 - bce: 0.3625 - logcosh: 0.0183 - val_loss: 0.4196 - val_bce: 0.3826 - val_logcosh: 0.0214\n",
      "  val_spearman-rho: 0.3284                                                                                                    \n",
      "Epoch 24/50\n",
      "4863/4863 [==============================] - 1s 127us/step - loss: 0.3962 - bce: 0.3625 - logcosh: 0.0183 - val_loss: 0.4160 - val_bce: 0.3798 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3203                                                                                                    \n",
      "Epoch 25/50\n",
      "4863/4863 [==============================] - 1s 126us/step - loss: 0.3960 - bce: 0.3626 - logcosh: 0.0183 - val_loss: 0.4176 - val_bce: 0.3816 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3248                                                                                                    \n",
      "Epoch 26/50\n",
      "4863/4863 [==============================] - 1s 143us/step - loss: 0.3953 - bce: 0.3623 - logcosh: 0.0182 - val_loss: 0.4156 - val_bce: 0.3801 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3201                                                                                                    \n",
      "Epoch 27/50\n",
      "4863/4863 [==============================] - 1s 127us/step - loss: 0.3950 - bce: 0.3623 - logcosh: 0.0182 - val_loss: 0.4154 - val_bce: 0.3801 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3301                                                                                                    \n",
      "Epoch 28/50\n",
      "4863/4863 [==============================] - 1s 131us/step - loss: 0.3945 - bce: 0.3621 - logcosh: 0.0182 - val_loss: 0.4160 - val_bce: 0.3809 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3179                                                                                                    \n",
      "Epoch 29/50\n",
      "4863/4863 [==============================] - 1s 130us/step - loss: 0.3939 - bce: 0.3619 - logcosh: 0.0182 - val_loss: 0.4149 - val_bce: 0.3802 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3256                                                                                                    \n",
      "Epoch 30/50\n",
      "4863/4863 [==============================] - 1s 128us/step - loss: 0.3943 - bce: 0.3624 - logcosh: 0.0182 - val_loss: 0.4132 - val_bce: 0.3789 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3214                                                                                                    \n",
      "Epoch 31/50\n",
      "4863/4863 [==============================] - 1s 125us/step - loss: 0.3931 - bce: 0.3616 - logcosh: 0.0181 - val_loss: 0.4141 - val_bce: 0.3801 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3208                                                                                                    \n",
      "Epoch 32/50\n",
      "4863/4863 [==============================] - 1s 127us/step - loss: 0.3931 - bce: 0.3619 - logcosh: 0.0182 - val_loss: 0.4140 - val_bce: 0.3801 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3223                                                                                                    \n",
      "Epoch 33/50\n",
      "4863/4863 [==============================] - 1s 129us/step - loss: 0.3924 - bce: 0.3615 - logcosh: 0.0181 - val_loss: 0.4140 - val_bce: 0.3803 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3237                                                                                                    \n",
      "Epoch 34/50\n",
      "4863/4863 [==============================] - 1s 128us/step - loss: 0.3923 - bce: 0.3616 - logcosh: 0.0181 - val_loss: 0.4132 - val_bce: 0.3799 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3286                                                                                                    \n",
      "Epoch 35/50\n",
      "4863/4863 [==============================] - 1s 129us/step - loss: 0.3920 - bce: 0.3615 - logcosh: 0.0181 - val_loss: 0.4133 - val_bce: 0.3802 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3264                                                                                                    \n",
      "Epoch 36/50\n",
      "4863/4863 [==============================] - 1s 130us/step - loss: 0.3918 - bce: 0.3615 - logcosh: 0.0181 - val_loss: 0.4129 - val_bce: 0.3800 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3233                                                                                                    \n",
      "Epoch 37/50\n",
      "4863/4863 [==============================] - 1s 127us/step - loss: 0.3914 - bce: 0.3614 - logcosh: 0.0181 - val_loss: 0.4119 - val_bce: 0.3793 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.322                                                                                                    \n",
      "Epoch 38/50\n",
      "4863/4863 [==============================] - 1s 136us/step - loss: 0.3913 - bce: 0.3615 - logcosh: 0.0181 - val_loss: 0.4114 - val_bce: 0.3791 - val_logcosh: 0.0207\n",
      "  val_spearman-rho: 0.3274                                                                                                    \n",
      "Epoch 39/50\n",
      "4863/4863 [==============================] - 1s 129us/step - loss: 0.3910 - bce: 0.3614 - logcosh: 0.0181 - val_loss: 0.4119 - val_bce: 0.3797 - val_logcosh: 0.0208\n",
      "  val_spearman-rho: 0.3186                                                                                                    \n",
      "Epoch 40/50\n",
      "4863/4863 [==============================] - 1s 133us/step - loss: 0.3903 - bce: 0.3610 - logcosh: 0.0180 - val_loss: 0.4161 - val_bce: 0.3833 - val_logcosh: 0.0216\n",
      "  val_spearman-rho: 0.3214                                                                                                    \n",
      "Epoch 41/50\n",
      "4863/4863 [==============================] - 1s 130us/step - loss: 0.3903 - bce: 0.3612 - logcosh: 0.0180 - val_loss: 0.4126 - val_bce: 0.3806 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3237                                                                                                    \n",
      "Epoch 42/50\n",
      "4863/4863 [==============================] - 1s 128us/step - loss: 0.3901 - bce: 0.3611 - logcosh: 0.0180 - val_loss: 0.4117 - val_bce: 0.3799 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3205                                                                                                    \n",
      "Epoch 43/50\n",
      "4863/4863 [==============================] - 1s 125us/step - loss: 0.3898 - bce: 0.3610 - logcosh: 0.0180 - val_loss: 0.4113 - val_bce: 0.3798 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.3206                                                                                                    \n",
      "Epoch 44/50\n",
      "4863/4863 [==============================] - 1s 129us/step - loss: 0.3898 - bce: 0.3611 - logcosh: 0.0181 - val_loss: 0.4141 - val_bce: 0.3825 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.332                                                                                                    \n",
      "Epoch 45/50\n",
      "4863/4863 [==============================] - 1s 127us/step - loss: 0.3896 - bce: 0.3612 - logcosh: 0.0181 - val_loss: 0.4131 - val_bce: 0.3817 - val_logcosh: 0.0211\n",
      "  val_spearman-rho: 0.3228                                                                                                    \n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 46/50\n",
      "4863/4863 [==============================] - 1s 127us/step - loss: 0.3867 - bce: 0.3588 - logcosh: 0.0176 - val_loss: 0.4089 - val_bce: 0.3781 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3146                                                                                                    \n",
      "Epoch 47/50\n",
      "4863/4863 [==============================] - 1s 127us/step - loss: 0.3865 - bce: 0.3586 - logcosh: 0.0176 - val_loss: 0.4089 - val_bce: 0.3781 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3272                                                                                                    \n",
      "Epoch 48/50\n",
      "4863/4863 [==============================] - 1s 130us/step - loss: 0.3864 - bce: 0.3585 - logcosh: 0.0176 - val_loss: 0.4089 - val_bce: 0.3781 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.318                                                                                                    \n",
      "Epoch 49/50\n",
      "4863/4863 [==============================] - 1s 129us/step - loss: 0.3864 - bce: 0.3585 - logcosh: 0.0176 - val_loss: 0.4088 - val_bce: 0.3780 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3148                                                                                                    \n",
      "Epoch 50/50\n",
      "4863/4863 [==============================] - 1s 125us/step - loss: 0.3863 - bce: 0.3585 - logcosh: 0.0176 - val_loss: 0.4089 - val_bce: 0.3781 - val_logcosh: 0.0206\n",
      "  val_spearman-rho: 0.3235                                                                                                    \n",
      "  val_spearman-rho: 0.3262                                                                                                    \n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 4576)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 512)               2343424   \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 30)                7710      \n",
      "=================================================================\n",
      "Total params: 2,482,462\n",
      "Trainable params: 2,482,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4864 samples, validate on 1215 samples\n",
      "Epoch 1/100\n",
      "4864/4864 [==============================] - 1s 163us/step - loss: 0.4613 - bce: 0.4326 - logcosh: 0.0287 - val_loss: 0.4180 - val_bce: 0.3946 - val_logcosh: 0.0234\n",
      "  val_spearman-rho: 0.2525                                                                                                    \n",
      "  reload best: 0.2525\n",
      "Epoch 2/100\n",
      "4864/4864 [==============================] - 0s 100us/step - loss: 0.4117 - bce: 0.3891 - logcosh: 0.0227 - val_loss: 0.4139 - val_bce: 0.3911 - val_logcosh: 0.0228\n",
      "  val_spearman-rho: 0.2818                                                                                                    \n",
      "  reload best: 0.2818\n",
      "Epoch 3/100\n",
      "4864/4864 [==============================] - 1s 104us/step - loss: 0.4014 - bce: 0.3803 - logcosh: 0.0212 - val_loss: 0.4102 - val_bce: 0.3879 - val_logcosh: 0.0223\n",
      "  val_spearman-rho: 0.2918                                                                                                    \n",
      "  reload best: 0.2918\n",
      "Epoch 4/100\n",
      "4864/4864 [==============================] - 0s 97us/step - loss: 0.3972 - bce: 0.3765 - logcosh: 0.0206 - val_loss: 0.4007 - val_bce: 0.3798 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3009                                                                                                    \n",
      "  reload best: 0.3009\n",
      "Epoch 5/100\n",
      "4864/4864 [==============================] - 0s 101us/step - loss: 0.3901 - bce: 0.3705 - logcosh: 0.0196 - val_loss: 0.4012 - val_bce: 0.3803 - val_logcosh: 0.0210\n",
      "  val_spearman-rho: 0.3081                                                                                                    \n",
      "  reload best: 0.3081\n",
      "Epoch 6/100\n",
      "4864/4864 [==============================] - 0s 97us/step - loss: 0.3844 - bce: 0.3656 - logcosh: 0.0188 - val_loss: 0.3961 - val_bce: 0.3758 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3157                                                                                                    \n",
      "  reload best: 0.3157\n",
      "Epoch 7/100\n",
      "4864/4864 [==============================] - 0s 102us/step - loss: 0.3806 - bce: 0.3623 - logcosh: 0.0183 - val_loss: 0.3956 - val_bce: 0.3753 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3062                                                                                                    \n",
      "  reload best: 0.3157\n",
      "Epoch 8/100\n",
      "4864/4864 [==============================] - 0s 100us/step - loss: 0.3805 - bce: 0.3622 - logcosh: 0.0183 - val_loss: 0.3946 - val_bce: 0.3745 - val_logcosh: 0.0201\n",
      "  val_spearman-rho: 0.311                                                                                                    \n",
      "  reload best: 0.3157\n",
      "Epoch 9/100\n",
      "4864/4864 [==============================] - 0s 98us/step - loss: 0.3812 - bce: 0.3628 - logcosh: 0.0184 - val_loss: 0.3955 - val_bce: 0.3752 - val_logcosh: 0.0202\n",
      "  val_spearman-rho: 0.3101                                                                                                    \n",
      "  reload best: 0.3157\n",
      "Epoch 10/100\n",
      "4864/4864 [==============================] - 0s 100us/step - loss: 0.3825 - bce: 0.3639 - logcosh: 0.0186 - val_loss: 0.3966 - val_bce: 0.3763 - val_logcosh: 0.0203\n",
      "  val_spearman-rho: 0.3093                                                                                                    \n",
      "  reload best: 0.3157\n",
      "Epoch 11/100\n",
      "4864/4864 [==============================] - 1s 105us/step - loss: 0.3815 - bce: 0.3631 - logcosh: 0.0184 - val_loss: 0.3941 - val_bce: 0.3741 - val_logcosh: 0.0200\n",
      "  val_spearman-rho: 0.3118                                                                                                    \n",
      "  reload best: 0.3157\n",
      "Epoch 12/100\n",
      "4864/4864 [==============================] - 0s 99us/step - loss: 0.3817 - bce: 0.3633 - logcosh: 0.0184 - val_loss: 0.4003 - val_bce: 0.3794 - val_logcosh: 0.0209\n",
      "  val_spearman-rho: 0.313                                                                                                    \n",
      "  reload best: 0.3157\n",
      "Epoch 13/100\n",
      "4288/4864 [=========================>....] - ETA: 0s - loss: 0.3819 - bce: 0.3633 - logcosh: 0.0185"
     ]
    }
   ],
   "source": [
    "all_predictions = []\n",
    "while len(all_predictions) < 20:\n",
    "    run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is slow...\n",
    "# from sklearn.linear_model import MultiTaskElasticNet\n",
    "# \n",
    "# kf = KFold(n_splits=5, random_state=2019, shuffle=True)\n",
    "# for ind, (tr, val) in enumerate(kf.split(X_train)):\n",
    "#     X_tr = X_train[tr]\n",
    "#     y_tr = y_train[tr]\n",
    "#     X_vl = X_train[val]\n",
    "#     y_vl = y_train[val]\n",
    "    \n",
    "#     model = MultiTaskElasticNet(alpha=0.001, random_state=42, l1_ratio=0.5)\n",
    "#     model.fit(X_tr, y_tr)\n",
    "#     all_predictions.append(model.predict(X_test))\n",
    "    \n",
    "# model = MultiTaskElasticNet(alpha=0.001, random_state=42, l1_ratio=0.5)\n",
    "# model.fit(X_train, y_train)\n",
    "# all_predictions.append(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2323022"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catboost didn't work well\n",
    "# # clear session and clear cuda memory for catboost\n",
    "# K.clear_session()\n",
    "# gc.collect()\n",
    "\n",
    "# from numba import cuda;\n",
    "# cuda.select_device(0);\n",
    "# cuda.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.multiclass import OneVsRestClassifier\n",
    "# from sklearn.multioutput import MultiOutputRegressor\n",
    "# # all_predictions = []\n",
    "# for ind, (tr, val) in enumerate(kf.split(X_train)):\n",
    "#     X_tr = X_train[tr]\n",
    "#     y_tr = y_train[tr]\n",
    "#     X_vl = X_train[val]\n",
    "#     y_vl = y_train[val]\n",
    "\n",
    "#     print(X_tr.shape)\n",
    "#     print(y_tr.shape)\n",
    "\n",
    "\n",
    "    \n",
    "#     gs1 = MultiOutputRegressor(\n",
    "#         cb.CatBoostRegressor(iterations=400,\n",
    "#                             learning_rate=0.7,\n",
    "#                             depth=9,\n",
    "#                             verbose = 20,\n",
    "#                             task_type = 'GPU',\n",
    "#                             loss_function = 'MAE')\n",
    "        \n",
    "#     )\n",
    "#     gs1.fit(X_tr, y_tr);    \n",
    "\n",
    "#     all_predictions.append(gs1.predict(X_test))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.array([np.array([rankdata(c) for c in p.T]).T for p in all_predictions]).mean(axis=0)\n",
    "max_val = test_preds.max() + 1\n",
    "test_preds = test_preds/max_val + 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.803026</td>\n",
       "      <td>0.588369</td>\n",
       "      <td>0.891715</td>\n",
       "      <td>0.481087</td>\n",
       "      <td>0.341901</td>\n",
       "      <td>0.275636</td>\n",
       "      <td>0.860633</td>\n",
       "      <td>0.878316</td>\n",
       "      <td>0.840762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.804485</td>\n",
       "      <td>0.339349</td>\n",
       "      <td>0.200711</td>\n",
       "      <td>0.456750</td>\n",
       "      <td>0.384742</td>\n",
       "      <td>0.264516</td>\n",
       "      <td>0.108285</td>\n",
       "      <td>0.170176</td>\n",
       "      <td>0.852703</td>\n",
       "      <td>0.812050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.296874</td>\n",
       "      <td>0.310728</td>\n",
       "      <td>0.281287</td>\n",
       "      <td>0.670221</td>\n",
       "      <td>0.233434</td>\n",
       "      <td>0.658828</td>\n",
       "      <td>0.358582</td>\n",
       "      <td>0.421748</td>\n",
       "      <td>0.101267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029806</td>\n",
       "      <td>0.451919</td>\n",
       "      <td>0.364142</td>\n",
       "      <td>0.506335</td>\n",
       "      <td>0.464406</td>\n",
       "      <td>0.404339</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.317200</td>\n",
       "      <td>0.039650</td>\n",
       "      <td>0.178562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.601039</td>\n",
       "      <td>0.657369</td>\n",
       "      <td>0.534044</td>\n",
       "      <td>0.712515</td>\n",
       "      <td>0.899827</td>\n",
       "      <td>0.883511</td>\n",
       "      <td>0.722815</td>\n",
       "      <td>0.625832</td>\n",
       "      <td>0.473977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734026</td>\n",
       "      <td>0.441801</td>\n",
       "      <td>0.247926</td>\n",
       "      <td>0.552548</td>\n",
       "      <td>0.378088</td>\n",
       "      <td>0.250296</td>\n",
       "      <td>0.157415</td>\n",
       "      <td>0.170632</td>\n",
       "      <td>0.821438</td>\n",
       "      <td>0.571780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.486100</td>\n",
       "      <td>0.089509</td>\n",
       "      <td>0.145201</td>\n",
       "      <td>0.387385</td>\n",
       "      <td>0.492480</td>\n",
       "      <td>0.704038</td>\n",
       "      <td>0.375991</td>\n",
       "      <td>0.437335</td>\n",
       "      <td>0.699663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300884</td>\n",
       "      <td>0.783338</td>\n",
       "      <td>0.719624</td>\n",
       "      <td>0.735667</td>\n",
       "      <td>0.788442</td>\n",
       "      <td>0.781880</td>\n",
       "      <td>0.812688</td>\n",
       "      <td>0.798013</td>\n",
       "      <td>0.587276</td>\n",
       "      <td>0.406526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.882600</td>\n",
       "      <td>0.499408</td>\n",
       "      <td>0.487604</td>\n",
       "      <td>0.945037</td>\n",
       "      <td>0.730836</td>\n",
       "      <td>0.897457</td>\n",
       "      <td>0.886975</td>\n",
       "      <td>0.862273</td>\n",
       "      <td>0.731747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424300</td>\n",
       "      <td>0.461945</td>\n",
       "      <td>0.660924</td>\n",
       "      <td>0.747425</td>\n",
       "      <td>0.509069</td>\n",
       "      <td>0.439978</td>\n",
       "      <td>0.265700</td>\n",
       "      <td>0.573694</td>\n",
       "      <td>0.642877</td>\n",
       "      <td>0.325768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>245</td>\n",
       "      <td>0.869201</td>\n",
       "      <td>0.954881</td>\n",
       "      <td>0.693829</td>\n",
       "      <td>0.790994</td>\n",
       "      <td>0.883511</td>\n",
       "      <td>0.703947</td>\n",
       "      <td>0.695561</td>\n",
       "      <td>0.524747</td>\n",
       "      <td>0.288397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861726</td>\n",
       "      <td>0.641874</td>\n",
       "      <td>0.397594</td>\n",
       "      <td>0.569684</td>\n",
       "      <td>0.507611</td>\n",
       "      <td>0.804120</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.132167</td>\n",
       "      <td>0.703673</td>\n",
       "      <td>0.521466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>257</td>\n",
       "      <td>0.316835</td>\n",
       "      <td>0.186401</td>\n",
       "      <td>0.256768</td>\n",
       "      <td>0.245374</td>\n",
       "      <td>0.314921</td>\n",
       "      <td>0.452192</td>\n",
       "      <td>0.197430</td>\n",
       "      <td>0.248291</td>\n",
       "      <td>0.724729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248291</td>\n",
       "      <td>0.837936</td>\n",
       "      <td>0.764288</td>\n",
       "      <td>0.660013</td>\n",
       "      <td>0.776957</td>\n",
       "      <td>0.761918</td>\n",
       "      <td>0.870386</td>\n",
       "      <td>0.978944</td>\n",
       "      <td>0.333607</td>\n",
       "      <td>0.201896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>267</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.791541</td>\n",
       "      <td>0.968280</td>\n",
       "      <td>0.403063</td>\n",
       "      <td>0.357123</td>\n",
       "      <td>0.126242</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.980767</td>\n",
       "      <td>0.530489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.878316</td>\n",
       "      <td>0.203992</td>\n",
       "      <td>0.697111</td>\n",
       "      <td>0.355847</td>\n",
       "      <td>0.325859</td>\n",
       "      <td>0.294504</td>\n",
       "      <td>0.018412</td>\n",
       "      <td>0.019871</td>\n",
       "      <td>0.945948</td>\n",
       "      <td>0.872573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>284</td>\n",
       "      <td>0.103272</td>\n",
       "      <td>0.056330</td>\n",
       "      <td>0.466047</td>\n",
       "      <td>0.223134</td>\n",
       "      <td>0.394221</td>\n",
       "      <td>0.321940</td>\n",
       "      <td>0.124328</td>\n",
       "      <td>0.314921</td>\n",
       "      <td>0.573785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065354</td>\n",
       "      <td>0.697840</td>\n",
       "      <td>0.497585</td>\n",
       "      <td>0.543524</td>\n",
       "      <td>0.723726</td>\n",
       "      <td>0.625741</td>\n",
       "      <td>0.523562</td>\n",
       "      <td>0.434691</td>\n",
       "      <td>0.735029</td>\n",
       "      <td>0.442439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>292</td>\n",
       "      <td>0.720627</td>\n",
       "      <td>0.595479</td>\n",
       "      <td>0.313645</td>\n",
       "      <td>0.762282</td>\n",
       "      <td>0.798833</td>\n",
       "      <td>0.929450</td>\n",
       "      <td>0.704038</td>\n",
       "      <td>0.735211</td>\n",
       "      <td>0.530125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367332</td>\n",
       "      <td>0.468599</td>\n",
       "      <td>0.365691</td>\n",
       "      <td>0.601495</td>\n",
       "      <td>0.512260</td>\n",
       "      <td>0.412907</td>\n",
       "      <td>0.362137</td>\n",
       "      <td>0.195880</td>\n",
       "      <td>0.722359</td>\n",
       "      <td>0.490384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>296</td>\n",
       "      <td>0.429952</td>\n",
       "      <td>0.365053</td>\n",
       "      <td>0.200164</td>\n",
       "      <td>0.433871</td>\n",
       "      <td>0.304166</td>\n",
       "      <td>0.595114</td>\n",
       "      <td>0.222678</td>\n",
       "      <td>0.448182</td>\n",
       "      <td>0.362137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269073</td>\n",
       "      <td>0.743141</td>\n",
       "      <td>0.788533</td>\n",
       "      <td>0.760368</td>\n",
       "      <td>0.718166</td>\n",
       "      <td>0.775864</td>\n",
       "      <td>0.909124</td>\n",
       "      <td>0.706499</td>\n",
       "      <td>0.308450</td>\n",
       "      <td>0.352384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>312</td>\n",
       "      <td>0.658372</td>\n",
       "      <td>0.928265</td>\n",
       "      <td>0.488014</td>\n",
       "      <td>0.908577</td>\n",
       "      <td>0.883511</td>\n",
       "      <td>0.667396</td>\n",
       "      <td>0.444080</td>\n",
       "      <td>0.341263</td>\n",
       "      <td>0.663750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905843</td>\n",
       "      <td>0.815331</td>\n",
       "      <td>0.638638</td>\n",
       "      <td>0.753076</td>\n",
       "      <td>0.610154</td>\n",
       "      <td>0.794458</td>\n",
       "      <td>0.228603</td>\n",
       "      <td>0.155319</td>\n",
       "      <td>0.874943</td>\n",
       "      <td>0.583721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>322</td>\n",
       "      <td>0.333789</td>\n",
       "      <td>0.433871</td>\n",
       "      <td>0.290767</td>\n",
       "      <td>0.208732</td>\n",
       "      <td>0.442257</td>\n",
       "      <td>0.597758</td>\n",
       "      <td>0.382098</td>\n",
       "      <td>0.462765</td>\n",
       "      <td>0.346185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518275</td>\n",
       "      <td>0.786255</td>\n",
       "      <td>0.563668</td>\n",
       "      <td>0.703309</td>\n",
       "      <td>0.902561</td>\n",
       "      <td>0.752074</td>\n",
       "      <td>0.894540</td>\n",
       "      <td>0.656914</td>\n",
       "      <td>0.290675</td>\n",
       "      <td>0.624282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>327</td>\n",
       "      <td>0.702215</td>\n",
       "      <td>0.541154</td>\n",
       "      <td>0.202990</td>\n",
       "      <td>0.966639</td>\n",
       "      <td>0.907848</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.694011</td>\n",
       "      <td>0.545803</td>\n",
       "      <td>0.451463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260778</td>\n",
       "      <td>0.879865</td>\n",
       "      <td>0.799562</td>\n",
       "      <td>0.847142</td>\n",
       "      <td>0.795005</td>\n",
       "      <td>0.879865</td>\n",
       "      <td>0.477076</td>\n",
       "      <td>0.366876</td>\n",
       "      <td>0.417008</td>\n",
       "      <td>0.512715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>334</td>\n",
       "      <td>0.492024</td>\n",
       "      <td>0.665937</td>\n",
       "      <td>0.221858</td>\n",
       "      <td>0.889345</td>\n",
       "      <td>0.713335</td>\n",
       "      <td>0.933917</td>\n",
       "      <td>0.195242</td>\n",
       "      <td>0.216571</td>\n",
       "      <td>0.674688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625011</td>\n",
       "      <td>0.775681</td>\n",
       "      <td>0.732477</td>\n",
       "      <td>0.568863</td>\n",
       "      <td>0.562392</td>\n",
       "      <td>0.833926</td>\n",
       "      <td>0.592198</td>\n",
       "      <td>0.630389</td>\n",
       "      <td>0.234619</td>\n",
       "      <td>0.545803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>340</td>\n",
       "      <td>0.153040</td>\n",
       "      <td>0.159147</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.384195</td>\n",
       "      <td>0.562756</td>\n",
       "      <td>0.306627</td>\n",
       "      <td>0.132987</td>\n",
       "      <td>0.227327</td>\n",
       "      <td>0.349193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336341</td>\n",
       "      <td>0.512351</td>\n",
       "      <td>0.451554</td>\n",
       "      <td>0.278917</td>\n",
       "      <td>0.506061</td>\n",
       "      <td>0.557287</td>\n",
       "      <td>0.639504</td>\n",
       "      <td>0.857807</td>\n",
       "      <td>0.376720</td>\n",
       "      <td>0.165254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>357</td>\n",
       "      <td>0.080303</td>\n",
       "      <td>0.294777</td>\n",
       "      <td>0.420381</td>\n",
       "      <td>0.226780</td>\n",
       "      <td>0.876584</td>\n",
       "      <td>0.567314</td>\n",
       "      <td>0.271443</td>\n",
       "      <td>0.140188</td>\n",
       "      <td>0.285936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224045</td>\n",
       "      <td>0.229696</td>\n",
       "      <td>0.350925</td>\n",
       "      <td>0.162793</td>\n",
       "      <td>0.325221</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>0.156595</td>\n",
       "      <td>0.449275</td>\n",
       "      <td>0.891076</td>\n",
       "      <td>0.660560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>374</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.398961</td>\n",
       "      <td>0.055419</td>\n",
       "      <td>0.703126</td>\n",
       "      <td>0.707593</td>\n",
       "      <td>0.933461</td>\n",
       "      <td>0.354845</td>\n",
       "      <td>0.454562</td>\n",
       "      <td>0.708504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308905</td>\n",
       "      <td>0.923799</td>\n",
       "      <td>0.912952</td>\n",
       "      <td>0.902835</td>\n",
       "      <td>0.860541</td>\n",
       "      <td>0.859448</td>\n",
       "      <td>0.748063</td>\n",
       "      <td>0.782882</td>\n",
       "      <td>0.355118</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>375</td>\n",
       "      <td>0.963631</td>\n",
       "      <td>0.951509</td>\n",
       "      <td>0.785890</td>\n",
       "      <td>0.314101</td>\n",
       "      <td>0.894449</td>\n",
       "      <td>0.214657</td>\n",
       "      <td>0.931456</td>\n",
       "      <td>0.972837</td>\n",
       "      <td>0.743688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947589</td>\n",
       "      <td>0.367332</td>\n",
       "      <td>0.525932</td>\n",
       "      <td>0.495944</td>\n",
       "      <td>0.344362</td>\n",
       "      <td>0.306627</td>\n",
       "      <td>0.095160</td>\n",
       "      <td>0.108832</td>\n",
       "      <td>0.636952</td>\n",
       "      <td>0.868836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>387</td>\n",
       "      <td>0.985781</td>\n",
       "      <td>0.884514</td>\n",
       "      <td>0.971379</td>\n",
       "      <td>0.654453</td>\n",
       "      <td>0.018594</td>\n",
       "      <td>0.042658</td>\n",
       "      <td>0.985872</td>\n",
       "      <td>0.987786</td>\n",
       "      <td>0.875490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977030</td>\n",
       "      <td>0.548993</td>\n",
       "      <td>0.482089</td>\n",
       "      <td>0.691824</td>\n",
       "      <td>0.407438</td>\n",
       "      <td>0.520828</td>\n",
       "      <td>0.097803</td>\n",
       "      <td>0.152949</td>\n",
       "      <td>0.759457</td>\n",
       "      <td>0.831009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0      39                             0.803026                0.588369   \n",
       "1      46                             0.296874                0.310728   \n",
       "2      70                             0.601039                0.657369   \n",
       "3     132                             0.486100                0.089509   \n",
       "4     200                             0.882600                0.499408   \n",
       "5     245                             0.869201                0.954881   \n",
       "6     257                             0.316835                0.186401   \n",
       "7     267                             0.919606                0.791541   \n",
       "8     284                             0.103272                0.056330   \n",
       "9     292                             0.720627                0.595479   \n",
       "10    296                             0.429952                0.365053   \n",
       "11    312                             0.658372                0.928265   \n",
       "12    322                             0.333789                0.433871   \n",
       "13    327                             0.702215                0.541154   \n",
       "14    334                             0.492024                0.665937   \n",
       "15    340                             0.153040                0.159147   \n",
       "16    357                             0.080303                0.294777   \n",
       "17    374                             0.444444                0.398961   \n",
       "18    375                             0.963631                0.951509   \n",
       "19    387                             0.985781                0.884514   \n",
       "\n",
       "    question_conversational  question_expect_short_answer  \\\n",
       "0                  0.891715                      0.481087   \n",
       "1                  0.281287                      0.670221   \n",
       "2                  0.534044                      0.712515   \n",
       "3                  0.145201                      0.387385   \n",
       "4                  0.487604                      0.945037   \n",
       "5                  0.693829                      0.790994   \n",
       "6                  0.256768                      0.245374   \n",
       "7                  0.968280                      0.403063   \n",
       "8                  0.466047                      0.223134   \n",
       "9                  0.313645                      0.762282   \n",
       "10                 0.200164                      0.433871   \n",
       "11                 0.488014                      0.908577   \n",
       "12                 0.290767                      0.208732   \n",
       "13                 0.202990                      0.966639   \n",
       "14                 0.221858                      0.889345   \n",
       "15                 0.489290                      0.384195   \n",
       "16                 0.420381                      0.226780   \n",
       "17                 0.055419                      0.703126   \n",
       "18                 0.785890                      0.314101   \n",
       "19                 0.971379                      0.654453   \n",
       "\n",
       "    question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0                0.341901                               0.275636   \n",
       "1                0.233434                               0.658828   \n",
       "2                0.899827                               0.883511   \n",
       "3                0.492480                               0.704038   \n",
       "4                0.730836                               0.897457   \n",
       "5                0.883511                               0.703947   \n",
       "6                0.314921                               0.452192   \n",
       "7                0.357123                               0.126242   \n",
       "8                0.394221                               0.321940   \n",
       "9                0.798833                               0.929450   \n",
       "10               0.304166                               0.595114   \n",
       "11               0.883511                               0.667396   \n",
       "12               0.442257                               0.597758   \n",
       "13               0.907848                               0.931911   \n",
       "14               0.713335                               0.933917   \n",
       "15               0.562756                               0.306627   \n",
       "16               0.876584                               0.567314   \n",
       "17               0.707593                               0.933461   \n",
       "18               0.894449                               0.214657   \n",
       "19               0.018594                               0.042658   \n",
       "\n",
       "    question_interestingness_others  question_interestingness_self  \\\n",
       "0                          0.860633                       0.878316   \n",
       "1                          0.358582                       0.421748   \n",
       "2                          0.722815                       0.625832   \n",
       "3                          0.375991                       0.437335   \n",
       "4                          0.886975                       0.862273   \n",
       "5                          0.695561                       0.524747   \n",
       "6                          0.197430                       0.248291   \n",
       "7                          0.972199                       0.980767   \n",
       "8                          0.124328                       0.314921   \n",
       "9                          0.704038                       0.735211   \n",
       "10                         0.222678                       0.448182   \n",
       "11                         0.444080                       0.341263   \n",
       "12                         0.382098                       0.462765   \n",
       "13                         0.694011                       0.545803   \n",
       "14                         0.195242                       0.216571   \n",
       "15                         0.132987                       0.227327   \n",
       "16                         0.271443                       0.140188   \n",
       "17                         0.354845                       0.454562   \n",
       "18                         0.931456                       0.972837   \n",
       "19                         0.985872                       0.987786   \n",
       "\n",
       "    question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0                0.840762  ...               0.804485        0.339349   \n",
       "1                0.101267  ...               0.029806        0.451919   \n",
       "2                0.473977  ...               0.734026        0.441801   \n",
       "3                0.699663  ...               0.300884        0.783338   \n",
       "4                0.731747  ...               0.424300        0.461945   \n",
       "5                0.288397  ...               0.861726        0.641874   \n",
       "6                0.724729  ...               0.248291        0.837936   \n",
       "7                0.530489  ...               0.878316        0.203992   \n",
       "8                0.573785  ...               0.065354        0.697840   \n",
       "9                0.530125  ...               0.367332        0.468599   \n",
       "10               0.362137  ...               0.269073        0.743141   \n",
       "11               0.663750  ...               0.905843        0.815331   \n",
       "12               0.346185  ...               0.518275        0.786255   \n",
       "13               0.451463  ...               0.260778        0.879865   \n",
       "14               0.674688  ...               0.625011        0.775681   \n",
       "15               0.349193  ...               0.336341        0.512351   \n",
       "16               0.285936  ...               0.224045        0.229696   \n",
       "17               0.708504  ...               0.308905        0.923799   \n",
       "18               0.743688  ...               0.947589        0.367332   \n",
       "19               0.875490  ...               0.977030        0.548993   \n",
       "\n",
       "    answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                      0.200711          0.456750          0.384742   \n",
       "1                      0.364142          0.506335          0.464406   \n",
       "2                      0.247926          0.552548          0.378088   \n",
       "3                      0.719624          0.735667          0.788442   \n",
       "4                      0.660924          0.747425          0.509069   \n",
       "5                      0.397594          0.569684          0.507611   \n",
       "6                      0.764288          0.660013          0.776957   \n",
       "7                      0.697111          0.355847          0.325859   \n",
       "8                      0.497585          0.543524          0.723726   \n",
       "9                      0.365691          0.601495          0.512260   \n",
       "10                     0.788533          0.760368          0.718166   \n",
       "11                     0.638638          0.753076          0.610154   \n",
       "12                     0.563668          0.703309          0.902561   \n",
       "13                     0.799562          0.847142          0.795005   \n",
       "14                     0.732477          0.568863          0.562392   \n",
       "15                     0.451554          0.278917          0.506061   \n",
       "16                     0.350925          0.162793          0.325221   \n",
       "17                     0.912952          0.902835          0.860541   \n",
       "18                     0.525932          0.495944          0.344362   \n",
       "19                     0.482089          0.691824          0.407438   \n",
       "\n",
       "    answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0              0.264516                  0.108285               0.170176   \n",
       "1              0.404339                  0.930271               0.317200   \n",
       "2              0.250296                  0.157415               0.170632   \n",
       "3              0.781880                  0.812688               0.798013   \n",
       "4              0.439978                  0.265700               0.573694   \n",
       "5              0.804120                  0.159420               0.132167   \n",
       "6              0.761918                  0.870386               0.978944   \n",
       "7              0.294504                  0.018412               0.019871   \n",
       "8              0.625741                  0.523562               0.434691   \n",
       "9              0.412907                  0.362137               0.195880   \n",
       "10             0.775864                  0.909124               0.706499   \n",
       "11             0.794458                  0.228603               0.155319   \n",
       "12             0.752074                  0.894540               0.656914   \n",
       "13             0.879865                  0.477076               0.366876   \n",
       "14             0.833926                  0.592198               0.630389   \n",
       "15             0.557287                  0.639504               0.857807   \n",
       "16             0.224410                  0.156595               0.449275   \n",
       "17             0.859448                  0.748063               0.782882   \n",
       "18             0.306627                  0.095160               0.108832   \n",
       "19             0.520828                  0.097803               0.152949   \n",
       "\n",
       "    answer_type_reason_explanation  answer_well_written  \n",
       "0                         0.852703             0.812050  \n",
       "1                         0.039650             0.178562  \n",
       "2                         0.821438             0.571780  \n",
       "3                         0.587276             0.406526  \n",
       "4                         0.642877             0.325768  \n",
       "5                         0.703673             0.521466  \n",
       "6                         0.333607             0.201896  \n",
       "7                         0.945948             0.872573  \n",
       "8                         0.735029             0.442439  \n",
       "9                         0.722359             0.490384  \n",
       "10                        0.308450             0.352384  \n",
       "11                        0.874943             0.583721  \n",
       "12                        0.290675             0.624282  \n",
       "13                        0.417008             0.512715  \n",
       "14                        0.234619             0.545803  \n",
       "15                        0.376720             0.165254  \n",
       "16                        0.891076             0.660560  \n",
       "17                        0.355118             0.777778  \n",
       "18                        0.636952             0.868836  \n",
       "19                        0.759457             0.831009  \n",
       "\n",
       "[20 rows x 31 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(INPUT_PATH+'google-quest-challenge/sample_submission.csv')\n",
    "submission[targets] = test_preds\n",
    "submission.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0f6154ff1ca84a50849068a584829561": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b6a8af2739ec425784d06302587f2399",
        "IPY_MODEL_7779f529edf141c7a8093aa89715a228"
       ],
       "layout": "IPY_MODEL_4b8d9b81dff94abe8876b618685baa3a"
      }
     },
     "122b703ebac24dfb900bed603005d957": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_47b4addd765d4e7bbf60adc3a0f82ba7",
        "IPY_MODEL_8cc182ca0e1f4b28987f3e818dad5e11"
       ],
       "layout": "IPY_MODEL_523b114da8c14e2f9a43259c5c0269e7"
      }
     },
     "12abba34e9e34e1a8fee76f640173f17": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1be88be5b7a4468698df2e724c96c00e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ea9d856f13143708d8973616013613a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_80aee781487944aaa2c3fda4a2a0194f",
       "placeholder": "​",
       "style": "IPY_MODEL_344807d70e8c4af7ba5375b698a75b02",
       "value": " 8/? [00:06&lt;00:00,  1.24it/s]"
      }
     },
     "225aff503a184406b795d8e7d0de15e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2ce87d57138c4b8da6a77aec0cfa20c8",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2d3cd78e640c43beb277fd06850401c3",
       "value": 1
      }
     },
     "2372c0410f73493581944718477c6ffa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ce87d57138c4b8da6a77aec0cfa20c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2d3cd78e640c43beb277fd06850401c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "33077a25096e4889a4b9995aa24923b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "344807d70e8c4af7ba5375b698a75b02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "37aea566503a4c3d80566f76ba78efe0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1be88be5b7a4468698df2e724c96c00e",
       "placeholder": "​",
       "style": "IPY_MODEL_8dc9ed3f538841f39788104e46d05883",
       "value": " 8/? [00:04&lt;00:00,  1.66it/s]"
      }
     },
     "39ce04d21ba847a9a09cdae75898d71f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_985151d13fa34612bdcec4b004e0309c",
        "IPY_MODEL_6f18c946040f4330a7d81e6fdbb7a7c5"
       ],
       "layout": "IPY_MODEL_6aaadb2d1e5c4ee5880a9a5ab65c12f9"
      }
     },
     "47b4addd765d4e7bbf60adc3a0f82ba7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a243d6cc4de74f2a8a624db048eed14b",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_501832d3aa8b4ac8a44ef6fc73e411d7",
       "value": 1
      }
     },
     "4b8d9b81dff94abe8876b618685baa3a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "501832d3aa8b4ac8a44ef6fc73e411d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "523b114da8c14e2f9a43259c5c0269e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "54794e5145b343ee8f2c8cffac1c2352": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7edefa114b2d4a549174704fb37b6c48",
        "IPY_MODEL_1ea9d856f13143708d8973616013613a"
       ],
       "layout": "IPY_MODEL_9da48c88afbc46e6a13b6daec27b368b"
      }
     },
     "61f67ac644a84bfd880d3fc4bbfcaaf4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6aaadb2d1e5c4ee5880a9a5ab65c12f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6f18c946040f4330a7d81e6fdbb7a7c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_33077a25096e4889a4b9995aa24923b9",
       "placeholder": "​",
       "style": "IPY_MODEL_e81aacac360c47e8bace534fd6508044",
       "value": " 95/? [01:21&lt;00:00,  1.16it/s]"
      }
     },
     "70e19001e8e3479aaa9f6e4ac527df12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "70ea1cdab66a43eeb7bfeb7b7e82ca85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "776db6c535da4943804f9fc7ab9912a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7cadcea8856d463eb2347937fc00fd93",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_70ea1cdab66a43eeb7bfeb7b7e82ca85",
       "value": 1
      }
     },
     "7779f529edf141c7a8093aa89715a228": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2372c0410f73493581944718477c6ffa",
       "placeholder": "​",
       "style": "IPY_MODEL_70e19001e8e3479aaa9f6e4ac527df12",
       "value": " 95/? [01:22&lt;00:00,  1.16it/s]"
      }
     },
     "7cadcea8856d463eb2347937fc00fd93": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7edefa114b2d4a549174704fb37b6c48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a84c0e72cbb34324b0c3db38e6553b15",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b7e9b43f621a4484b54f517cb7ac4fd1",
       "value": 1
      }
     },
     "80aee781487944aaa2c3fda4a2a0194f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8cc182ca0e1f4b28987f3e818dad5e11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_61f67ac644a84bfd880d3fc4bbfcaaf4",
       "placeholder": "​",
       "style": "IPY_MODEL_a58754b32069406eb079173046ba94a8",
       "value": " 8/? [00:06&lt;00:00,  1.22it/s]"
      }
     },
     "8dc9ed3f538841f39788104e46d05883": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8f8504588ea54e92b835b351c0f171a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "92764c5369a04a318d1b2c957a4ee2a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "985151d13fa34612bdcec4b004e0309c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b91c1a91cb60425e97e91ebf3d9e4c9f",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_92764c5369a04a318d1b2c957a4ee2a3",
       "value": 1
      }
     },
     "9da48c88afbc46e6a13b6daec27b368b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a243d6cc4de74f2a8a624db048eed14b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a58754b32069406eb079173046ba94a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a84c0e72cbb34324b0c3db38e6553b15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ab5196d5f0c74e3e9a637fb60619c04e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b6a8af2739ec425784d06302587f2399": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ea281c89a9eb4aa5bff679cfc8fcf933",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e7ed297fe2ce4df780551dbf873adc3f",
       "value": 1
      }
     },
     "b7e9b43f621a4484b54f517cb7ac4fd1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "b91c1a91cb60425e97e91ebf3d9e4c9f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b9f8bf1df91044d180b5ca2465251026": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d54ef5893ae7488fbbe74b2e91d7f474",
       "placeholder": "​",
       "style": "IPY_MODEL_ab5196d5f0c74e3e9a637fb60619c04e",
       "value": " 95/? [00:57&lt;00:00,  1.66it/s]"
      }
     },
     "c375c8e6f75f4c9a87d01a91f996c8d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_776db6c535da4943804f9fc7ab9912a0",
        "IPY_MODEL_b9f8bf1df91044d180b5ca2465251026"
       ],
       "layout": "IPY_MODEL_12abba34e9e34e1a8fee76f640173f17"
      }
     },
     "d54ef5893ae7488fbbe74b2e91d7f474": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e70762a9d8954d6cbffdab1750ea410e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_225aff503a184406b795d8e7d0de15e9",
        "IPY_MODEL_37aea566503a4c3d80566f76ba78efe0"
       ],
       "layout": "IPY_MODEL_8f8504588ea54e92b835b351c0f171a6"
      }
     },
     "e7ed297fe2ce4df780551dbf873adc3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "e81aacac360c47e8bace534fd6508044": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ea281c89a9eb4aa5bff679cfc8fcf933": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
